{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1htD3uRTqfry"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elTVD2pVOMFp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Embedding, Reshape, Conv1D, MaxPool1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xCNiunBhTK"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--GFqd9iqyPb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4w3NERBvq55R",
        "outputId": "68d4a751-a0fc-4328-d2db-428c20695c88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   1\n",
              "0  ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...\n",
              "1  امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...\n",
              "2  خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...\n",
              "3  در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...\n",
              "4  ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b4b49ef-cf1d-4f12-aa3e-c3a5d148c86f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b4b49ef-cf1d-4f12-aa3e-c3a5d148c86f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b4b49ef-cf1d-4f12-aa3e-c3a5d148c86f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b4b49ef-cf1d-4f12-aa3e-c3a5d148c86f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckG4SpxpBv0v"
      },
      "source": [
        "**Read Stop-Words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j1ET4Envq9WJ"
      },
      "outputs": [],
      "source": [
        "def read_stop_words(filename):\n",
        "  with open(filename) as stopwords_file:\n",
        "    stopwords = stopwords_file.readlines()\n",
        "  stopwords = [line.replace('\\n', '') for line in stopwords] \n",
        "  return stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcvHmY1GrB6m",
        "outputId": "b0bb3f4e-98fb-49ef-a457-aeb75974a2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1382\n"
          ]
        }
      ],
      "source": [
        "stopwords = read_stop_words('stopwords.txt')\n",
        "print(len(stopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrUF5WHobMYG"
      },
      "source": [
        "**hazm library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51aGKS8zcXBb",
        "outputId": "c9577ff2-deaf-4c4b-ec04-d43fefef9ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=b54a78e3b60651e6622b2db21afb50b7b5a166a9c141e2f0470aa357733bd3a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154031 sha256=a52667381b42613306921543c24025518ef12719367c586dde8dda94b31fe6d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "# install hazm library\n",
        "!pip install hazm\n",
        "from hazm import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efCRPjKQbXHH"
      },
      "source": [
        "### **Preprocess the text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nCg2QfwVa_6C"
      },
      "outputs": [],
      "source": [
        "# preprocess the text\n",
        "def text_preprocess(data):\n",
        "  text = [line.replace('\\t', ' ') for line in data.values.flatten()]\n",
        "  text = [line.replace('-', ' ') for line in text]\n",
        "  text = [re.sub(\"\\d+\", \"\", t) for t in text]\n",
        "\n",
        "  word_tokenized = [word_tokenize(t) for t in text]\n",
        "  word_tokenized_filtered = [[w for w in sentence if w not in stopwords] for sentence in word_tokenized]\n",
        "\n",
        "  sentences = [' '.join(sentence) for sentence in word_tokenized_filtered]\n",
        "  sentences = [sentence for sentence in sentences if sentence != '']\n",
        "\n",
        "  return sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BbJ_TpjbrR52"
      },
      "outputs": [],
      "source": [
        "sentences = text_preprocess(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EN2dI2uITsRP",
        "outputId": "2dcfff26-be20-42c7-89cd-45a0aeafe42d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'رستخیز رحمت منتها آتشی افروخته بیشه اندیشه'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1buSxp96bxfF"
      },
      "source": [
        "### **get less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VnVjtr5ldH0h"
      },
      "outputs": [],
      "source": [
        "def get_all_sentences():\n",
        "  all_sentences = ''\n",
        "  sentences = text_preprocess(data)\n",
        "  for sentence in sentences:\n",
        "    all_sentences += sentence\n",
        "    all_sentences += ' '\n",
        "\n",
        "  return all_sentences  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6mjyKRbHeXGB"
      },
      "outputs": [],
      "source": [
        "def get_word_freq(vocabularies):\n",
        "  word_freq = []\n",
        "  for vocab in vocabularies:\n",
        "    word_freq.append(vocabularies.count(vocab))\n",
        "  return word_freq  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q3BTyonArXoS"
      },
      "outputs": [],
      "source": [
        "# get the words that frequentes less than 2 times in the corpus\n",
        "def get_less_frequente_words():\n",
        "  low_frequency_words = []\n",
        "  all_sentences = get_all_sentences()\n",
        "  vocabularies = all_sentences.split(' ')\n",
        "  word_freq = get_word_freq(vocabularies)\n",
        "\n",
        "  for i in range(len(word_freq)):\n",
        "    if word_freq[i] < 2:\n",
        "      low_frequency_words.append(vocabularies[i])\n",
        "\n",
        "  return low_frequency_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i758iopdesxx"
      },
      "outputs": [],
      "source": [
        "less_frequente_words = get_less_frequente_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3CZ3SK3Obj",
        "outputId": "2da7cbd8-4086-4025-d997-7ba9dbb58678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6366\n"
          ]
        }
      ],
      "source": [
        "print(len(less_frequente_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebfg1Rvyb-Gv"
      },
      "source": [
        "## **remove less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vC7K9jAcv0Qz"
      },
      "outputs": [],
      "source": [
        "# remove the words that frequentes less than 2 times in the corpus\n",
        "def remove_less_frequente_words(less_frequente_words, sentences):\n",
        "  sentences_tokenized = [word_tokenize(sentence) for sentence in sentences]\n",
        "  sentences_tokenized_filtered = [[w for w in sentence if w not in less_frequente_words] for sentence in sentences_tokenized]\n",
        "  corpus = [' '.join(sentence) for sentence in sentences_tokenized_filtered]\n",
        "  corpus = [sentence for sentence in corpus if sentence != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WH0VEdXFwS6L"
      },
      "outputs": [],
      "source": [
        "corpus = remove_less_frequente_words(less_frequente_words, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvdxpqaHzAnp",
        "outputId": "cc46c0bd-e13c-48d0-ee28-dcdfc9dddac8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['رستخیز رحمت منتها آتشی افروخته بیشه اندیشه',\n",
              " 'خندان آمدی مفتاح زندان آمدی آمدی بخشش فضل خدا',\n",
              " 'خورشید حاجب تویی امید واجب تویی مطلب تویی طالب تویی منتها',\n",
              " 'سینه اندیشه آراسته حاجت روا',\n",
              " 'روح علم باقی بهانه دغل علت دوا',\n",
              " 'دغل کژ گنه کین مست مست نان شوربا',\n",
              " 'هل عقل هل نان نشاید ماجرا',\n",
              " 'تدبیر رنگ افکنی روم زنگ افکنی جنگ افکنی یری',\n",
              " 'پنهان گوش جان بهانه کسان جان رب زنان والله کیا',\n",
              " 'خامش رفتم پای علم کاغذ بنه بشکن قلم ساقی درآمد الصلا']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "corpus[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHH7-nVDcRAx"
      },
      "source": [
        "## **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0xOHtNwUOAY1"
      },
      "outputs": [],
      "source": [
        "# tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eeZyyz09OOBL"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rHUu4qzOWxT",
        "outputId": "30ae7233-3f0a-44d7-8569-6d6d4b403180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'جان': 1, 'دل': 2, 'عشق': 3, 'آب': 4, 'چشم': 5, 'شب': 6, 'جهان': 7, 'شمس': 8, 'دست': 9, 'مست': 10, 'گل': 11, 'یار': 12, 'عقل': 13, 'جمله': 14, 'غم': 15, 'آتش': 16, 'نور': 17, 'مه': 18, 'خاک': 19, 'تن': 20, 'عالم': 21, 'تبریز': 22, 'خدا': 23, 'شاه': 24, 'ره': 25, 'خانه': 26, 'باده': 27, 'عاشق': 28, 'تویی': 29, 'روح': 30, 'ساقی': 31, 'خون': 32, 'ماه': 33, 'کف': 34, 'رخ': 35, 'لطف': 36, 'شکر': 37, 'پا': 38, 'زر': 39, 'آسمان': 40, 'گوش': 41, 'عاشقان': 42, 'زمین': 43, 'بحر': 44, 'ذره': 45, 'خورشید': 46, 'سخن': 47, 'چرخ': 48, 'گرد': 49, 'پرده': 50, 'باغ': 51, 'جام': 52, 'تبریزی': 53, 'دین': 54, 'آرزوست': 55, 'پای': 56, 'خواب': 57, 'ای': 58, 'آفتاب': 59, 'گشت': 60, 'سو': 61, 'یوسف': 62, 'درد': 63, 'گشته': 64, 'دوست': 65, 'بنده': 66, 'دریا': 67, 'نفس': 68, 'شمع': 69, 'روان': 70, 'شراب': 71, 'دلم': 72, 'هوا': 73, 'برو': 74, 'زبان': 75, 'ببین': 76, 'پنهان': 77, 'سنگ': 78, 'دهان': 79, 'وقت': 80, 'وفا': 81, 'بوی': 82, 'رسد': 83, 'سجده': 84, 'خواجه': 85, 'خمش': 86, 'سایه': 87, 'خار': 88, 'نقش': 89, 'شیر': 90, 'اصل': 91, 'سینه': 92, 'نهان': 93, 'خیال': 94, 'برد': 95, 'فنا': 96, 'شهر': 97, 'فلک': 98, 'زن': 99, 'رقص': 100, 'سلطان': 101, 'دور': 102, 'بده': 103, 'رنگ': 104, 'جو': 105, 'دولت': 106, 'داند': 107, 'خم': 108, 'چشمه': 109, 'قد': 110, 'رود': 111, 'موسی': 112, 'کرم': 113, 'بینی': 114, 'گفتا': 115, 'بام': 116, 'بنگر': 117, 'ملک': 118, 'خبر': 119, 'پاره': 120, 'بلا': 121, 'خلق': 122, 'دید': 123, 'حیات': 124, 'دام': 125, 'نظر': 126, 'صفا': 127, 'ابر': 128, 'دلا': 129, 'حسن': 130, 'هزاران': 131, 'جوی': 132, 'نباشد': 133, 'الله': 134, 'چنگ': 135, 'نو': 136, 'زنده': 137, 'بسته': 138, 'مستان': 139, 'مستی': 140, 'اسرار': 141, 'گنج': 142, 'اندیشه': 143, 'حلقه': 144, 'کوه': 145, 'لقا': 146, 'دمی': 147, 'ترک': 148, 'جمال': 149, 'مخسب': 150, 'غیب': 151, 'خمار': 152, 'خاموش': 153, 'قضا': 154, 'وصل': 155, 'خدایا': 156, 'بستان': 157, 'ساقیا': 158, 'بانگ': 159, 'مرده': 160, 'طلب': 161, 'باقی': 162, 'لعل': 163, 'کش': 164, 'نگر': 165, 'آرد': 166, 'کشد': 167, 'لحظه': 168, 'دعا': 169, 'صفت': 170, 'شیوه': 171, 'مرغ': 172, 'خرد': 173, 'گوهر': 174, 'بند': 175, 'الدین': 176, 'حلوا': 177, 'رنج': 178, 'مرد': 179, 'پری': 180, 'طرب': 181, 'درخت': 182, 'مجلس': 183, 'بهار': 184, 'خندان': 185, 'الصلا': 186, 'بقا': 187, 'دود': 188, 'سرو': 189, 'دلی': 190, 'پاک': 191, 'جنگ': 192, 'نهد': 193, 'رها': 194, 'زخم': 195, 'زهره': 196, 'دانه': 197, 'جانا': 198, 'سحر': 199, 'زلف': 200, 'خامش': 201, 'دانی': 202, 'معنی': 203, 'جانی': 204, 'کای': 205, 'نعره': 206, 'بگشا': 207, 'مطرب': 208, 'نان': 209, 'وصال': 210, 'قبله': 211, 'جانم': 212, 'مشک': 213, 'سما': 214, 'فتنه': 215, 'جوش': 216, 'محو': 217, 'شادی': 218, 'هوای': 219, 'اینست': 220, 'علم': 221, 'یقین': 222, 'دریای': 223, 'ذوق': 224, 'باری': 225, 'دلبر': 226, 'دوش': 227, 'گم': 228, 'بوسه': 229, 'گران': 230, 'نیم': 231, 'عیسی': 232, 'موج': 233, 'تنگ': 234, 'هله': 235, 'مغز': 236, 'ساغر': 237, 'کوی': 238, 'ناز': 239, 'سلام': 240, 'خدای': 241, 'عمر': 242, 'ببینی': 243, 'دوا': 244, 'زنان': 245, 'حد': 246, 'صبا': 247, 'نرگس': 248, 'طمع': 249, 'صبر': 250, 'دان': 251, 'سفر': 252, 'جانب': 253, 'عیش': 254, 'منم': 255, 'خموش': 256, 'نار': 257, 'طالب': 258, 'رب': 259, 'خدمت': 260, 'هوس': 261, 'خوان': 262, 'دیدم': 263, 'خوبی': 264, 'چهره': 265, 'گلشن': 266, 'رشک': 267, 'بزن': 268, 'قیامت': 269, 'مهر': 270, 'دیدی': 271, 'عین': 272, 'صبح': 273, 'شاخ': 274, 'العشق': 275, 'شاد': 276, 'خر': 277, 'نفسی': 278, 'کاسه': 279, 'فراق': 280, 'گذشت': 281, 'عید': 282, 'رحمت': 283, 'والله': 284, 'سودای': 285, 'چاره': 286, 'بو': 287, 'چمن': 288, 'چراغ': 289, 'قرار': 290, 'خورد': 291, 'گردن': 292, 'دی': 293, 'دیدن': 294, 'تست': 295, 'قمر': 296, 'دلدار': 297, 'جسم': 298, 'ابد': 299, 'علی': 300, 'سودا': 301, 'روحی': 302, 'جاست': 303, 'توبه': 304, 'مبارکست': 305, 'قطره': 306, 'زد': 307, 'اقبال': 308, 'جفا': 309, 'ناله': 310, 'دیدار': 311, 'گلزار': 312, 'آسیا': 313, 'پیر': 314, 'قدح': 315, 'دشمن': 316, 'بلبل': 317, 'یاد': 318, 'عشاق': 319, 'منزل': 320, 'گلستان': 321, 'مار': 322, 'روشن': 323, 'بازار': 324, 'تشنه': 325, 'خشک': 326, 'گمان': 327, 'خراب': 328, 'بشنو': 329, 'ولیکن': 330, 'پروانه': 331, 'فضل': 332, 'کشتی': 333, 'مرگ': 334, 'جگر': 335, 'کمان': 336, 'خسرو': 337, 'هوش': 338, 'انا': 339, 'سرا': 340, 'غمزه': 341, 'خوبان': 342, 'لطیف': 343, 'جواب': 344, 'مشین': 345, 'جست': 346, 'نمود': 347, 'خنده': 348, 'جمع': 349, 'شده': 350, 'است': 351, 'روم': 352, 'یاری': 353, 'نیک': 354, 'دستار': 355, 'سرمست': 356, 'تیغ': 357, 'مجنون': 358, 'زار': 359, 'مرحبا': 360, 'قصه': 361, 'بخت': 362, 'درویش': 363, 'هجر': 364, 'نه': 365, 'نما': 366, 'ترش': 367, 'خوی': 368, 'گشاد': 369, 'بت': 370, 'برگ': 371, 'آواز': 372, 'سود': 373, 'تماشا': 374, 'کدامست': 375, 'هیهات': 376, 'بنه': 377, 'نقد': 378, 'پایان': 379, 'قبا': 380, 'مهمان': 381, 'بیند': 382, 'بزم': 383, 'خوار': 384, 'آدم': 385, 'تیر': 386, 'گردان': 387, 'آینه': 388, 'سگ': 389, 'بیدار': 390, 'حدیث': 391, 'غیرت': 392, 'صید': 393, 'الحق': 394, 'سعادت': 395, 'نوبت': 396, 'آتشی': 397, 'زندان': 398, 'بهانه': 399, 'مال': 400, 'شور': 401, 'بدر': 402, 'بری': 403, 'زاده': 404, 'منه': 405, 'مانده': 406, 'حیران': 407, 'آهن': 408, 'ایمان': 409, 'دیو': 410, 'بدی': 411, 'پیشش': 412, 'خام': 413, 'مثال': 414, 'غصه': 415, 'بگذار': 416, 'حجاب': 417, 'مفخر': 418, 'ماجرا': 419, 'اهل': 420, 'روزی': 421, 'لاله': 422, 'صلا': 423, 'نهی': 424, 'مده': 425, 'رونق': 426, 'خور': 427, 'موی': 428, 'شرم': 429, 'صاحب': 430, 'برآ': 431, 'مرغان': 432, 'حرف': 433, 'ماهی': 434, 'نوش': 435, 'زهر': 436, 'محرم': 437, 'صنم': 438, 'خوشتر': 439, 'سلیمان': 440, 'سیر': 441, 'رست': 442, 'بست': 443, 'عن': 444, 'نای': 445, 'بیمار': 446, 'طبل': 447, 'رخت': 448, 'صنما': 449, 'میدان': 450, 'لاف': 451, 'رویی': 452, 'عشقش': 453, 'جانست': 454, 'معشوق': 455, 'برادر': 456, 'بدید': 457, 'سه': 458, 'مصلحت': 459, 'الهوی': 460, 'بخسب': 461, 'خرابات': 462, 'جستیم': 463, 'هل': 464, 'عشقت': 465, 'بال': 466, 'گردون': 467, 'سیم': 468, 'صدا': 469, 'اشک': 470, 'ضیا': 471, 'گرو': 472, 'سوز': 473, 'میر': 474, 'ننگ': 475, 'گشتی': 476, 'خواهی': 477, 'بها': 478, 'شوق': 479, 'بیچاره': 480, 'نیستی': 481, 'عرش': 482, 'جانت': 483, 'سبک': 484, 'نیاید': 485, 'دامن': 486, 'گفتار': 487, 'کوری': 488, 'صافی': 489, 'فرعون': 490, 'کنان': 491, 'عنایت': 492, 'ببر': 493, 'پخته': 494, 'میا': 495, 'صوفیان': 496, 'دوان': 497, 'صدر': 498, 'پهلوی': 499, 'جانش': 500, 'جهانی': 501, 'درده': 502, 'مشعله': 503, 'واجبست': 504, 'برات': 505, 'هجران': 506, 'فخر': 507, 'خاکی': 508, 'جرعه': 509, 'خطا': 510, 'طبع': 511, 'ندا': 512, 'آدمی': 513, 'عیار': 514, 'نماند': 515, 'نوا': 516, 'دف': 517, 'آر': 518, 'برآید': 519, 'آبی': 520, 'سان': 521, 'منگر': 522, 'خدایی': 523, 'ام': 524, 'فدا': 525, 'گرم': 526, 'دیگ': 527, 'قدم': 528, 'حیوان': 529, 'مکر': 530, 'وعده': 531, 'مسیح': 532, 'ساعت': 533, 'گهر': 534, 'آیدت': 535, 'خسته': 536, 'کام': 537, 'پست': 538, 'یاران': 539, 'خوف': 540, 'گفتمش': 541, 'جنون': 542, 'قند': 543, 'کوزه': 544, 'غزل': 545, 'پوست': 546, 'نوری': 547, 'بیار': 548, 'گشاید': 549, 'خضر': 550, 'زمانه': 551, 'الست': 552, 'مراد': 553, 'نهانی': 554, 'حریف': 555, 'بدو': 556, 'سیه': 557, 'نثار': 558, 'رباب': 559, 'دیوانه': 560, 'لقمه': 561, 'زنهار': 562, 'خشم': 563, 'گرفتست': 564, 'شکار': 565, 'قالب': 566, 'عظیمست': 567, 'آمدی': 568, 'کین': 569, 'درآمد': 570, 'سال': 571, 'کشان': 572, 'کور': 573, 'خوشی': 574, 'جامه': 575, 'خاصه': 576, 'برده': 577, 'پند': 578, 'شبی': 579, 'تیز': 580, 'فزا': 581, 'مشتری': 582, 'تجلی': 583, 'مسکین': 584, 'راز': 585, 'جانان': 586, 'گور': 587, 'طره': 588, 'نردبان': 589, 'غلط': 590, 'جاء': 591, 'منکر': 592, 'سبزه': 593, 'ترس': 594, 'خداوند': 595, 'شرح': 596, 'شاهی': 597, 'برگشا': 598, 'چونی': 599, 'تاب': 600, 'بیخ': 601, 'حبس': 602, 'گریه': 603, 'زو': 604, 'پریشان': 605, 'ساز': 606, 'خیز': 607, 'بجو': 608, 'روزه': 609, 'آهوی': 610, 'سبب': 611, 'اسب': 612, 'نگار': 613, 'بروید': 614, 'بدانی': 615, 'نکته': 616, 'گواه': 617, 'نبیند': 618, 'صحرا': 619, 'یارا': 620, 'که': 621, 'خاص': 622, 'درآید': 623, 'نبینی': 624, 'عشرت': 625, 'همت': 626, 'زیان': 627, 'زکات': 628, 'دماغ': 629, 'خط': 630, 'منست': 631, 'معدن': 632, 'مذهب': 633, 'قم': 634, 'خوشست': 635, 'امید': 636, 'افلاک': 637, 'قال': 638, 'آغاز': 639, 'اختر': 640, 'حسد': 641, 'عطا': 642, 'جنت': 643, 'نظاره': 644, 'زده': 645, 'عالمی': 646, 'آنگه': 647, 'شیشه': 648, 'ناگه': 649, 'مجو': 650, 'آمدم': 651, 'شیران': 652, 'اژدها': 653, 'شعله': 654, 'باران': 655, 'گذر': 656, 'خو': 657, 'سیل': 658, 'پیشت': 659, 'نشسته': 660, 'گردش': 661, 'مرو': 662, 'پدر': 663, 'رضا': 664, 'دهن': 665, 'برق': 666, 'دهل': 667, 'طال': 668, 'سلسله': 669, 'گیا': 670, 'کبر': 671, 'کبریا': 672, 'فسون': 673, 'عاشقی': 674, 'غریب': 675, 'کمین': 676, 'کرده': 677, 'بربند': 678, 'جوید': 679, 'بخور': 680, 'دگربار': 681, 'مخمور': 682, 'بیان': 683, 'گشتم': 684, 'خزان': 685, 'امیر': 686, 'سقا': 687, 'میوه': 688, 'مکان': 689, 'دراز': 690, 'گوشه': 691, 'ثنا': 692, 'نشود': 693, 'ضمیر': 694, 'خواند': 695, 'صفات': 696, 'نقاب': 697, 'خواهم': 698, 'نقل': 699, 'خیالت': 700, 'بهشت': 701, 'ولیک': 702, 'نبات': 703, 'قامت': 704, 'حقایق': 705, 'صوفی': 706, 'زرین': 707, 'آیی': 708, 'بیخودی': 709, 'برآمد': 710, 'تری': 711, 'نظری': 712, 'چاه': 713, 'حریفان': 714, 'سماع': 715, 'دلست': 716, 'میی': 717, 'بخشد': 718, 'رخسار': 719, 'خصم': 720, 'مقیم': 721, 'ذات': 722, 'فاسقنیها': 723, 'تظلمونا': 724, 'آمدست': 725, 'بدانک': 726, 'حاجت': 727, 'روا': 728, 'کژ': 729, 'یری': 730, 'رفتم': 731, 'بشکن': 732, 'نگردد': 733, 'فانی': 734, 'الضحی': 735, 'زنم': 736, 'داغ': 737, 'ربنا': 738, 'اجل': 739, 'شرابی': 740, 'گردی': 741, 'دری': 742, 'درکش': 743, 'شمشیر': 744, 'طفل': 745, 'شیری': 746, 'ظاهر': 747, 'طوطی': 748, 'قوت': 749, 'قرین': 750, 'اشتر': 751, 'نگویی': 752, 'پرنور': 753, 'شاهان': 754, 'بینا': 755, 'بدن': 756, 'دلش': 757, 'سرش': 758, 'نادره': 759, 'نوشت': 760, 'سرگردان': 761, 'خجل': 762, 'کشی': 763, 'سازد': 764, 'کردست': 765, 'صلح': 766, 'دعوت': 767, 'آواره': 768, 'ورا': 769, 'عنقا': 770, 'عذرا': 771, 'دیوار': 772, 'غلام': 773, 'لامکان': 774, 'گریان': 775, 'مصر': 776, 'چاشنی': 777, 'چوگان': 778, 'قصد': 779, 'عجایب': 780, 'هذا': 781, 'ریحان': 782, 'صف': 783, 'بگرفته': 784, 'نک': 785, 'دفع': 786, 'اغیار': 787, 'ویران': 788, 'شجر': 789, 'غرقه': 790, 'شهره': 791, 'فاش': 792, 'آثار': 793, 'زرد': 794, 'گره': 795, 'بهل': 796, 'گوهری': 797, 'شست': 798, 'حقیقت': 799, 'خلوت': 800, 'عکس': 801, 'نهاده': 802, 'عهد': 803, 'نشانی': 804, 'خنک': 805, 'غوغا': 806, 'تعالی': 807, 'قاف': 808, 'مقام': 809, 'تابان': 810, 'شکوفه': 811, 'ملامت': 812, 'طواف': 813, 'خوابی': 814, 'دنیا': 815, 'صبوح': 816, 'تک': 817, 'دزد': 818, 'بتان': 819, 'بیم': 820, 'شرق': 821, 'سزا': 822, 'صلاح': 823, 'فاسقنا': 824, 'جنس': 825, 'رسول': 826, 'لو': 827, 'ذا': 828, 'ننشست': 829, 'بخشش': 830, 'مطلب': 831, 'عشقی': 832, 'خرقه': 833, 'امر': 834, 'الف': 835, 'شعر': 836, 'نعم': 837, 'جرم': 838, 'بگذرد': 839, 'بشکند': 840, 'عدو': 841, 'لایق': 842, 'رهی': 843, 'مقصود': 844, 'امان': 845, 'آتشین': 846, 'بیت': 847, 'هشیار': 848, 'کشم': 849, 'مادر': 850, 'نوح': 851, 'دعوی': 852, 'زعفران': 853, 'ارواح': 854, 'گلی': 855, 'کاه': 856, 'نسیم': 857, 'دیده': 858, 'افتاده': 859, 'روشنی': 860, 'مریم': 861, 'یعقوب': 862, 'کشت': 863, 'خارا': 864, 'علا': 865, 'قافله': 866, 'گدا': 867, 'تابش': 868, 'تیره': 869, 'درمان': 870, 'نشین': 871, 'علینا': 872, 'شعشعه': 873, 'رسته': 874, 'تهی': 875, 'دانش': 876, 'گلو': 877, 'کفش': 878, 'عاقل': 879, 'مژده': 880, 'تار': 881, 'سلامت': 882, 'حاصل': 883, 'آفرین': 884, 'بگشاید': 885, 'اذا': 886, 'مردی': 887, 'زنجیر': 888, 'القلب': 889, 'نگنجد': 890, 'نهایت': 891, 'دستی': 892, 'منتظر': 893, 'دندان': 894, 'دشت': 895, 'شیدا': 896, 'روید': 897, 'جویی': 898, 'بشنود': 899, 'برهان': 900, 'برآرد': 901, 'بکش': 902, 'توام': 903, 'خری': 904, 'دلبری': 905, 'زنی': 906, 'حیرت': 907, 'عند': 908, 'غار': 909, 'ندهد': 910, 'اسباب': 911, 'ندانم': 912, 'تخته': 913, 'سرد': 914, 'مدار': 915, 'نهاد': 916, 'گزیده': 917, 'اسیر': 918, 'بشکست': 919, 'صاف': 920, 'برفت': 921, 'سیما': 922, 'طبیب': 923, 'جمالش': 924, 'سرخ': 925, 'کرامت': 926, 'مگیر': 927, 'مولا': 928, 'بگفت': 929, 'حشر': 930, 'شهوت': 931, 'حرص': 932, 'غنچه': 933, 'سجود': 934, 'شر': 935, 'مردان': 936, 'جمالت': 937, 'بیگانه': 938, 'کعبه': 939, 'کون': 940, 'عربده': 941, 'یوم': 942, 'احمد': 943, 'مدد': 944, 'سکر': 945, 'رخش': 946, 'بستم': 947, 'عیان': 948, 'ترانه': 949, 'سبز': 950, 'مشکل': 951, 'اثر': 952, 'مبارکی': 953, 'غمش': 954, 'کهنه': 955, 'نکرد': 956, 'لم': 957, 'بامداد': 958, 'فقر': 959, 'غبار': 960, 'اختیار': 961, 'له': 962, 'ثم': 963, 'مستست': 964, 'خوشکست': 965, 'نرفت': 966, 'بیشه': 967, 'علت': 968, 'تدبیر': 969, 'خالی': 970, 'شتر': 971, 'مصطفی': 972, 'گنبد': 973, 'چشمم': 974, 'خورم': 975, 'همراه': 976, 'زدی': 977, 'عود': 978, 'شکل': 979, 'همنشین': 980, 'جادوی': 981, 'ابروی': 982, 'بنا': 983, 'ماییم': 984, 'اتی': 985, 'رویت': 986, 'خوشم': 987, 'دلربا': 988, 'قفا': 989, 'آشنا': 990, 'کمر': 991, 'رقصان': 992, 'نگویم': 993, 'ستاره': 994, 'بگردان': 995, 'خواره': 996, 'برجه': 997, 'نالان': 998, 'عدل': 999, 'خرم': 1000, 'کهربا': 1001, 'لذت': 1002, 'گشتیم': 1003, 'عصا': 1004, 'کهسار': 1005, 'کفر': 1006, 'پرست': 1007, 'عیب': 1008, 'دانا': 1009, 'مخدوم': 1010, 'مسجد': 1011, 'بازآ': 1012, 'بنمای': 1013, 'یشا': 1014, 'گریبان': 1015, 'بنما': 1016, 'هلا': 1017, 'فهم': 1018, 'قهر': 1019, 'فریاد': 1020, 'شهنشاه': 1021, 'ولا': 1022, 'رحم': 1023, 'دردی': 1024, 'ناطق': 1025, 'کنعان': 1026, 'وحی': 1027, 'سخا': 1028, 'نوحه': 1029, 'اصحاب': 1030, 'امتحان': 1031, 'قفل': 1032, 'تاج': 1033, 'وطن': 1034, 'الولا': 1035, 'روضه': 1036, 'گلزارها': 1037, 'نمودی': 1038, 'نعمت': 1039, 'جستن': 1040, 'حضرت': 1041, 'اشارت': 1042, 'جسته': 1043, 'معراج': 1044, 'لی': 1045, 'دزدیده': 1046, 'خفته': 1047, 'رستم': 1048, 'ازل': 1049, 'دعای': 1050, 'دوی': 1051, 'نفی': 1052, 'بدم': 1053, 'تخت': 1054, 'ببرد': 1055, 'پاست': 1056, 'کر': 1057, 'شکسته': 1058, 'شنید': 1059, 'بریده': 1060, 'اطلس': 1061, 'بسوزد': 1062, 'کشته': 1063, 'دوزخ': 1064, 'سزای': 1065, 'طرفی': 1066, 'دریاست': 1067, 'چشمت': 1068, 'معانی': 1069, 'امت': 1070, 'صحبت': 1071, 'دستان': 1072, 'شکرخا': 1073, 'رعنا': 1074, 'حوض': 1075, 'چین': 1076, 'بن': 1077, 'لاغر': 1078, 'نتوان': 1079, 'گنجد': 1080, 'نیابی': 1081, 'کیسه': 1082, 'علیک': 1083, 'شتاب': 1084, 'سوداست': 1085, 'لوت': 1086, 'سوگند': 1087, 'چپ': 1088, 'دانک': 1089, 'بدیدم': 1090, 'سویی': 1091, 'رنجور': 1092, 'رسیدی': 1093, 'شمار': 1094, 'بنشین': 1095, 'حبیب': 1096, 'گشاده': 1097, 'خاطر': 1098, 'ات': 1099, 'نبرد': 1100, 'بتافت': 1101, 'مو': 1102, 'استاره': 1103, 'حور': 1104, 'عار': 1105, 'فاتحه': 1106, 'قلب': 1107, 'انکار': 1108, 'شکاف': 1109, 'هنر': 1110, 'پیاله': 1111, 'بگرد': 1112, 'بیابان': 1113, 'سوال': 1114, 'میانه': 1115, 'فعل': 1116, 'بخندد': 1117, 'الحب': 1118, 'حکم': 1119, 'سیماب': 1120, 'زشت': 1121, 'غماز': 1122, 'نازکست': 1123, 'مفتاح': 1124, 'نشاید': 1125, 'زنگ': 1126, 'کیا': 1127, 'قلم': 1128, 'خونی': 1129, 'عدد': 1130, 'قلزم': 1131, 'عذر': 1132, 'اولیا': 1133, 'مهره': 1134, 'انوار': 1135, 'گری': 1136, 'چشمی': 1137, 'دغا': 1138, 'انگور': 1139, 'گندم': 1140, 'بیخود': 1141, 'آهنگ': 1142, 'احمر': 1143, 'شهان': 1144, 'درت': 1145, 'برخیز': 1146, 'اندرآ': 1147, 'برهم': 1148, 'جل': 1149, 'بدریده': 1150, 'بشر': 1151, 'آفتابی': 1152, 'بندگان': 1153, 'حیا': 1154, 'برج': 1155, 'دایه': 1156, 'فتد': 1157, 'دکان': 1158, 'احسان': 1159, 'پنجه': 1160, 'طوفان': 1161, 'باطن': 1162, 'شکم': 1163, 'خرمن': 1164, 'تلخی': 1165, 'خلقان': 1166, 'حقست': 1167, 'آیینه': 1168, 'عمران': 1169, 'آفاق': 1170, 'جلوه': 1171, 'آگه': 1172, 'همره': 1173, 'تلخ': 1174, 'نسرین': 1175, 'غریبی': 1176, 'رفیق': 1177, 'یفعل': 1178, 'پدید': 1179, 'سوراخ': 1180, 'سیاه': 1181, 'سرم': 1182, 'نداند': 1183, 'کسب': 1184, 'پرد': 1185, 'مرکب': 1186, 'اختران': 1187, 'لنگ': 1188, 'بینم': 1189, 'جذب': 1190, 'تاریک': 1191, 'عز': 1192, 'زنار': 1193, 'خودی': 1194, 'دوتا': 1195, 'هش': 1196, 'زفت': 1197, 'خداوندی': 1198, 'وهم': 1199, 'بگشاد': 1200, 'فتاد': 1201, 'چشمش': 1202, 'ریش': 1203, 'غره': 1204, 'انبار': 1205, 'اقربا': 1206, 'لیلی': 1207, 'طرفه': 1208, 'سرکه': 1209, 'رفتی': 1210, 'رطل': 1211, 'اجزای': 1212, 'دستم': 1213, 'رسن': 1214, 'کامروز': 1215, 'ماننده': 1216, 'جذبه': 1217, 'افتاد': 1218, 'حبذا': 1219, 'حج': 1220, 'مرهم': 1221, 'آشفته': 1222, 'خمشی': 1223, 'عارف': 1224, 'طوق': 1225, 'بکشد': 1226, 'گشتست': 1227, 'ندید': 1228, 'بهاری': 1229, 'زشتی': 1230, 'مات': 1231, 'دلت': 1232, 'کلیم': 1233, 'کیمیا': 1234, 'خلعت': 1235, 'کشیده': 1236, 'کوته': 1237, 'کران': 1238, 'خوشش': 1239, 'یاوه': 1240, 'باوفا': 1241, 'دشمنان': 1242, 'امین': 1243, 'ببیند': 1244, 'بداند': 1245, 'نامه': 1246, 'فسانه': 1247, 'شربت': 1248, 'یوسفی': 1249, 'بدیده': 1250, 'حیله': 1251, 'هندو': 1252, 'بادست': 1253, 'زاد': 1254, 'گرگین': 1255, 'رام': 1256, 'گوشم': 1257, 'سوسن': 1258, 'استاد': 1259, 'کوثر': 1260, 'خلایق': 1261, 'صفرا': 1262, 'امن': 1263, 'جامی': 1264, 'زیبا': 1265, 'عشقست': 1266, 'یکتا': 1267, 'روزن': 1268, 'یزدان': 1269, 'بنمود': 1270, 'اوصاف': 1271, 'درختی': 1272, 'خطاب': 1273, 'شوریده': 1274, 'حالت': 1275, 'خوری': 1276, 'قوم': 1277, 'مگذار': 1278, 'منت': 1279, 'خمر': 1280, 'رعد': 1281, 'انداخت': 1282, 'جبار': 1283, 'ناموس': 1284, 'حرامست': 1285, 'برخاست': 1286, 'مجرد': 1287, 'تقاضا': 1288, 'گول': 1289, 'یارم': 1290, 'شناسد': 1291, 'سیمین': 1292, 'لیس': 1293, 'لشکر': 1294, 'کاری': 1295, 'نگیرد': 1296, 'چراست': 1297, 'بگشای': 1298, 'زال': 1299, 'شانه': 1300, 'مونس': 1301, 'ندانی': 1302, 'طوبی': 1303, 'ایم': 1304, 'سنگی': 1305, 'بلک': 1306, 'مباد': 1307, 'وصلت': 1308, 'برگشاید': 1309, 'پیاپی': 1310, 'گلوی': 1311, 'تخم': 1312, 'میل': 1313, 'دوستان': 1314, 'زندگانی': 1315, 'لها': 1316, 'خلیل': 1317, 'مایه': 1318, 'دریاب': 1319, 'جنبش': 1320, 'جفت': 1321, 'امکان': 1322, 'قاضی': 1323, 'عظیم': 1324, 'دریده': 1325, 'رویم': 1326, 'پیوند': 1327, 'قفص': 1328, 'لنا': 1329, 'اندک': 1330, 'بگذشت': 1331, 'فیه': 1332, 'ذاک': 1333, 'یوما': 1334, 'دوغ': 1335, 'ساده': 1336, 'منتها': 1337, 'آراسته': 1338, 'ماهت': 1339, 'فزون': 1340, 'فرشته': 1341, 'غلغله': 1342, 'شکری': 1343, 'منور': 1344, 'گویان': 1345, 'فردوس': 1346, 'بکا': 1347, 'گزید': 1348, 'برم': 1349, 'فرخ': 1350, 'سنبل': 1351, 'دلتنگ': 1352, 'مریخ': 1353, 'زمن': 1354, 'خنجر': 1355, 'زدن': 1356, 'سپر': 1357, 'افغان': 1358, 'بتر': 1359, 'پاینده': 1360, 'استیزه': 1361, 'ظلم': 1362, 'افتد': 1363, 'اخوان': 1364, 'نوبهار': 1365, 'اشکال': 1366, 'پیغام': 1367, 'خیزد': 1368, 'پار': 1369, 'گلگون': 1370, 'شیخ': 1371, 'محمد': 1372, 'فن': 1373, 'قاب': 1374, 'بردی': 1375, 'سرت': 1376, 'جوشد': 1377, 'افزون': 1378, 'بگرفت': 1379, 'خارها': 1380, 'عجل': 1381, 'فرمود': 1382, 'شیطان': 1383, 'قرص': 1384, 'کفی': 1385, 'سرسبز': 1386, 'چرخی': 1387, 'بشکسته': 1388, 'مها': 1389, 'نطق': 1390, 'مور': 1391, 'لابه': 1392, 'کاهل': 1393, 'وانگه': 1394, 'لرزان': 1395, 'ابتلا': 1396, 'فرد': 1397, 'غافل': 1398, 'مشغول': 1399, 'واسطه': 1400, 'دجال': 1401, 'علامت': 1402, 'سنایی': 1403, 'ایام': 1404, 'شمر': 1405, 'تکرار': 1406, 'دمدمه': 1407, 'بادی': 1408, 'افکند': 1409, 'پشه': 1410, 'شکستی': 1411, 'ناسزا': 1412, 'سیب': 1413, 'شهد': 1414, 'ماهیان': 1415, 'مما': 1416, 'اولی': 1417, 'شوره': 1418, 'شاباش': 1419, 'یوسفان': 1420, 'مبارک': 1421, 'عروسی': 1422, 'القلوب': 1423, 'رخی': 1424, 'روپوش': 1425, 'دوری': 1426, 'دستک': 1427, 'قلبی': 1428, 'حبه': 1429, 'السکر': 1430, 'دینار': 1431, 'بود': 1432, 'صحت': 1433, 'مفتعلن': 1434, 'سحری': 1435, 'زیانست': 1436, 'ملکت': 1437, 'جدایی': 1438, 'همدگر': 1439, 'نگاری': 1440, 'زبون': 1441, 'آنم': 1442, 'ملرز': 1443, 'بشد': 1444, 'ستان': 1445, 'زبانه': 1446, 'عاجز': 1447, 'رهیده': 1448, 'مگشا': 1449, 'بیافت': 1450, 'هفتمین': 1451, 'کباب': 1452, 'زندگی': 1453, 'پنبه': 1454, 'جوشش': 1455, 'عوض': 1456, 'نخورم': 1457, 'شکرستان': 1458, 'پنهانی': 1459, 'نتیجه': 1460, 'شرب': 1461, 'خرما': 1462, 'رمز': 1463, 'ظلمت': 1464, 'طالع': 1465, 'غیبی': 1466, 'فلا': 1467, 'جوان': 1468, 'برهنه': 1469, 'نشناسد': 1470, 'نقصان': 1471, 'ناید': 1472, 'قربان': 1473, 'ایثار': 1474, 'قصر': 1475, 'خواری': 1476, 'شکایت': 1477, 'آیت': 1478, 'کشاکش': 1479, 'پیام': 1480, 'سلطانی': 1481, 'عقلی': 1482, 'اسما': 1483, 'کاف': 1484, 'پرتو': 1485, 'نورت': 1486, 'صهبا': 1487, 'بکرد': 1488, 'نهم': 1489, 'سرنا': 1490, 'قبول': 1491, 'پوسیده': 1492, 'کشاند': 1493, 'بازآمد': 1494, 'قدحی': 1495, 'نیارد': 1496, 'خرابی': 1497, 'زاغ': 1498, 'وسوسه': 1499, 'طلعت': 1500, 'افسون': 1501, 'گاو': 1502, 'فغان': 1503, 'احسنت': 1504, 'دشنام': 1505, 'پناه': 1506, 'سبوی': 1507, 'شسته': 1508, 'خمارم': 1509, 'تبارک': 1510, 'علالا': 1511, 'میالا': 1512, 'میندیش': 1513, 'دامست': 1514, 'حیاتست': 1515, 'دگرگون': 1516, 'ید': 1517, 'بباید': 1518, 'دلارام': 1519, 'اشیاء': 1520, 'خاست': 1521, 'مسلم': 1522, 'چست': 1523, 'لالا': 1524, 'سیاهی': 1525, 'شنیدی': 1526, 'کآتش': 1527, 'بمیرد': 1528, 'فرع': 1529, 'خندد': 1530, 'کلوخ': 1531, 'قوام': 1532, 'نهادی': 1533, 'شاهد': 1534, 'هندوی': 1535, 'بلند': 1536, 'مبر': 1537, 'محال': 1538, 'فکنده': 1539, 'کافر': 1540, 'سرکش': 1541, 'پرآتش': 1542, 'ایمنی': 1543, 'اگرت': 1544, 'دزدی': 1545, 'عزیز': 1546, 'سیمبر': 1547, 'نوای': 1548, 'چوب': 1549, 'بلبلان': 1550, 'شیرگیر': 1551, 'غرب': 1552, 'ثانی': 1553, 'حسنش': 1554, 'نشست': 1555, 'ران': 1556, 'گربه': 1557, 'بریزد': 1558, 'مطلق': 1559, 'شهریار': 1560, 'امتزاج': 1561, 'ظل': 1562, 'تعالوا': 1563, 'درآیی': 1564, 'هوسش': 1565, 'خلاص': 1566, 'آرم': 1567, 'شنیدم': 1568, 'وصف': 1569, 'نگوید': 1570, 'سلم': 1571, 'بازی': 1572, 'دهانم': 1573, 'نادر': 1574, 'کشیدم': 1575, 'وا': 1576, 'برگیر': 1577, 'زخمه': 1578, 'خزینه': 1579, 'ضرب': 1580, 'کشید': 1581, 'نصیب': 1582, 'چار': 1583, 'ظریف': 1584, 'تبریزیان': 1585, 'پوش': 1586, 'سوخت': 1587, 'زردی': 1588, 'ربی': 1589, 'مهتاب': 1590, 'طبیعت': 1591, 'عزم': 1592, 'مولانا': 1593, 'ببند': 1594, 'کلید': 1595, 'الروح': 1596, 'یارست': 1597, 'الغیب': 1598, 'فاذا': 1599, 'دولاب': 1600, 'برست': 1601, 'زرست': 1602, 'سرست': 1603, 'شکست': 1604, 'باخودی': 1605, 'کدامین': 1606, 'شکن': 1607, 'جداست': 1608, 'وفاست': 1609, 'افروخته': 1610, 'دغل': 1611, 'افکنی': 1612, 'کسان': 1613, 'قدس': 1614, 'پاکی': 1615, 'رفعت': 1616, 'بُدست': 1617, 'گله': 1618, 'سبق': 1619, 'ظن': 1620, 'کشش': 1621, 'بربست': 1622, 'شبان': 1623, 'بصر': 1624, 'فدای': 1625, 'پیشه': 1626, 'گزیدی': 1627, 'سور': 1628, 'منصور': 1629, 'بمانده': 1630, 'لگن': 1631, 'فتی': 1632, 'تنم': 1633, 'زحمت': 1634, 'ابله': 1635, 'غایب': 1636, 'بندد': 1637, 'لقب': 1638, 'فرست': 1639, 'همرنگ': 1640, 'حمله': 1641, 'پهلو': 1642, 'ماده': 1643, 'فارغ': 1644, 'محتشم': 1645, 'ساحل': 1646, 'افکنده': 1647, 'حجت': 1648, 'قرارم': 1649, 'میزبان': 1650, 'نانبا': 1651, 'گفتمی': 1652, 'نانی': 1653, 'افشان': 1654, 'چکد': 1655, 'ریز': 1656, 'پرباد': 1657, 'ریخته': 1658, 'بجه': 1659, 'بگذر': 1660, 'مقبل': 1661, 'ربا': 1662, 'هان': 1663, 'مستیم': 1664, 'نیش': 1665, 'ارزد': 1666, 'وش': 1667, 'جرس': 1668, 'مفرش': 1669, 'پران': 1670, 'گولخن': 1671, 'القضا': 1672, 'فرما': 1673, 'رسان': 1674, 'سلامی': 1675, 'بگردانی': 1676, 'هشیاری': 1677, 'سقایی': 1678, 'عقلست': 1679, 'کت': 1680, 'نون': 1681, 'منکری': 1682, 'دلان': 1683, 'آونگ': 1684, 'اه': 1685, 'شرف': 1686, 'کفت': 1687, 'عما': 1688, 'فرقت': 1689, 'کوتاه': 1690, 'شهنشه': 1691, 'حین': 1692, 'عالی': 1693, 'بشکافد': 1694, 'پیل': 1695, 'فرش': 1696, 'ابتدا': 1697, 'صیقل': 1698, 'مشتاق': 1699, 'عصای': 1700, 'رسوا': 1701, 'خویشان': 1702, 'هما': 1703, 'عینی': 1704, 'وسط': 1705, 'باقیش': 1706, 'گندمی': 1707, 'سرمه': 1708, 'توتیا': 1709, 'مولی': 1710, 'ریا': 1711, 'رانی': 1712, 'شفا': 1713, 'اشتری': 1714, 'قارون': 1715, 'کفن': 1716, 'مکافات': 1717, 'الرضا': 1718, 'مستفعلن': 1719, 'باب': 1720, 'قل': 1721, 'صحن': 1722, 'غوره': 1723, 'احد': 1724, 'بوالعجب': 1725, 'نورافشان': 1726, 'دررسد': 1727, 'کشند': 1728, 'اشکوفه': 1729, 'رای': 1730, 'هدیه': 1731, 'کامشب': 1732, 'پیمانه': 1733, 'سنان': 1734, 'حلوای': 1735, 'رجا': 1736, 'دورم': 1737, 'ذرات': 1738, 'الشمس': 1739, 'البدر': 1740, 'جنبان': 1741, 'شام': 1742, 'سغراق': 1743, 'مختار': 1744, 'افروز': 1745, 'سیلاب': 1746, 'دانم': 1747, 'نومی': 1748, 'خدایش': 1749, 'مسبب': 1750, 'شکاری': 1751, 'گلبن': 1752, 'جفای': 1753, 'قسم': 1754, 'گشا': 1755, 'نرم': 1756, 'کندش': 1757, 'رضای': 1758, 'بپرد': 1759, 'شنود': 1760, 'بوستان': 1761, 'برود': 1762, 'لطافت': 1763, 'کارگه': 1764, 'خسروی': 1765, 'صلای': 1766, 'نمک': 1767, 'گزین': 1768, 'نزار': 1769, 'مبین': 1770, 'کحل': 1771, 'مکش': 1772, 'حفظ': 1773, 'هبا': 1774, 'خفت': 1775, 'کرانه': 1776, 'دمم': 1777, 'بنموده': 1778, 'بکوب': 1779, 'مسکن': 1780, 'پرس': 1781, 'کافران': 1782, 'صفای': 1783, 'بزند': 1784, 'روحانی': 1785, 'ملاحت': 1786, 'پنداری': 1787, 'صنعت': 1788, 'نوشد': 1789, 'جاه': 1790, 'هاشان': 1791, 'دریابد': 1792, 'متاع': 1793, 'مهی': 1794, 'رایت': 1795, 'رهزن': 1796, 'ناری': 1797, 'سلیمانی': 1798, 'سرنای': 1799, 'سرگین': 1800, 'حکایت': 1801, 'رکن': 1802, 'لوط': 1803, 'آهم': 1804, 'حیلت': 1805, 'حلاوت': 1806, 'نقشی': 1807, 'وامق': 1808, 'فراغت': 1809, 'خرگه': 1810, 'ربانی': 1811, 'جوهر': 1812, 'آهسته': 1813, 'برجا': 1814, 'کردار': 1815, 'حی': 1816, 'افزا': 1817, 'مایی': 1818, 'درستی': 1819, 'پایم': 1820, 'مستم': 1821, 'الموتی': 1822, 'باور': 1823, 'ببخشد': 1824, 'فرستاد': 1825, 'صدق': 1826, 'ادب': 1827, 'مهتر': 1828, 'جوینده': 1829, 'نشوی': 1830, 'عسل': 1831, 'ویرانه': 1832, 'قراضه': 1833, 'احوال': 1834, 'کتاب': 1835, 'خطابی': 1836, 'درهم': 1837, 'اخ': 1838, 'جویان': 1839, 'نشکنی': 1840, 'خوردی': 1841, 'دمت': 1842, 'خیمه': 1843, 'استن': 1844, 'سوزان': 1845, 'پستی': 1846, 'حلواست': 1847, 'خضرا': 1848, 'خروش': 1849, 'شیرینی': 1850, 'بشتاب': 1851, 'باک': 1852, 'درانداز': 1853, 'زیباست': 1854, 'شکرریز': 1855, 'خیالش': 1856, 'مایده': 1857, 'آفت': 1858, 'بیضا': 1859, 'گریزی': 1860, 'خبرش': 1861, 'تمنا': 1862, 'عشوه': 1863, 'برآور': 1864, 'مصفا': 1865, 'صبحی': 1866, 'بگفتم': 1867, 'درآرد': 1868, 'خواهد': 1869, 'لایزالی': 1870, 'سکون': 1871, 'بویی': 1872, 'دون': 1873, 'سرای': 1874, 'نیاز': 1875, 'جعفری': 1876, 'ذکر': 1877, 'تکبر': 1878, 'حاشا': 1879, 'گردم': 1880, 'کارم': 1881, 'بدیدی': 1882, 'پرخون': 1883, 'براق': 1884, 'زاری': 1885, 'چارم': 1886, 'تقدیر': 1887, 'محابا': 1888, 'خویشی': 1889, 'نشانه': 1890, 'سازم': 1891, 'ساقیان': 1892, 'حسرت': 1893, 'مهان': 1894, 'داستان': 1895, 'ندیدم': 1896, 'دره': 1897, 'ببسته': 1898, 'نبیذ': 1899, 'بگفته': 1900, 'درونه': 1901, 'عاقلان': 1902, 'غارت': 1903, 'ایرا': 1904, 'آلود': 1905, 'سیف': 1906, 'سگان': 1907, 'تنت': 1908, 'خاره': 1909, 'بوده': 1910, 'شفاعت': 1911, 'شرمسار': 1912, 'خرگاه': 1913, 'درگاه': 1914, 'مدح': 1915, 'رهد': 1916, 'پذیرد': 1917, 'ویست': 1918, 'نوازد': 1919, 'گوشت': 1920, 'سپار': 1921, 'نیکی': 1922, 'واقفم': 1923, 'غافلم': 1924, 'پرور': 1925, 'حقا': 1926, 'تسبیع': 1927, 'کشیدن': 1928, 'جویم': 1929, 'کهی': 1930, 'رفتن': 1931, 'نگران': 1932, 'بکشید': 1933, 'عقیق': 1934, 'نرسد': 1935, 'زمستان': 1936, 'ناخوش': 1937, 'عنصر': 1938, 'پرگار': 1939, 'بگفتی': 1940, 'بنشست': 1941, 'کجایی': 1942, 'آشنایی': 1943, 'آیین': 1944, 'زهد': 1945, 'خلد': 1946, 'خورند': 1947, 'نر': 1948, 'بپرس': 1949, 'باشد': 1950, 'فسرده': 1951, 'رسیدم': 1952, 'لطفت': 1953, 'رایگانست': 1954, 'مگس': 1955, 'نبشته': 1956, 'سبو': 1957, 'دفتر': 1958, 'پاسبان': 1959, 'همو': 1960, 'باغی': 1961, 'ایمن': 1962, 'مکه': 1963, 'مجموع': 1964, 'نظم': 1965, 'گیاه': 1966, 'بنفشه': 1967, 'نشوم': 1968, 'ضعیف': 1969, 'اضطراب': 1970, 'ناودان': 1971, 'تماشای': 1972, 'نزل': 1973, 'نقره': 1974, 'بنوش': 1975, 'سپاه': 1976, 'حوا': 1977, 'سزاست': 1978, 'ملاقات': 1979, 'طیار': 1980, 'توایم': 1981, 'قراری': 1982, 'هواست': 1983, 'وام': 1984, 'فقیر': 1985, 'قانع': 1986, 'لبش': 1987, 'ضد': 1988, 'جلا': 1989, 'شنو': 1990, 'بسوز': 1991, 'کیمیاست': 1992, 'لمن': 1993, 'فراموش': 1994, 'تنتن': 1995, 'فیما': 1996, 'راح': 1997, 'شکرا': 1998, 'ساعه': 1999, 'فضله': 2000, 'انت': 2001, 'نحو': 2002, 'بحری': 2003, 'ازرق': 2004, 'چادر': 2005, 'مباش': 2006, 'سحاب': 2007, 'تتق': 2008, 'میقات': 2009, 'قاعده': 2010, 'آمده': 2011, 'شهری': 2012, 'روزست': 2013, 'طرار': 2014, 'شخص': 2015, 'خاکست': 2016, 'مدرسه': 2017, 'رسواست': 2018, 'امامست': 2019, 'نظامست': 2020, 'هاش': 2021, 'پاچه': 2022, 'یاسمن': 2023, 'سست': 2024, 'نجات': 2025, 'ثبات': 2026, 'ظالم': 2027, 'قفاست': 2028, 'جوست': 2029, 'لقاست': 2030, 'واجب': 2031, 'گنه': 2032, 'احب': 2033, 'سرنگون': 2034, 'خال': 2035, 'خارم': 2036, 'مثقال': 2037, 'افعال': 2038, 'حالی': 2039, 'زلزله': 2040, 'شفق': 2041, 'طغرای': 2042, 'فال': 2043, 'دال': 2044, 'اعمال': 2045, 'اجمال': 2046, 'انبان': 2047, 'درخورد': 2048, 'خربنده': 2049, 'سمن': 2050, 'آتشکده': 2051, 'کاروان': 2052, 'پیروز': 2053, 'آیم': 2054, 'صباح': 2055, 'سرهنگ': 2056, 'گنگ': 2057, 'بوک': 2058, 'خوبت': 2059, 'ادا': 2060, 'پیرهن': 2061, 'پیچیده': 2062, 'آشنایان': 2063, 'سیلی': 2064, 'فوت': 2065, 'سنبله': 2066, 'مهم': 2067, 'نشنود': 2068, 'افزای': 2069, 'برریز': 2070, 'دستگیر': 2071, 'کنجی': 2072, 'نغمه': 2073, 'غلغل': 2074, 'خیک': 2075, 'نفخه': 2076, 'جویبار': 2077, 'گریز': 2078, 'لعلین': 2079, 'عرق': 2080, 'میمون': 2081, 'شرر': 2082, 'غوطه': 2083, 'پزد': 2084, 'بربود': 2085, 'برکند': 2086, 'تشریف': 2087, 'تریاق': 2088, 'دلق': 2089, 'صدپاره': 2090, 'قیر': 2091, 'برنا': 2092, 'قوس': 2093, 'قرب': 2094, 'ادنی': 2095, 'نادی': 2096, 'شرط': 2097, 'پویان': 2098, 'فتحنا': 2099, 'خیالی': 2100, 'چندانک': 2101, 'مکوب': 2102, 'ورد': 2103, 'وادی': 2104, 'عصمت': 2105, 'جنبد': 2106, 'حله': 2107, 'عشر': 2108, 'لبیک': 2109, 'راند': 2110, 'فرسنگ': 2111, 'بارد': 2112, 'رهوار': 2113, 'اومید': 2114, 'الطاف': 2115, 'بنگرم': 2116, 'بازگرد': 2117, 'واله': 2118, 'پادشا': 2119, 'اندرآمد': 2120, 'منع': 2121, 'نالد': 2122, 'سمین': 2123, 'عنقای': 2124, 'منقار': 2125, 'تنی': 2126, 'ماندم': 2127, 'شطرنج': 2128, 'واصل': 2129, 'عطار': 2130, 'نورش': 2131, 'اندوه': 2132, 'خنبک': 2133, 'ماری': 2134, 'انی': 2135, 'الینا': 2136, 'پایت': 2137, 'جزا': 2138, 'چوبین': 2139, 'بردم': 2140, 'مطلوب': 2141, 'دعاگو': 2142, 'عرضه': 2143, 'نادیده': 2144, 'کهن': 2145, 'کاره': 2146, 'تبش': 2147, 'کنج': 2148, 'خلا': 2149, 'قیصر': 2150, 'پوشد': 2151, 'مل': 2152, 'راهش': 2153, 'شید': 2154, 'وارهد': 2155, 'بحرش': 2156, 'سکن': 2157, 'خوردند': 2158, 'نوی': 2159, 'داماد': 2160, 'استخوان': 2161, 'رقصی': 2162, 'بوالعلی': 2163, 'بوالعلا': 2164, 'درج': 2165, 'فرج': 2166, 'برکن': 2167, 'ولایت': 2168, 'مستش': 2169, 'زوتر': 2170, 'گرمی': 2171, 'خران': 2172, 'ناگاهان': 2173, 'تره': 2174, 'الوصل': 2175, 'اکرم': 2176, 'رویان': 2177, 'سرخوشان': 2178, 'دامان': 2179, 'پیکار': 2180, 'حجره': 2181, 'تندی': 2182, 'قافیه': 2183, 'خرابم': 2184, 'گوینده': 2185, 'رسدم': 2186, 'رخان': 2187, 'شکرین': 2188, 'تاتار': 2189, 'بطلب': 2190, 'حامله': 2191, 'دیدست': 2192, 'مددا': 2193, 'پرورش': 2194, 'سره': 2195, 'نرد': 2196, 'ورق': 2197, 'مران': 2198, 'عزت': 2199, 'صورتی': 2200, 'دهدت': 2201, 'کری': 2202, 'کآب': 2203, 'ریگ': 2204, 'سوزن': 2205, 'مس': 2206, 'نیزه': 2207, 'کاس': 2208, 'نهفته': 2209, 'دریچه': 2210, 'برسد': 2211, 'تافت': 2212, 'تشنگان': 2213, 'بساط': 2214, 'وفای': 2215, 'کوثری': 2216, 'عقار': 2217, 'نروم': 2218, 'بشو': 2219, 'بلاها': 2220, 'مخور': 2221, 'رزم': 2222, 'استسقا': 2223, 'پوشیده': 2224, 'لوح': 2225, 'درس': 2226, 'گشتند': 2227, 'عطارد': 2228, 'آسمانی': 2229, 'وحدت': 2230, 'خس': 2231, 'مسلمانان': 2232, 'خاری': 2233, 'خداوندا': 2234, 'لطفش': 2235, 'ازیرا': 2236, 'دستست': 2237, 'قاصد': 2238, 'ایوان': 2239, 'کوهی': 2240, 'پایی': 2241, 'پراکنده': 2242, 'بختی': 2243, 'کفایت': 2244, 'شاخی': 2245, 'تنگی': 2246, 'غایت': 2247, 'اعمی': 2248, 'فریب': 2249, 'مصری': 2250, 'صیادی': 2251, 'فایق': 2252, 'زهرا': 2253, 'پیغامبر': 2254, 'سوزد': 2255, 'مپرس': 2256, 'نقاش': 2257, 'شاهنشه': 2258, 'حورا': 2259, 'مرغی': 2260, 'اینت': 2261, 'جلالی': 2262, 'سخره': 2263, 'مخوان': 2264, 'خامی': 2265, 'جانانه': 2266, 'دربند': 2267, 'پیما': 2268, 'نمایی': 2269, 'قدسی': 2270, 'جامش': 2271, 'تعیین': 2272, 'عقلم': 2273, 'آهو': 2274, 'دستش': 2275, 'ترسم': 2276, 'اعدا': 2277, 'حیاتی': 2278, 'نباتی': 2279, 'درختان': 2280, 'بشارت': 2281, 'شقایق': 2282, 'نبودی': 2283, 'تب': 2284, 'میخانه': 2285, 'مگریز': 2286, 'مفلس': 2287, 'ژنده': 2288, 'مشرق': 2289, 'کرمش': 2290, 'بریان': 2291, 'آریم': 2292, 'مشکات': 2293, 'عرصه': 2294, 'بقایی': 2295, 'بوسد': 2296, 'سحابی': 2297, 'بربای': 2298, 'نقابی': 2299, 'نومیدی': 2300, 'جغد': 2301, 'گلرخ': 2302, 'فکن': 2303, 'بوبکر': 2304, 'ربابی': 2305, 'خرف': 2306, 'آگاه': 2307, 'پیشین': 2308, 'نکشد': 2309, 'بالین': 2310, 'سستی': 2311, 'معشوقه': 2312, 'سامان': 2313, 'بستی': 2314, 'سرده': 2315, 'شاهانه': 2316, 'فتوح': 2317, 'فراوان': 2318, 'گرگ': 2319, 'مسلمان': 2320, 'سودی': 2321, 'طعنه': 2322, 'فرخنده': 2323, 'پرند': 2324, 'نایی': 2325, 'برنایی': 2326, 'ببندی': 2327, 'کاسد': 2328, 'حمرا': 2329, 'زدیم': 2330, 'ناظر': 2331, 'خاتم': 2332, 'زمزم': 2333, 'دارو': 2334, 'غلطان': 2335, 'خاقان': 2336, 'امینی': 2337, 'بپالا': 2338, 'برستی': 2339, 'نغزست': 2340, 'خوبست': 2341, 'نهانست': 2342, 'درافتاد': 2343, 'غوغاست': 2344, 'نورست': 2345, 'دخل': 2346, 'ثریاست': 2347, 'سواران': 2348, 'فتادیم': 2349, 'نقشیست': 2350, 'حدث': 2351, 'حدثی': 2352, 'فروبند': 2353, 'گام': 2354, 'الکاس': 2355, 'بتی': 2356, 'سهیل': 2357, 'زبر': 2358, 'موثر': 2359, 'طلبد': 2360, 'دگری': 2361, 'لبی': 2362, 'اسم': 2363, 'صبوحی': 2364, 'ترشی': 2365, 'ندیدست': 2366, 'بخشید': 2367, 'نپرم': 2368, 'طشت': 2369, 'بازآرد': 2370, 'سقف': 2371, 'واقف': 2372, 'ستون': 2373, 'برآر': 2374, 'مغرب': 2375, 'مهتری': 2376, 'گذارد': 2377, 'بردار': 2378, 'دررو': 2379, 'فرورفت': 2380, 'معلا': 2381, 'بویش': 2382, 'مصطفا': 2383, 'کشیدی': 2384, 'بان': 2385, 'ترنگ': 2386, 'اغانی': 2387, 'عیدی': 2388, 'عیدست': 2389, 'اکبر': 2390, 'قوی': 2391, 'مگویید': 2392, 'شاهدان': 2393, 'انبیا': 2394, 'کلیدی': 2395, 'ترنج': 2396, 'منشور': 2397, 'یاسمین': 2398, 'جبین': 2399, 'ساقیست': 2400, 'ببرده': 2401, 'سخاوت': 2402, 'خرج': 2403, 'بجوشد': 2404, 'اله': 2405, 'کیش': 2406, 'مخزن': 2407, 'ببستی': 2408, 'طلسم': 2409, 'سبحان': 2410, 'رواقی': 2411, 'فلانی': 2412, 'فلانه': 2413, 'بدل': 2414, 'ترکی': 2415, 'غنی': 2416, 'ساکنی': 2417, 'همسایه': 2418, 'روانی': 2419, 'روانه': 2420, 'لک': 2421, 'دوار': 2422, 'درها': 2423, 'لاغری': 2424, 'صور': 2425, 'رحیق': 2426, 'قدیم': 2427, 'شریف': 2428, 'پادشاهی': 2429, 'بنگرید': 2430, 'بنهاد': 2431, 'فرق': 2432, 'کمال': 2433, 'رمزی': 2434, 'کارها': 2435, 'بازاری': 2436, 'آفتابت': 2437, 'افکن': 2438, 'داوود': 2439, 'مشتاقان': 2440, 'سرمدی': 2441, 'مانی': 2442, 'ریزد': 2443, 'همای': 2444, 'دیدمش': 2445, 'سنجر': 2446, 'جهانست': 2447, 'چراگاه': 2448, 'چتر': 2449, 'حذر': 2450, 'نجویی': 2451, 'ترازو': 2452, 'گهواره': 2453, 'فتاده': 2454, 'فراقت': 2455, 'نال': 2456, 'بیضه': 2457, 'برپرد': 2458, 'دستت': 2459, 'پات': 2460, 'سوار': 2461, 'بندت': 2462, 'نپنداری': 2463, 'رکاب': 2464, 'رغبت': 2465, 'بگردد': 2466, 'طاووس': 2467, 'بارت': 2468, 'عزیزی': 2469, 'کنارت': 2470, 'عادت': 2471, 'ریخت': 2472, 'خرابه': 2473, 'صومعه': 2474, 'ایها': 2475, 'العشاق': 2476, 'بصیرت': 2477, 'نخوت': 2478, 'آتشست': 2479, 'اندرون': 2480, 'قدرت': 2481, 'شهید': 2482, 'مقتدا': 2483, 'نبوده': 2484, 'شعاع': 2485, 'روحش': 2486, 'روحست': 2487, 'رکوع': 2488, 'ثنای': 2489, 'مراتب': 2490, 'فخرست': 2491, 'مزور': 2492, 'ببندد': 2493, 'بتابد': 2494, 'خبری': 2495, 'گیرا': 2496, 'فرود': 2497, 'کریم': 2498, 'صنمی': 2499, 'خرامد': 2500, 'عذار': 2501, 'ابدا': 2502, 'سپه': 2503, 'نمایند': 2504, 'یحیی': 2505, 'جود': 2506, 'لوا': 2507, 'کربلایی': 2508, 'مبا': 2509, 'عاشقا': 2510, 'فشان': 2511, 'سرها': 2512, 'مکار': 2513, 'گفتنت': 2514, 'خسروان': 2515, 'سبا': 2516, 'شکفته': 2517, 'قیمت': 2518, 'اصلی': 2519, 'کودکان': 2520, 'لحد': 2521, 'صفی': 2522, 'پریان': 2523, 'حس': 2524, 'تصور': 2525, 'گلیم': 2526, 'پیاده': 2527, 'باخبر': 2528, 'راهی': 2529, 'آمین': 2530, 'واقعه': 2531, 'مرید': 2532, 'فراخ': 2533, 'ربود': 2534, 'حلال': 2535, 'رسند': 2536, 'ارغوان': 2537, 'پیک': 2538, 'خفاش': 2539, 'نهیم': 2540, 'حریر': 2541, 'تیزپا': 2542, 'تنست': 2543, 'آشکار': 2544, 'ناچار': 2545, 'نگشت': 2546, 'منزلی': 2547, 'نشینی': 2548, 'سرگشته': 2549, 'مدرس': 2550, 'ذوالفقار': 2551, 'برقرار': 2552, 'لباس': 2553, 'پسر': 2554, 'هدی': 2555, 'آرزو': 2556, 'وصالش': 2557, 'التفات': 2558, 'ببارد': 2559, 'حجب': 2560, 'خرامان': 2561, 'فرمان': 2562, 'قمرا': 2563, 'الدجی': 2564, 'ربوده': 2565, 'احیا': 2566, 'برآورد': 2567, 'الاعلی': 2568, 'نگین': 2569, 'اجزا': 2570, 'مرسل': 2571, 'ملول': 2572, 'جاودان': 2573, 'زید': 2574, 'کندت': 2575, 'نحن': 2576, 'صدفی': 2577, 'یگانه': 2578, 'فتادی': 2579, 'متی': 2580, 'رهش': 2581, 'خجسته': 2582, 'گفته': 2583, 'متصل': 2584, 'اوفتاد': 2585, 'بدند': 2586, 'راغ': 2587, 'آیتی': 2588, 'نیت': 2589, 'تای': 2590, 'گویمش': 2591, 'کبوتر': 2592, 'کشف': 2593, 'کژی': 2594, 'غمی': 2595, 'نخل': 2596, 'فکرتی': 2597, 'ختم': 2598, 'جانانست': 2599, 'دمید': 2600, 'دمش': 2601, 'جنه': 2602, 'نرهد': 2603, 'هوایی': 2604, 'خوردست': 2605, 'السما': 2606, 'نوره': 2607, 'مثله': 2608, 'غیره': 2609, 'تسبیح': 2610, 'عام': 2611, 'رسی': 2612, 'درگه': 2613, 'پابند': 2614, 'دردانه': 2615, 'افسانه': 2616, 'فرزانه': 2617, 'حنانه': 2618, 'دروغ': 2619, 'انگشت': 2620, 'دلشده': 2621, 'تجری': 2622, 'محسن': 2623, 'الموت': 2624, 'فوادی': 2625, 'کاسا': 2626, 'لاح': 2627, 'لما': 2628, 'شعشاع': 2629, 'بالله': 2630, 'البلا': 2631, 'حل': 2632, 'الیوم': 2633, 'سماوات': 2634, 'فبلا': 2635, 'سکرنا': 2636, 'ضریر': 2637, 'اذ': 2638, 'سیدا': 2639, 'الناس': 2640, 'لکم': 2641, 'اوطانا': 2642, 'خاب': 2643, 'ریاض': 2644, 'خفتند': 2645, 'بحمدالله': 2646, 'شکرلب': 2647, 'ابواب': 2648, 'پود': 2649, 'صواب': 2650, 'فتح': 2651, 'ویند': 2652, 'صلوات': 2653, 'فراش': 2654, 'روشنست': 2655, 'گردنست': 2656, 'الکنست': 2657, 'ترست': 2658, 'گوارش': 2659, 'خونم': 2660, 'مسخره': 2661, 'ننهد': 2662, 'پایش': 2663, 'زنگی': 2664, 'بازست': 2665, 'هفتاد': 2666, 'دعاست': 2667, 'انتظار': 2668, 'جالینوس': 2669, 'منزلست': 2670, 'رمیده': 2671, 'آزار': 2672, 'گنجی': 2673, 'آفات': 2674, 'شهمات': 2675, 'ترکش': 2676, 'کمینه': 2677, 'بنشان': 2678, 'بهای': 2679, 'سیماست': 2680, 'تمامست': 2681, 'مدامست': 2682, 'لثامست': 2683, 'سلامست': 2684, 'پیامست': 2685, 'غلامست': 2686, 'ختامست': 2687, 'زمامست': 2688, 'فطامست': 2689, 'لگامست': 2690, 'زلفین': 2691, 'غمخوار': 2692, 'افزاست': 2693, 'تنهاست': 2694, 'تعبیه': 2695, 'روست': 2696, 'نخوهم': 2697, 'بقای': 2698, 'وفات': 2699, 'بنین': 2700, 'بنات': 2701, 'جهات': 2702, 'دوستی': 2703, 'نشستم': 2704, 'حاصلست': 2705, 'مایلست': 2706, 'تواضع': 2707, 'بخوردی': 2708, 'غرامت': 2709, 'لرزد': 2710, 'تف': 2711, 'سوخته': 2712, 'غمگین': 2713, 'شادان': 2714, 'نامبارک': 2715, 'مکری': 2716, 'بداد': 2717, 'شوی': 2718, 'سماست': 2719, 'باقیست': 2720, 'صفاست': 2721, 'خوست': 2722, 'موست': 2723, 'تهیست': 2724, 'ختن': 2725, 'رستخیز': 2726, 'حاجب': 2727, 'شوربا': 2728, 'کاغذ': 2729, 'فزوده': 2730, 'الافلین': 2731, 'تمثال': 2732, 'غمت': 2733, 'بشکافته': 2734, 'تبع': 2735, 'سیدی': 2736, 'اجلال': 2737, 'زلزال': 2738, 'شال': 2739, 'رقعه': 2740, 'دلیل': 2741, 'استدلال': 2742, 'تفصیل': 2743, 'پُر': 2744, 'خلاف': 2745, 'چشش': 2746, 'تلخت': 2747, 'ترسان': 2748, 'بنال': 2749, 'بانک': 2750, 'بستست': 2751, 'ترم': 2752, 'نابینا': 2753, 'عمی': 2754, 'بایزید': 2755, 'بایزیدش': 2756, 'جوشی': 2757, 'برمی': 2758, 'خوابت': 2759, 'بگریز': 2760, 'برشکن': 2761, 'فراخی': 2762, 'جره': 2763, 'بربط': 2764, 'تو': 2765, 'اسحاق': 2766, 'نشکند': 2767, 'برجوشد': 2768, 'قرن': 2769, 'خل': 2770, 'شهسوار': 2771, 'حشم': 2772, 'خرام': 2773, 'منقطع': 2774, 'مفلسان': 2775, 'لبت': 2776, 'آموزد': 2777, 'نیستان': 2778, 'رخم': 2779, 'مردن': 2780, 'گفتنی': 2781, 'طامع': 2782, 'گوا': 2783, 'بم': 2784, 'فرهاد': 2785, 'دردم': 2786, 'محبوس': 2787, 'موقوف': 2788, 'دلبران': 2789, 'پاکتر': 2790, 'ماستی': 2791, 'چاکر': 2792, 'گلشکر': 2793, 'پیامت': 2794, 'پرها': 2795, 'مشکین': 2796, 'نیارم': 2797, 'تابد': 2798, 'کله': 2799, 'طالبان': 2800, 'شکافد': 2801, 'اخضر': 2802, 'عبهر': 2803, 'خورده': 2804, 'باغبان': 2805, 'باخویش': 2806, 'درفشان': 2807, 'سلطانان': 2808, 'طارم': 2809, 'مینا': 2810, 'روزم': 2811, 'سینا': 2812, 'داده': 2813, 'تیری': 2814, 'شاها': 2815, 'الامین': 2816, 'مکین': 2817, 'اقصی': 2818, 'اهلا': 2819, 'سهلا': 2820, 'زندانیان': 2821, 'بنهم': 2822, 'آوارگی': 2823, 'گنده': 2824, 'مرحله': 2825, 'همنفس': 2826, 'خلقی': 2827, 'گستاخ': 2828, 'رسولی': 2829, 'گریزان': 2830, 'رد': 2831, 'لطیفی': 2832, 'مرنجان': 2833, 'حجر': 2834, 'گرمابه': 2835, 'غزا': 2836, 'خارپشت': 2837, 'رستی': 2838, 'ساکن': 2839, 'ضاق': 2840, 'الفضا': 2841, 'صابران': 2842, 'جرمی': 2843, 'نتان': 2844, 'یی': 2845, 'اسد': 2846, 'پارسا': 2847, 'ری': 2848, 'بننماید': 2849, 'برکنم': 2850, 'سنگین': 2851, 'بدیدندی': 2852, 'نشاط': 2853, 'زارت': 2854, 'فرهنگ': 2855, 'رفتنی': 2856, 'خسپد': 2857, 'معذور': 2858, 'سنا': 2859, 'فم': 2860, 'صدف': 2861, 'سیاره': 2862, 'شاهنشاه': 2863, 'سلطنت': 2864, 'بربوده': 2865, 'ترتیب': 2866, 'مجتبا': 2867, 'کارزد': 2868, 'چشمان': 2869, 'ذوفنون': 2870, 'تعلیم': 2871, 'بخیزد': 2872, 'نگارین': 2873, 'درنیابد': 2874, 'جبریل': 2875, 'عنکبوت': 2876, 'حرون': 2877, 'رسم': 2878, 'لازم': 2879, 'نگفتم': 2880, 'غنیمت': 2881, 'چاکرت': 2882, 'نبودش': 2883, 'مجنبان': 2884, 'دودش': 2885, 'بنگری': 2886, 'صفیر': 2887, 'برخوان': 2888, 'بازیچه': 2889, 'همیان': 2890, 'ژاژخا': 2891, 'آفتی': 2892, 'بدهد': 2893, 'درم': 2894, 'موسیی': 2895, 'عزا': 2896, 'اشکسته': 2897, 'زعفرانی': 2898, 'زخمی': 2899, 'غمازه': 2900, 'تیرش': 2901, 'عجبتر': 2902, 'مدهوش': 2903, 'مخلص': 2904, 'هلکنا': 2905, 'بعدکم': 2906, 'ویلنا': 2907, 'ممتحن': 2908, 'النوی': 2909, 'شکستست': 2910, 'انسان': 2911, 'زلیخا': 2912, 'بگریخت': 2913, 'گفتش': 2914, 'غالب': 2915, 'باریک': 2916, 'مغلطه': 2917, 'کیستم': 2918, 'معلوم': 2919, 'دانیش': 2920, 'تعجیل': 2921, 'مبتلا': 2922, 'لکل': 2923, 'کژدم': 2924, 'حبوب': 2925, 'گون': 2926, 'سوش': 2927, 'تلوین': 2928, 'وبا': 2929, 'خنب': 2930, 'بکم': 2931, 'الشکر': 2932, 'جرار': 2933, 'تابستان': 2934, 'برزند': 2935, 'جسد': 2936, 'بدری': 2937, 'بهره': 2938, 'جزوها': 2939, 'نوایی': 2940, 'بشکفته': 2941, 'پگه': 2942, 'خماران': 2943, 'ببرید': 2944, 'سیمای': 2945, 'النفوس': 2946, 'مولای': 2947, 'جویای': 2948, 'تصرف': 2949, 'عارفان': 2950, 'کالای': 2951, 'مد': 2952, 'حمرای': 2953, 'بستند': 2954, 'قومی': 2955, 'شاهراه': 2956, 'ساغری': 2957, 'جوشیده': 2958, 'نوشش': 2959, 'سرخوش': 2960, 'بازش': 2961, 'بنشناسم': 2962, 'آبم': 2963, 'آسایش': 2964, 'خوابم': 2965, 'خونبها': 2966, 'خضرای': 2967, 'دمن': 2968, 'خیالات': 2969, 'حارس': 2970, 'برقی': 2971, 'برزده': 2972, 'صراف': 2973, 'مصباح': 2974, 'الحشا': 2975, 'الغشا': 2976, 'مشا': 2977, 'سایلی': 2978, 'التجلی': 2979, 'افنی': 2980, 'الکری': 2981, 'اندیش': 2982, 'خاموشان': 2983, 'ستار': 2984, 'مفلسانیم': 2985, 'کاهلانیم': 2986, 'خفتگانیم': 2987, 'خستگانیم': 2988, 'خرابیم': 2989, 'معمار': 2990, 'واپس': 2991, 'جوابم': 2992, 'هرچ': 2993, 'وادهد': 2994, 'کهیم': 2995, 'شکربار': 2996, 'آغشته': 2997, 'شد': 2998, 'ناگفته': 2999, 'فاتح': 3000, 'دریوزه': 3001, 'نبدی': 3002, 'درخور': 3003, 'شعرا': 3004, 'نغز': 3005, 'سخنم': 3006, 'کشدم': 3007, 'ترلللا': 3008, 'مقالات': 3009, 'نظرش': 3010, 'پرسش': 3011, 'شکرش': 3012, 'گرفتار': 3013, 'دستگه': 3014, 'شکند': 3015, 'خریدار': 3016, 'اسلام': 3017, 'آبله': 3018, 'جامع': 3019, 'مشغله': 3020, 'زنگله': 3021, 'نبد': 3022, 'بدا': 3023, 'هیج': 3024, 'سببی': 3025, 'پابسته': 3026, 'کینه': 3027, 'جوع': 3028, 'بخوری': 3029, 'نمیرد': 3030, 'کارگزاری': 3031, 'شبم': 3032, 'فلسفی': 3033, 'بپرورد': 3034, 'فردی': 3035, 'جزوی': 3036, 'صفتی': 3037, 'هوسی': 3038, 'مترس': 3039, 'خواندم': 3040, 'تپش': 3041, 'بخورد': 3042, 'شنوی': 3043, 'درزی': 3044, 'جهد': 3045, 'ریسمان': 3046, 'بارگه': 3047, 'عرب': 3048, 'خدمتی': 3049, 'کما': 3050, 'بشوی': 3051, 'ستم': 3052, 'چشیده': 3053, 'فزود': 3054, 'نورسیده': 3055, 'گزد': 3056, 'چکیده': 3057, 'خمیده': 3058, 'پریده': 3059, 'مفاعلن': 3060, 'برنهد': 3061, 'خفا': 3062, 'روترشی': 3063, 'کردنا': 3064, 'ملولی': 3065, 'هستیی': 3066, 'زینت': 3067, 'مومنان': 3068, 'دویدم': 3069, 'ماها': 3070, 'قباها': 3071, 'الهام': 3072, 'پشیمانی': 3073, 'اند': 3074, 'کشانندت': 3075, 'بپر': 3076, 'پوشی': 3077, 'تمر': 3078, 'رنگت': 3079, 'ایما': 3080, 'حواله': 3081, 'زلت': 3082, 'رق': 3083, 'نوشند': 3084, 'فکرت': 3085, 'براندازد': 3086, 'عبارت': 3087, 'عبرت': 3088, 'معنوی': 3089, 'عروسان': 3090, 'قیاس': 3091, 'نصرت': 3092, 'سبع': 3093, 'دزدد': 3094, 'عذب': 3095, 'نبغی': 3096, 'لقیت': 3097, 'عطشانا': 3098, 'عریانا': 3099, 'هوشیاری': 3100, 'سپردن': 3101, 'سپاری': 3102, 'کاهی': 3103, 'نزدیکست': 3104, 'هدهد': 3105, 'نالی': 3106, 'پرپست': 3107, 'فرومانی': 3108, 'خوکی': 3109, 'وقایت': 3110, 'دونان': 3111, 'حمایت': 3112, 'نهادستی': 3113, 'خوش': 3114, 'صنعتی': 3115, 'ویرانم': 3116, 'حیرانم': 3117, 'واپرسم': 3118, 'اینم': 3119, 'خرگاهم': 3120, 'وقفم': 3121, 'خموشی': 3122, 'مستعد': 3123, 'قیام': 3124, 'سقاهم': 3125, 'ربهم': 3126, 'مجمر': 3127, 'بنیاد': 3128, 'منقاد': 3129, 'سیری': 3130, 'قاهر': 3131, 'عذابست': 3132, 'شکنجه': 3133, 'برشد': 3134, 'مقامی': 3135, 'بربسته': 3136, 'فروکش': 3137, 'شکرریزی': 3138, 'نامی': 3139, 'مهل': 3140, 'خاصت': 3141, 'عامی': 3142, 'نادانی': 3143, 'بافد': 3144, 'دامی': 3145, 'القاب': 3146, 'کلامی': 3147, 'پیامی': 3148, 'ساغرم': 3149, 'غلامی': 3150, 'باحسن': 3151, 'ابرو': 3152, 'پستست': 3153, 'کرسی': 3154, 'نجهد': 3155, 'نشستست': 3156, 'شصت': 3157, 'طومار': 3158, 'خدیو': 3159, 'بلندی': 3160, 'انگیز': 3161, 'فزای': 3162, 'ز': 3163, 'زیست': 3164, 'اسیران': 3165, 'حمل': 3166, 'شعاعش': 3167, 'بدخشان': 3168, 'یاقوت': 3169, 'ذاتش': 3170, 'خماری': 3171, 'جسمانی': 3172, 'شاکر': 3173, 'برآوردی': 3174, 'خطه': 3175, 'حیوانست': 3176, 'بردست': 3177, 'ماتست': 3178, 'کوبد': 3179, 'مهار': 3180, 'اشتران': 3181, 'بازد': 3182, 'فطرت': 3183, 'بنماید': 3184, 'بیننده': 3185, 'جلالت': 3186, 'خوشدل': 3187, 'نوشی': 3188, 'درسوز': 3189, 'بشنید': 3190, 'خوردن': 3191, 'زجاجه': 3192, 'فزایی': 3193, 'همایی': 3194, 'عصایی': 3195, 'انصافست': 3196, 'بنمی': 3197, 'وفایی': 3198, 'سمایی': 3199, 'کبابی': 3200, 'همکاسه': 3201, 'نابی': 3202, 'هوشی': 3203, 'غرابی': 3204, 'دیوارم': 3205, 'بط': 3206, 'بررسته': 3207, 'تا': 3208, 'انگوری': 3209, 'یاسین': 3210, 'بستر': 3211, 'سلاطین': 3212, 'دسته': 3213, 'ملکی': 3214, 'شومی': 3215, 'درخشان': 3216, 'رمید': 3217, 'جهل': 3218, 'درآمیزی': 3219, 'ابلیس': 3220, 'برافزودی': 3221, 'رنگستش': 3222, 'منیر': 3223, 'خسبد': 3224, 'برسان': 3225, 'برکش': 3226, 'درافتاده': 3227, 'کمربسته': 3228, 'درازش': 3229, 'نازش': 3230, 'رهبر': 3231, 'اقبالت': 3232, 'نقص': 3233, 'دافع': 3234, 'انگیخته': 3235, 'ننشاند': 3236, 'بهلم': 3237, 'المولی': 3238, 'عشاقی': 3239, 'حاتم': 3240, 'بشکفت': 3241, 'تولا': 3242, 'بدرد': 3243, 'لیلا': 3244, 'والا': 3245, 'ناقوس': 3246, 'زمینی': 3247, 'جلالا': 3248, 'فروپوش': 3249, 'اوباش': 3250, 'جنونست': 3251, 'شجاعت': 3252, 'مهیاست': 3253, 'مغزست': 3254, 'بیناست': 3255, 'سرناست': 3256, 'جوییم': 3257, 'خوردم': 3258, 'گویاست': 3259, 'برجاست': 3260, 'گرمیم': 3261, 'فروریخت': 3262, 'ندانیم': 3263, 'دامیست': 3264, 'بندست': 3265, 'برپاست': 3266, 'غریبست': 3267, 'خموشید': 3268, 'مسیحا': 3269, 'پرحدث': 3270, 'پالیز': 3271, 'نگه': 3272, 'معده': 3273, 'مهیا': 3274, 'چالاک': 3275, 'القهوه': 3276, 'کشیدست': 3277, 'قمری': 3278, 'گهری': 3279, 'جگری': 3280, 'اثری': 3281, 'خداییست': 3282, 'عروس': 3283, 'گزارد': 3284, 'سپری': 3285, 'نظرت': 3286, 'لطیفست': 3287, 'سدره': 3288, 'غرد': 3289, 'بخیلانه': 3290, 'نگریست': 3291, 'رفتند': 3292, 'نگنجی': 3293, 'عمارت': 3294, 'همدل': 3295, 'ضعیفان': 3296, 'جوزا': 3297, 'حسنت': 3298, 'تیرم': 3299, 'سویست': 3300, 'آوردند': 3301, 'روانست': 3302, 'کرد': 3303, 'صرف': 3304, 'برانیم': 3305, 'سازیم': 3306, 'سرهاست': 3307, 'فرورو': 3308, 'نقصی': 3309, 'انگشتری': 3310, 'مکرم': 3311, 'عبهری': 3312, 'احمری': 3313, 'کافری': 3314, 'جهاد': 3315, 'سامری': 3316, 'نپرد': 3317, 'عقیله': 3318, 'کالا': 3319, 'خارست': 3320, 'کلاه': 3321, 'شکرفروش': 3322, 'نپرسد': 3323, 'نیر': 3324, 'فروشد': 3325, 'میاموز': 3326, 'استادست': 3327, 'آموز': 3328, 'دوز': 3329, 'اندوز': 3330, 'پیوست': 3331, 'عینا': 3332, 'بیشی': 3333, 'عمری': 3334, 'پستان': 3335, 'چشیدی': 3336, 'بخلت': 3337, 'التقینا': 3338, 'پیشم': 3339, 'بازگونه': 3340, 'اجسام': 3341, 'پوستین': 3342, 'بدران': 3343, 'جانیم': 3344, 'منش': 3345, 'پاها': 3346, 'صما': 3347, 'خاشاک': 3348, 'شنیده': 3349, 'بدگمان': 3350, 'سالی': 3351, 'خالق': 3352, 'نگارا': 3353, 'شاهدی': 3354, 'عثمان': 3355, 'مرتضا': 3356, 'ابروهای': 3357, 'بگشاده': 3358, 'برجسته': 3359, 'برونی': 3360, 'بیزار': 3361, 'آلو': 3362, 'سحرت': 3363, 'قضای': 3364, 'همتا': 3365, 'مقدس': 3366, 'بازگو': 3367, 'نرسم': 3368, 'نرویم': 3369, 'مرگست': 3370, 'درریز': 3371, 'زندگانیست': 3372, 'پرسید': 3373, 'صعوه': 3374, 'اصول': 3375, 'شورش': 3376, 'آرا': 3377, 'خلیفه': 3378, 'گشادی': 3379, 'کانی': 3380, 'فالی': 3381, 'ظاهرست': 3382, 'صادقان': 3383, 'سپارم': 3384, 'عزلت': 3385, 'خامشی': 3386, 'مومنی': 3387, 'غمگسار': 3388, 'بیفکن': 3389, 'عصاش': 3390, 'چوبی': 3391, 'بفزا': 3392, 'گشتن': 3393, 'بجوش': 3394, 'سرشته': 3395, 'بجنبان': 3396, 'خسان': 3397, 'فرصت': 3398, 'هوایش': 3399, 'ایست': 3400, 'گذار': 3401, 'درونست': 3402, 'بدایت': 3403, 'کوهست': 3404, 'کناره': 3405, 'عشقیست': 3406, 'اندرآید': 3407, 'محبوب': 3408, 'سفری': 3409, 'مکنید': 3410, 'کیقباد': 3411, 'طاعت': 3412, 'فساد': 3413, 'نفخ': 3414, 'علمدار': 3415, 'ساغرهای': 3416, 'مستت': 3417, 'جویا': 3418, 'نافه': 3419, 'ناف': 3420, 'دلربایی': 3421, 'فروغ': 3422, 'اضداد': 3423, 'صادق': 3424, 'یمن': 3425, 'حدست': 3426, 'اعتماد': 3427, 'محتاج': 3428, 'دیباج': 3429, 'حلاج': 3430, 'کوسه': 3431, 'نطع': 3432, 'محل': 3433, 'پالوده': 3434, 'جبل': 3435, 'صباحی': 3436, 'باف': 3437, 'استارگان': 3438, 'حیوانی': 3439, 'رازدار': 3440, 'تبریزست': 3441, 'جانبی': 3442, 'مرداری': 3443, 'نسیه': 3444, 'ایمانی': 3445, 'آنی': 3446, 'نوست': 3447, 'فرعی': 3448, 'تبریزیست': 3449, 'نیستش': 3450, 'سکه': 3451, 'شاخه': 3452, 'آذر': 3453, 'صعب': 3454, 'آزر': 3455, 'صحرای': 3456, 'کایمان': 3457, 'مرجان': 3458, 'جملگان': 3459, 'جزوم': 3460, 'افتادند': 3461, 'ملا': 3462, 'وارهان': 3463, 'ملایک': 3464, 'تافته': 3465, 'برداشته': 3466, 'وصالت': 3467, 'درفتاده': 3468, 'سکته': 3469, 'بکردی': 3470, 'مقال': 3471, 'رغم': 3472, 'افزار': 3473, 'کارت': 3474, 'گامی': 3475, 'خرسنگ': 3476, 'گداز': 3477, 'برگیرید': 3478, 'وصلش': 3479, 'ساعد': 3480, 'قرآن': 3481, 'ننهی': 3482, 'آفتابست': 3483, 'کیوان': 3484, 'رواق': 3485, 'سرمایه': 3486, 'سهل': 3487, 'غوطی': 3488, 'ایزد': 3489, 'رهاند': 3490, 'قباد': 3491, 'طاق': 3492, 'اخلاق': 3493, 'بزد': 3494, 'شایسته': 3495, 'هجرم': 3496, 'تشنیع': 3497, 'خرق': 3498, 'افتان': 3499, 'خیزان': 3500, 'کوفت': 3501, 'پیدای': 3502, 'جیب': 3503, 'بدمستی': 3504, 'تاجی': 3505, 'کفرست': 3506, 'خراباتی': 3507, 'نفع': 3508, 'جانشان': 3509, 'درید': 3510, 'درنگ': 3511, 'بدیدستی': 3512, 'جواهر': 3513, 'درناید': 3514, 'مردوار': 3515, 'هستیت': 3516, 'کامکار': 3517, 'مرتضی': 3518, 'بخواند': 3519, 'مامضی': 3520, 'دررباید': 3521, 'نشو': 3522, 'پیشوا': 3523, 'وهمی': 3524, 'ماورا': 3525, 'نفرین': 3526, 'حاصلم': 3527, 'مشکلم': 3528, 'منزلم': 3529, 'درربودی': 3530, 'گلم': 3531, 'نسوزد': 3532, 'عاقلم': 3533, 'حاضری': 3534, 'غایبی': 3535, 'عجوبه': 3536, 'کره': 3537, 'امیدوار': 3538, 'تاثیر': 3539, 'قید': 3540, 'تخییل': 3541, 'نم': 3542, 'ندیدی': 3543, 'نتانم': 3544, 'غاری': 3545, 'قار': 3546, 'زره': 3547, 'گرز': 3548, 'منشین': 3549, 'بمانی': 3550, 'گشادست': 3551, 'جاوید': 3552, 'خردا': 3553, 'عزبخانه': 3554, 'رمیدم': 3555, 'رهیدم': 3556, 'شکارم': 3557, 'نهادم': 3558, 'پیچان': 3559, 'بفریبد': 3560, 'مقربان': 3561, 'فکند': 3562, 'گذری': 3563, 'قیامتست': 3564, 'تفرج': 3565, 'بگاه': 3566, 'گسسته': 3567, 'عروسیست': 3568, 'زاغی': 3569, 'زدست': 3570, 'بنمایی': 3571, 'طبیبش': 3572, 'سرچشمه': 3573, 'نخوری': 3574, 'بغل': 3575, 'فریضه': 3576, 'دایره': 3577, 'برداشت': 3578, 'عقول': 3579, 'بگزید': 3580, 'لقایی': 3581, 'شکران': 3582, 'باوفایی': 3583, 'همراز': 3584, 'منتهایی': 3585, 'لوایی': 3586, 'کیمیایی': 3587, 'اولیایی': 3588, 'حسینی': 3589, 'دنگ': 3590, 'گلخن': 3591, 'عاقلی': 3592, 'پیری': 3593, 'برآوردم': 3594, 'فروخوردم': 3595, 'نیفتد': 3596, 'بیازردم': 3597, 'جوامردم': 3598, 'نیازارد': 3599, 'گوناگون': 3600, 'خودبین': 3601, 'ببینم': 3602, 'شهوانی': 3603, 'عطای': 3604, 'ببخشیده': 3605, 'بساز': 3606, 'لعلش': 3607, 'صلایی': 3608, 'بشنیده': 3609, 'آسیابان': 3610, 'نشیب': 3611, 'رفته': 3612, 'هفتم': 3613, 'جماد': 3614, 'قول': 3615, 'شی': 3616, 'ء': 3617, 'گوارد': 3618, 'دق': 3619, 'بخوانم': 3620, 'باطل': 3621, 'میرآب': 3622, 'مردمک': 3623, 'دیدگان': 3624, 'چابک': 3625, 'کندهای': 3626, 'کنده': 3627, 'کوبان': 3628, 'آسمانست': 3629, 'طوری': 3630, 'اشراق': 3631, 'پنجاه': 3632, 'نباشی': 3633, 'خیانت': 3634, 'بیتی': 3635, 'بتم': 3636, 'شقا': 3637, 'بودی': 3638, 'نمد': 3639, 'گیجی': 3640, 'عدوی': 3641, 'طراز': 3642, 'سیلت': 3643, 'جوق': 3644, 'بشنوند': 3645, 'بررو': 3646, 'قعر': 3647, 'برانی': 3648, 'پژمرده': 3649, 'جوانی': 3650, 'زبانت': 3651, 'اندرآور': 3652, 'بید': 3653, 'نهالی': 3654, 'ادرار': 3655, 'درهای': 3656, 'مردگان': 3657, 'بدرید': 3658, 'ایتیا': 3659, 'گرت': 3660, 'خان': 3661, 'آمدیت': 3662, 'حاجیان': 3663, 'مروه': 3664, 'خطبه': 3665, 'عرفات': 3666, 'بچه': 3667, 'پریم': 3668, 'لنگی': 3669, 'آنت': 3670, 'تصاریف': 3671, 'رونده': 3672, 'قنق': 3673, 'متهم': 3674, 'نعل': 3675, 'نگذارد': 3676, 'اشتیاق': 3677, 'ناروا': 3678, 'خطیب': 3679, 'خاصان': 3680, 'دیک': 3681, 'صفوت': 3682, 'بگردی': 3683, 'رفیقان': 3684, 'منورست': 3685, 'سوداش': 3686, 'یادگار': 3687, 'قلندر': 3688, 'بلبلی': 3689, 'کرایی': 3690, 'نداد': 3691, 'پرشکر': 3692, 'فشاند': 3693, 'دده': 3694, 'میکده': 3695, 'نبری': 3696, 'همش': 3697, 'کرمت': 3698, 'نگرم': 3699, 'اوانی': 3700, 'آیدم': 3701, 'عیانی': 3702, 'بفشارد': 3703, 'خانگی': 3704, 'دیوانگی': 3705, 'تفت': 3706, 'فتا': 3707, 'فاخته': 3708, 'بریز': 3709, 'قبای': 3710, 'کدورت': 3711, 'پیچیم': 3712, 'سد': 3713, 'دوید': 3714, 'چشید': 3715, 'ارزید': 3716, 'اسری': 3717, 'نخوانده': 3718, 'غریو': 3719, 'منزه': 3720, 'عنا': 3721, 'بدندی': 3722, 'فرات': 3723, 'خاکستری': 3724, 'نگردی': 3725, 'یکان': 3726, 'پالان': 3727, 'گذشتی': 3728, 'ماران': 3729, 'سررشته': 3730, 'شرابخانه': 3731, 'یزید': 3732, 'اهبطوا': 3733, 'نیکبخت': 3734, 'مفتح': 3735, 'الابواب': 3736, 'نزلنا': 3737, 'سروی': 3738, 'مستجاب': 3739, 'روند': 3740, 'مظهر': 3741, 'بشناسد': 3742, 'معرفت': 3743, 'درش': 3744, 'آموخت': 3745, 'مجال': 3746, 'کردگار': 3747, 'مواسا': 3748, 'فما': 3749, 'ولکن': 3750, 'اتوب': 3751, 'صار': 3752, 'هلاک': 3753, 'کنارم': 3754, 'نگذارم': 3755, 'نخارم': 3756, 'صفاتت': 3757, 'ذاتت': 3758, 'وظیفه': 3759, 'عزیزا': 3760, 'آزاد': 3761, 'طعمه': 3762, 'بشکستی': 3763, 'پذیر': 3764, 'درافکند': 3765, 'نپذیرد': 3766, 'قدیمست': 3767, 'چرند': 3768, 'نگری': 3769, 'و': 3770, 'طلبی': 3771, 'نشستند': 3772, 'مطبخ': 3773, 'کفچه': 3774, 'پرآب': 3775, 'پرنم': 3776, 'یتیمی': 3777, 'خلل': 3778, 'آهوان': 3779, 'آستان': 3780, 'عللا': 3781, 'حسین': 3782, 'غلا': 3783, 'درختش': 3784, 'مکتب': 3785, 'زلال': 3786, 'مشرب': 3787, 'رنجه': 3788, 'دمشق': 3789, 'غبغب': 3790, 'بازرهد': 3791, 'ثعلب': 3792, 'وحشتی': 3793, 'گدای': 3794, 'کانست': 3795, 'خدعه': 3796, 'لکن': 3797, 'چنو': 3798, 'قنینه': 3799, 'طپیدن': 3800, 'زاهد': 3801, 'بگرفتست': 3802, 'لبست': 3803, 'تعلق': 3804, 'بگرداند': 3805, 'بخسپد': 3806, 'مردار': 3807, 'فزونست': 3808, 'بازان': 3809, 'اوج': 3810, 'آنست': 3811, 'کریما': 3812, 'مرغزار': 3813, 'هجده': 3814, 'دردست': 3815, 'الملا': 3816, 'امه': 3817, 'پیم': 3818, 'استضا': 3819, 'کیف': 3820, 'نرفتی': 3821, 'نگذارند': 3822, 'مشتغل': 3823, 'نشدی': 3824, 'برونیم': 3825, 'درگذر': 3826, 'علاج': 3827, 'بردرد': 3828, 'تنسی': 3829, 'کاشف': 3830, 'حوادث': 3831, 'ساکنان': 3832, 'گلست': 3833, 'بستن': 3834, 'کاهش': 3835, 'ببرم': 3836, 'بسازد': 3837, 'بنگارد': 3838, 'بستانی': 3839, 'نذر': 3840, 'برتر': 3841, 'مدمغ': 3842, 'زیت': 3843, 'تبسم': 3844, 'دیوان': 3845, 'قطار': 3846, 'کشاننده': 3847, 'پرنده': 3848, 'فرستی': 3849, 'دوروزه': 3850, 'بیهده': 3851, 'دریاصفت': 3852, 'سیمرغ': 3853, 'فتانه': 3854, 'درآر': 3855, 'اشارات': 3856, 'غلامانه': 3857, 'سخنی': 3858, 'الثری': 3859, 'بخفت': 3860, 'ساله': 3861, 'غرق': 3862, 'نشناسم': 3863, 'شکرخانه': 3864, 'بیخودم': 3865, 'شدن': 3866, 'برجهید': 3867, 'اننی': 3868, 'انجمن': 3869, 'اصفر': 3870, 'درجست': 3871, 'مضی': 3872, 'العرش': 3873, 'اعلم': 3874, 'کیل': 3875, 'چیزها': 3876, 'لگد': 3877, 'انما': 3878, 'نعیم': 3879, 'سرشت': 3880, 'لفوادی': 3881, 'دوشاب': 3882, 'دما': 3883, 'ملات': 3884, 'خوشا': 3885, 'لباب': 3886, 'فیها': 3887, 'التلاقی': 3888, 'السکاری': 3889, 'منهم': 3890, 'طیب': 3891, 'الملتقی': 3892, 'اضحی': 3893, 'الطوارق': 3894, 'المشارق': 3895, 'ضحی': 3896, 'عاد': 3897, 'العین': 3898, 'اشرقت': 3899, 'الدنیا': 3900, 'غدا': 3901, 'الصبوه': 3902, 'الورد': 3903, 'ریانا': 3904, 'ذبت': 3905, 'معنانا': 3906, 'فدیتک': 3907, 'تتری': 3908, 'جهرا': 3909, 'سکاری': 3910, 'الجد': 3911, 'غریق': 3912, 'روحا': 3913, 'دونه': 3914, 'نخلی': 3915, 'الفواد': 3916, 'الجلا': 3917, 'صفو': 3918, 'تتلو': 3919, 'رحیقا': 3920, 'شرابا': 3921, 'حسنه': 3922, 'امانا': 3923, 'سقی': 3924, 'ارضا': 3925, 'بروحی': 3926, 'ملالا': 3927, 'اللیل': 3928, 'جواهرا': 3929, 'صباحا': 3930, 'خفرات': 3931, 'هواکم': 3932, 'فدهشنا': 3933, 'شربنا': 3934, 'غصن': 3935, 'بتنا': 3936, 'رات': 3937, 'طیبوا': 3938, 'احوالها': 3939, 'الکونین': 3940, 'اصبحت': 3941, 'مدا': 3942, 'ضمیری': 3943, 'مالک': 3944, 'الردی': 3945, 'الکمال': 3946, 'یهدی': 3947, 'البقا': 3948, 'معرض': 3949, 'ارض': 3950, 'خطر': 3951, 'فسقانا': 3952, 'اتینا': 3953, 'حسنات': 3954, 'هوینا': 3955, 'الفضل': 3956, 'خلقونا': 3957, 'رزقونا': 3958, 'اغنانا': 3959, 'کنت': 3960, 'بارق': 3961, 'فلیعبد': 3962, 'فرقانا': 3963, 'الوانا': 3964, 'الباقی': 3965, 'احسانا': 3966, 'یطفی': 3967, 'المدامه': 3968, 'فقد': 3969, 'الملاحه': 3970, 'بل': 3971, 'لقاوک': 3972, 'تلا': 3973, 'عشقک': 3974, 'الحبیب': 3975, 'اتاک': 3976, 'عینک': 3977, 'عجائب': 3978, 'جنا': 3979, 'قلبک': 3980, 'احیی': 3981, 'فکان': 3982, 'الفراق': 3983, 'تحفه': 3984, 'خفتی': 3985, 'نرست': 3986, 'گدایان': 3987, 'میهمان': 3988, 'دلو': 3989, 'محراب': 3990, 'عناب': 3991, 'بخسبد': 3992, 'زحل': 3993, 'بریخت': 3994, 'مطیب': 3995, 'خلاب': 3996, 'خجلت': 3997, 'عنده': 3998, 'الکتاب': 3999, 'همرهان': 4000, 'بالصواب': 4001, 'زنبور': 4002, 'بودست': 4003, 'برسته': 4004, 'جسمیان': 4005, 'مکوش': 4006, 'هوایت': 4007, 'گذارم': 4008, 'زارم': 4009, 'بارم': 4010, 'قندت': 4011, 'انتظارم': 4012, 'نکوبی': 4013, 'مجلسی': 4014, 'بروب': 4015, 'اعظم': 4016, 'سیران': 4017, 'یتوب': 4018, 'شق': 4019, 'عذاب': 4020, 'بشنوید': 4021, 'انقلاب': 4022, 'ثواب': 4023, 'سراب': 4024, 'متاب': 4025, 'کیر': 4026, 'کآید': 4027, 'سوسنست': 4028, 'رباست': 4029, 'مراقب': 4030, 'مطالب': 4031, 'محنت': 4032, 'دمیده': 4033, 'کرست': 4034, 'خوشیم': 4035, 'حرام': 4036, 'کوثرست': 4037, 'برجهد': 4038, 'برویید': 4039, 'عقاب': 4040, 'گوار': 4041, 'بجست': 4042, 'درختست': 4043, 'بترس': 4044, 'هیبت': 4045, 'زینهار': 4046, 'سقای': 4047, 'الباب': 4048, 'درخورست': 4049, 'ندای': 4050, 'برهاند': 4051, 'نخاست': 4052, 'دریدم': 4053, 'غین': 4054, 'افتادست': 4055, 'درآییم': 4056, 'بدیدست': 4057, 'همتای': 4058, 'وراء': 4059, 'الود': 4060, 'فقلبی': 4061, 'بالت': 4062, 'ابکی': 4063, 'بیماریی': 4064, 'والده': 4065, 'بلای': 4066, 'خوشدلی': 4067, 'زه': 4068, 'امانم': 4069, 'نازی': 4070, 'احسانت': 4071, 'تابانت': 4072, 'آلت': 4073, 'گیج': 4074, 'شاهنشهی': 4075, 'سبلت': 4076, 'ورقی': 4077, 'بنوشته': 4078, 'نامش': 4079, 'انبوهی': 4080, 'چغانه': 4081, 'مغانه': 4082, 'عنبر': 4083, 'زمینست': 4084, 'فروکن': 4085, 'فسونست': 4086, 'فلانست': 4087, 'مهرست': 4088, 'میانش': 4089, 'توند': 4090, 'خرابست': 4091, 'دربان': 4092, 'گرگی': 4093, 'بایدش': 4094, 'ساخت': 4095, 'نونست': 4096, 'پرخونست': 4097, 'پوز': 4098, 'اموات': 4099, 'خوابست': 4100, 'آبست': 4101, 'کارست': 4102, 'عارست': 4103, 'هزارست': 4104, 'ماتم': 4105, 'دلستان': 4106, 'میانست': 4107, 'بختم': 4108, 'خوبش': 4109, 'جبه': 4110, 'بندم': 4111, 'لاغ': 4112, 'آز': 4113, 'رهایی': 4114, 'خردمند': 4115, 'سمرقند': 4116, 'خرسند': 4117, 'فرزند': 4118, 'رنگست': 4119, 'نگارست': 4120, 'یارکان': 4121, 'ضریریست': 4122, 'نومید': 4123, 'طاعات': 4124, 'شرحش': 4125, 'شمارست': 4126, 'موزون': 4127, 'بهاران': 4128, 'گلدسته': 4129, 'خموشانه': 4130, 'رسوای': 4131, 'عنقاست': 4132, 'روزکی': 4133, 'غارم': 4134, 'روت': 4135, 'خرافات': 4136, 'بدانستی': 4137, 'ساختی': 4138, 'درافتی': 4139, 'امیرست': 4140, 'زلفش': 4141, 'صحراست': 4142, 'بریم': 4143, 'دشمنی': 4144, 'برند': 4145, 'لطیفت': 4146, 'نکردی': 4147, 'گوشی': 4148, 'رمضان': 4149, 'سالار': 4150, 'نشانت': 4151, 'راهت': 4152, 'سبکتر': 4153, 'کریمست': 4154, 'آفریده': 4155, 'خارش': 4156, 'یم': 4157, 'کشتن': 4158, 'فروش': 4159, 'مغرور': 4160, 'فروشی': 4161, 'بدادی': 4162, 'مسلمات': 4163, 'مومنات': 4164, 'قانتات': 4165, 'تائبات': 4166, 'ثقات': 4167, 'شبت': 4168, 'فاعلاتن': 4169, 'کردنست': 4170, 'عقد': 4171, 'کابین': 4172, 'محبت': 4173, 'کوبی': 4174, 'اقرار': 4175, 'تکیه': 4176, 'ثری': 4177, 'پاشی': 4178, 'ابرار': 4179, 'حضور': 4180, 'بزمی': 4181, 'تیزی': 4182, 'مشکلست': 4183, 'شرطی': 4184, 'طبعت': 4185, 'باطلست': 4186, 'عاشقست': 4187, 'طبیبی': 4188, 'انفاس': 4189, 'خموشیت': 4190, 'تمامت': 4191, 'برپر': 4192, 'بامت': 4193, 'چستی': 4194, 'شهامت': 4195, 'ببست': 4196, 'خبرست': 4197, 'سحرست': 4198, 'گهربخش': 4199, 'صفرای': 4200, 'شادست': 4201, 'آحادست': 4202, 'فرهادست': 4203, 'فریادست': 4204, 'باخبران': 4205, 'درگذشت': 4206, 'نوبهاری': 4207, 'گلزارست': 4208, 'اقلیم': 4209, 'آویخته': 4210, 'افلاطون': 4211, 'کفتار': 4212, 'خودپرستی': 4213, 'ذوالجلال': 4214, 'حرم': 4215, 'نرگسدان': 4216, 'فربه': 4217, 'طالبا': 4218, 'اولیاست': 4219, 'مخالف': 4220, 'غمست': 4221, 'بخوردم': 4222, 'برآیی': 4223, 'نازنینی': 4224, 'قلتبانست': 4225, 'زبانست': 4226, 'بمردی': 4227, 'گلستانم': 4228, 'کانم': 4229, 'ایمانم': 4230, 'جعد': 4231, 'عشقم': 4232, 'هدهدم': 4233, 'سلیمانم': 4234, 'زنیم': 4235, 'منیست': 4236, 'بارگاه': 4237, 'اکبرست': 4238, 'پرورست': 4239, 'درنگر': 4240, 'دستیم': 4241, 'برترست': 4242, 'طپید': 4243, 'صباست': 4244, 'بیمارم': 4245, 'گلزارم': 4246, 'سالارم': 4247, 'ایمنست': 4248, 'لقای': 4249, 'تحیریست': 4250, 'وانما': 4251, 'شکمبه': 4252, 'خرسوار': 4253, 'گواست': 4254, 'عطاست': 4255, 'منتهاست': 4256, 'شهی': 4257, 'مصطفاست': 4258, 'برزنم': 4259, 'بوست': 4260, 'بمان': 4261, 'شکرست': 4262, 'شکرخوار': 4263, 'کالبد': 4264, 'بیات': 4265, 'ماهست': 4266, 'نابیناست': 4267, 'صلاست': 4268, 'خراباتست': 4269, 'زاید': 4270, 'گشادن': 4271, 'جعفر': 4272, 'منظر': 4273, 'هیزم': 4274, 'ستیزه': 4275, 'شادیست': 4276, 'برسیدست': 4277, 'صلات': 4278, 'نکوست': 4279, 'عجیب': 4280, 'خطاست': 4281, 'کنش': 4282, 'جهانیست': 4283}\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Jmi-MUXBf4VU"
      },
      "outputs": [],
      "source": [
        " # find more stopwords by sorting the tokenizer word counts\n",
        "#  word_count_sorted = dict(sorted(tokenizer.word_counts.items(), reverse=False, key=lambda t: t[1]))\n",
        "#  word_count_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ElB_faJPCQs"
      },
      "outputs": [],
      "source": [
        "encoded = tokenizer.texts_to_sequences(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNgPCssskVPV",
        "outputId": "8fd4b169-ae1e-45b2-8c66-4d661b709463"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2726, 283, 1337, 397, 1610, 967, 143],\n",
              " [185, 568, 1124, 398, 568, 568, 830, 332, 23],\n",
              " [46, 2727, 29, 636, 2031, 29, 831, 29, 258, 29, 1337],\n",
              " [92, 143, 1338, 727, 728],\n",
              " [30, 221, 162, 399, 1611, 968, 244],\n",
              " [1611, 729, 2032, 569, 10, 10, 209, 2728],\n",
              " [464, 13, 464, 209, 1125, 419],\n",
              " [969, 104, 1612, 352, 1126, 1612, 192, 1612, 730],\n",
              " [77, 41, 1, 399, 1613, 1, 259, 245, 284, 1127],\n",
              " [201, 731, 56, 221, 2729, 377, 732, 1128, 31, 570, 186]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "encoded[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ldaLQ0svKR1B"
      },
      "outputs": [],
      "source": [
        "num_all_words = sum(len(s) for s in encoded) # total number of words in the corpus\n",
        "num_unique_words = len(tokenizer.word_index) + 1  # total number of unique words in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwyN6alDj0Rl",
        "outputId": "1631226d-057c-4e40-cbf2-151b61a50e87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32654, 4284)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "num_all_words, num_unique_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate data**"
      ],
      "metadata": {
        "id": "0a--qhdFXzAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "iUFMB4csVOSc"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "window_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "i7mmQECLjEqz"
      },
      "outputs": [],
      "source": [
        "def generate_data(corpus, window_size, num_unique_words):\n",
        "    maxlen = window_size * 2\n",
        "    all_inputs = []\n",
        "    all_outputs = []\n",
        "    for words in corpus:\n",
        "      len_words = len(words)\n",
        "      for index,w in enumerate(words):\n",
        "        s = index - window_size\n",
        "        e = index + window_size + 1\n",
        "        for i in range(s, e):\n",
        "            if i != index and 0 <= i < len_words:\n",
        "              #all_inputs.append(w) \n",
        "              all_inputs.append(to_categorical(w, num_unique_words)) \n",
        "              all_outputs.append(to_categorical(words[i], num_unique_words))\n",
        "\n",
        "    return (np.array(all_inputs), np.array(all_outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-rdJV9GmsAu",
        "outputId": "9f864cc0-5743-41c9-92d6-4c1dd0ac2ee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98832, 4284), (98832, 4284))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Create training data\n",
        "X_train, y_train = generate_data(encoded, window_size, num_unique_words)\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDJ7gZp2yo8",
        "outputId": "18afe316-ab2c-4320-b695-8dec9b193fbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yxGjSSyJzXu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16d11fc-fd5f-4af1-e168-0d69159a7805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([2726]),)\n"
          ]
        }
      ],
      "source": [
        "# for i in X_train:\n",
        "#   print(np.where(i == 1))\n",
        "print(np.where(X_train[0] == 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Neural Network**"
      ],
      "metadata": {
        "id": "8mjVK7vmvwiW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7zVNpd6yT7Wx"
      },
      "outputs": [],
      "source": [
        "input1 = Input(shape=(X_train.shape[1],))\n",
        "dense1 = Dense(units=100, activation='linear')(input1)\n",
        "output1 = Dense(units=y_train.shape[1], activation='softmax')(dense1)\n",
        "model = Model(inputs=input1, outputs=output1)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Input(shape=(X_train.shape[1],)))\n",
        "# model.add(Dense(units=50, activation='linear'))\n",
        "# model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(units=y_train.shape[1], activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YCAYelLXEcXH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi8g7duhbFuV",
        "outputId": "691e6951-1c90-43a4-9267-d4e6c2bddeed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4284)]            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               428500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4284)              432684    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 861,184\n",
            "Trainable params: 861,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61aR17ijDIVc",
        "outputId": "5e78326d-402b-47f1-e285-f360d7de9838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "155/155 [==============================] - 25s 150ms/step - loss: 7.9545 - accuracy: 0.0240 - val_loss: 7.7563 - val_accuracy: 0.0179\n",
            "Epoch 2/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 7.4940 - accuracy: 0.0256 - val_loss: 7.8021 - val_accuracy: 0.0179\n",
            "Epoch 3/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 7.4682 - accuracy: 0.0256 - val_loss: 7.8285 - val_accuracy: 0.0179\n",
            "Epoch 4/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 7.4473 - accuracy: 0.0256 - val_loss: 7.8499 - val_accuracy: 0.0179\n",
            "Epoch 5/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 7.4203 - accuracy: 0.0260 - val_loss: 7.8604 - val_accuracy: 0.0192\n",
            "Epoch 6/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 7.3813 - accuracy: 0.0285 - val_loss: 7.8703 - val_accuracy: 0.0202\n",
            "Epoch 7/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 7.3292 - accuracy: 0.0301 - val_loss: 7.8741 - val_accuracy: 0.0209\n",
            "Epoch 8/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 7.2564 - accuracy: 0.0328 - val_loss: 7.8834 - val_accuracy: 0.0218\n",
            "Epoch 9/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 7.1598 - accuracy: 0.0375 - val_loss: 7.8886 - val_accuracy: 0.0227\n",
            "Epoch 10/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 7.0385 - accuracy: 0.0425 - val_loss: 7.8960 - val_accuracy: 0.0240\n",
            "Epoch 11/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 6.8962 - accuracy: 0.0486 - val_loss: 7.9055 - val_accuracy: 0.0250\n",
            "Epoch 12/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 6.7376 - accuracy: 0.0567 - val_loss: 7.9083 - val_accuracy: 0.0254\n",
            "Epoch 13/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 6.5663 - accuracy: 0.0643 - val_loss: 7.9327 - val_accuracy: 0.0266\n",
            "Epoch 14/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 6.3884 - accuracy: 0.0712 - val_loss: 7.9559 - val_accuracy: 0.0277\n",
            "Epoch 15/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 6.2092 - accuracy: 0.0774 - val_loss: 7.9885 - val_accuracy: 0.0275\n",
            "Epoch 16/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 6.0331 - accuracy: 0.0817 - val_loss: 8.0273 - val_accuracy: 0.0277\n",
            "Epoch 17/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 5.8633 - accuracy: 0.0855 - val_loss: 8.0729 - val_accuracy: 0.0276\n",
            "Epoch 18/500\n",
            "155/155 [==============================] - 15s 95ms/step - loss: 5.7023 - accuracy: 0.0877 - val_loss: 8.1203 - val_accuracy: 0.0274\n",
            "Epoch 19/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 5.5509 - accuracy: 0.0894 - val_loss: 8.1818 - val_accuracy: 0.0282\n",
            "Epoch 20/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 5.4100 - accuracy: 0.0898 - val_loss: 8.2372 - val_accuracy: 0.0287\n",
            "Epoch 21/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 5.2794 - accuracy: 0.0888 - val_loss: 8.3077 - val_accuracy: 0.0285\n",
            "Epoch 22/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 5.1593 - accuracy: 0.0891 - val_loss: 8.3747 - val_accuracy: 0.0286\n",
            "Epoch 23/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 5.0489 - accuracy: 0.0882 - val_loss: 8.4475 - val_accuracy: 0.0292\n",
            "Epoch 24/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.9476 - accuracy: 0.0880 - val_loss: 8.5159 - val_accuracy: 0.0290\n",
            "Epoch 25/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.8551 - accuracy: 0.0875 - val_loss: 8.5907 - val_accuracy: 0.0289\n",
            "Epoch 26/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.7705 - accuracy: 0.0872 - val_loss: 8.6643 - val_accuracy: 0.0284\n",
            "Epoch 27/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.6929 - accuracy: 0.0871 - val_loss: 8.7299 - val_accuracy: 0.0286\n",
            "Epoch 28/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.6221 - accuracy: 0.0860 - val_loss: 8.8026 - val_accuracy: 0.0280\n",
            "Epoch 29/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 4.5569 - accuracy: 0.0866 - val_loss: 8.8695 - val_accuracy: 0.0282\n",
            "Epoch 30/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 4.4969 - accuracy: 0.0864 - val_loss: 8.9399 - val_accuracy: 0.0285\n",
            "Epoch 31/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.4417 - accuracy: 0.0876 - val_loss: 9.0100 - val_accuracy: 0.0281\n",
            "Epoch 32/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.3908 - accuracy: 0.0872 - val_loss: 9.0756 - val_accuracy: 0.0279\n",
            "Epoch 33/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.3438 - accuracy: 0.0878 - val_loss: 9.1424 - val_accuracy: 0.0278\n",
            "Epoch 34/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 4.3004 - accuracy: 0.0875 - val_loss: 9.2084 - val_accuracy: 0.0275\n",
            "Epoch 35/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.2599 - accuracy: 0.0881 - val_loss: 9.2702 - val_accuracy: 0.0270\n",
            "Epoch 36/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.2227 - accuracy: 0.0873 - val_loss: 9.3338 - val_accuracy: 0.0267\n",
            "Epoch 37/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.1884 - accuracy: 0.0878 - val_loss: 9.3978 - val_accuracy: 0.0264\n",
            "Epoch 38/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.1563 - accuracy: 0.0877 - val_loss: 9.4521 - val_accuracy: 0.0263\n",
            "Epoch 39/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.1264 - accuracy: 0.0867 - val_loss: 9.5168 - val_accuracy: 0.0253\n",
            "Epoch 40/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.0986 - accuracy: 0.0880 - val_loss: 9.5725 - val_accuracy: 0.0261\n",
            "Epoch 41/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.0728 - accuracy: 0.0868 - val_loss: 9.6314 - val_accuracy: 0.0249\n",
            "Epoch 42/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.0487 - accuracy: 0.0870 - val_loss: 9.6855 - val_accuracy: 0.0253\n",
            "Epoch 43/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 4.0266 - accuracy: 0.0865 - val_loss: 9.7394 - val_accuracy: 0.0255\n",
            "Epoch 44/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 4.0058 - accuracy: 0.0864 - val_loss: 9.7972 - val_accuracy: 0.0253\n",
            "Epoch 45/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9865 - accuracy: 0.0850 - val_loss: 9.8482 - val_accuracy: 0.0254\n",
            "Epoch 46/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9683 - accuracy: 0.0849 - val_loss: 9.8962 - val_accuracy: 0.0253\n",
            "Epoch 47/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9516 - accuracy: 0.0846 - val_loss: 9.9456 - val_accuracy: 0.0251\n",
            "Epoch 48/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9357 - accuracy: 0.0851 - val_loss: 9.9987 - val_accuracy: 0.0255\n",
            "Epoch 49/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9210 - accuracy: 0.0850 - val_loss: 10.0434 - val_accuracy: 0.0255\n",
            "Epoch 50/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.9070 - accuracy: 0.0845 - val_loss: 10.0943 - val_accuracy: 0.0249\n",
            "Epoch 51/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8941 - accuracy: 0.0828 - val_loss: 10.1424 - val_accuracy: 0.0247\n",
            "Epoch 52/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 3.8819 - accuracy: 0.0837 - val_loss: 10.1850 - val_accuracy: 0.0253\n",
            "Epoch 53/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8705 - accuracy: 0.0828 - val_loss: 10.2265 - val_accuracy: 0.0249\n",
            "Epoch 54/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 3.8599 - accuracy: 0.0831 - val_loss: 10.2727 - val_accuracy: 0.0241\n",
            "Epoch 55/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8495 - accuracy: 0.0825 - val_loss: 10.3102 - val_accuracy: 0.0248\n",
            "Epoch 56/500\n",
            "155/155 [==============================] - 15s 96ms/step - loss: 3.8399 - accuracy: 0.0824 - val_loss: 10.3566 - val_accuracy: 0.0252\n",
            "Epoch 57/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8311 - accuracy: 0.0819 - val_loss: 10.3998 - val_accuracy: 0.0247\n",
            "Epoch 58/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.8224 - accuracy: 0.0813 - val_loss: 10.4356 - val_accuracy: 0.0249\n",
            "Epoch 59/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8142 - accuracy: 0.0826 - val_loss: 10.4726 - val_accuracy: 0.0250\n",
            "Epoch 60/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.8066 - accuracy: 0.0818 - val_loss: 10.5109 - val_accuracy: 0.0247\n",
            "Epoch 61/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7996 - accuracy: 0.0810 - val_loss: 10.5483 - val_accuracy: 0.0245\n",
            "Epoch 62/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7926 - accuracy: 0.0816 - val_loss: 10.5883 - val_accuracy: 0.0247\n",
            "Epoch 63/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7860 - accuracy: 0.0806 - val_loss: 10.6224 - val_accuracy: 0.0248\n",
            "Epoch 64/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7800 - accuracy: 0.0810 - val_loss: 10.6560 - val_accuracy: 0.0247\n",
            "Epoch 65/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7741 - accuracy: 0.0811 - val_loss: 10.6888 - val_accuracy: 0.0240\n",
            "Epoch 66/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.7684 - accuracy: 0.0811 - val_loss: 10.7212 - val_accuracy: 0.0244\n",
            "Epoch 67/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7632 - accuracy: 0.0807 - val_loss: 10.7578 - val_accuracy: 0.0243\n",
            "Epoch 68/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7584 - accuracy: 0.0807 - val_loss: 10.7867 - val_accuracy: 0.0243\n",
            "Epoch 69/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.7532 - accuracy: 0.0801 - val_loss: 10.8162 - val_accuracy: 0.0244\n",
            "Epoch 70/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.7488 - accuracy: 0.0804 - val_loss: 10.8526 - val_accuracy: 0.0250\n",
            "Epoch 71/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7442 - accuracy: 0.0811 - val_loss: 10.8819 - val_accuracy: 0.0249\n",
            "Epoch 72/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7402 - accuracy: 0.0798 - val_loss: 10.9097 - val_accuracy: 0.0245\n",
            "Epoch 73/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.7358 - accuracy: 0.0805 - val_loss: 10.9372 - val_accuracy: 0.0243\n",
            "Epoch 74/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.7321 - accuracy: 0.0797 - val_loss: 10.9670 - val_accuracy: 0.0242\n",
            "Epoch 75/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.7283 - accuracy: 0.0801 - val_loss: 10.9935 - val_accuracy: 0.0241\n",
            "Epoch 76/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7247 - accuracy: 0.0799 - val_loss: 11.0219 - val_accuracy: 0.0242\n",
            "Epoch 77/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7213 - accuracy: 0.0807 - val_loss: 11.0505 - val_accuracy: 0.0242\n",
            "Epoch 78/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7179 - accuracy: 0.0800 - val_loss: 11.0822 - val_accuracy: 0.0243\n",
            "Epoch 79/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7147 - accuracy: 0.0809 - val_loss: 11.1056 - val_accuracy: 0.0243\n",
            "Epoch 80/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7118 - accuracy: 0.0798 - val_loss: 11.1270 - val_accuracy: 0.0249\n",
            "Epoch 81/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7093 - accuracy: 0.0794 - val_loss: 11.1540 - val_accuracy: 0.0247\n",
            "Epoch 82/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7061 - accuracy: 0.0804 - val_loss: 11.1773 - val_accuracy: 0.0248\n",
            "Epoch 83/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7033 - accuracy: 0.0803 - val_loss: 11.2072 - val_accuracy: 0.0249\n",
            "Epoch 84/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.7009 - accuracy: 0.0799 - val_loss: 11.2279 - val_accuracy: 0.0249\n",
            "Epoch 85/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6983 - accuracy: 0.0791 - val_loss: 11.2524 - val_accuracy: 0.0240\n",
            "Epoch 86/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6957 - accuracy: 0.0796 - val_loss: 11.2771 - val_accuracy: 0.0243\n",
            "Epoch 87/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6934 - accuracy: 0.0797 - val_loss: 11.2995 - val_accuracy: 0.0245\n",
            "Epoch 88/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6911 - accuracy: 0.0789 - val_loss: 11.3231 - val_accuracy: 0.0247\n",
            "Epoch 89/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6891 - accuracy: 0.0802 - val_loss: 11.3426 - val_accuracy: 0.0245\n",
            "Epoch 90/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6871 - accuracy: 0.0793 - val_loss: 11.3668 - val_accuracy: 0.0248\n",
            "Epoch 91/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6849 - accuracy: 0.0789 - val_loss: 11.3876 - val_accuracy: 0.0246\n",
            "Epoch 92/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6831 - accuracy: 0.0792 - val_loss: 11.4095 - val_accuracy: 0.0242\n",
            "Epoch 93/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6812 - accuracy: 0.0801 - val_loss: 11.4272 - val_accuracy: 0.0250\n",
            "Epoch 94/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6793 - accuracy: 0.0797 - val_loss: 11.4487 - val_accuracy: 0.0238\n",
            "Epoch 95/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6773 - accuracy: 0.0790 - val_loss: 11.4705 - val_accuracy: 0.0252\n",
            "Epoch 96/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6756 - accuracy: 0.0795 - val_loss: 11.4920 - val_accuracy: 0.0240\n",
            "Epoch 97/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6742 - accuracy: 0.0791 - val_loss: 11.5097 - val_accuracy: 0.0249\n",
            "Epoch 98/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6728 - accuracy: 0.0794 - val_loss: 11.5267 - val_accuracy: 0.0241\n",
            "Epoch 99/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6710 - accuracy: 0.0786 - val_loss: 11.5499 - val_accuracy: 0.0237\n",
            "Epoch 100/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6696 - accuracy: 0.0786 - val_loss: 11.5669 - val_accuracy: 0.0241\n",
            "Epoch 101/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6679 - accuracy: 0.0783 - val_loss: 11.5874 - val_accuracy: 0.0239\n",
            "Epoch 102/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6666 - accuracy: 0.0786 - val_loss: 11.6080 - val_accuracy: 0.0244\n",
            "Epoch 103/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6651 - accuracy: 0.0791 - val_loss: 11.6225 - val_accuracy: 0.0240\n",
            "Epoch 104/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6637 - accuracy: 0.0792 - val_loss: 11.6405 - val_accuracy: 0.0240\n",
            "Epoch 105/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6622 - accuracy: 0.0785 - val_loss: 11.6601 - val_accuracy: 0.0239\n",
            "Epoch 106/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6611 - accuracy: 0.0790 - val_loss: 11.6791 - val_accuracy: 0.0244\n",
            "Epoch 107/500\n",
            "155/155 [==============================] - 15s 97ms/step - loss: 3.6596 - accuracy: 0.0788 - val_loss: 11.6924 - val_accuracy: 0.0246\n",
            "Epoch 108/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6587 - accuracy: 0.0789 - val_loss: 11.7102 - val_accuracy: 0.0245\n",
            "Epoch 109/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6576 - accuracy: 0.0792 - val_loss: 11.7279 - val_accuracy: 0.0244\n",
            "Epoch 110/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6563 - accuracy: 0.0785 - val_loss: 11.7441 - val_accuracy: 0.0242\n",
            "Epoch 111/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6553 - accuracy: 0.0791 - val_loss: 11.7578 - val_accuracy: 0.0243\n",
            "Epoch 112/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6543 - accuracy: 0.0788 - val_loss: 11.7744 - val_accuracy: 0.0242\n",
            "Epoch 113/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6532 - accuracy: 0.0793 - val_loss: 11.7865 - val_accuracy: 0.0235\n",
            "Epoch 114/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6522 - accuracy: 0.0789 - val_loss: 11.8052 - val_accuracy: 0.0233\n",
            "Epoch 115/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6510 - accuracy: 0.0793 - val_loss: 11.8215 - val_accuracy: 0.0239\n",
            "Epoch 116/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6502 - accuracy: 0.0795 - val_loss: 11.8363 - val_accuracy: 0.0244\n",
            "Epoch 117/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6491 - accuracy: 0.0788 - val_loss: 11.8535 - val_accuracy: 0.0245\n",
            "Epoch 118/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6485 - accuracy: 0.0791 - val_loss: 11.8665 - val_accuracy: 0.0235\n",
            "Epoch 119/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6472 - accuracy: 0.0790 - val_loss: 11.8823 - val_accuracy: 0.0234\n",
            "Epoch 120/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6466 - accuracy: 0.0785 - val_loss: 11.8963 - val_accuracy: 0.0241\n",
            "Epoch 121/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6456 - accuracy: 0.0784 - val_loss: 11.9094 - val_accuracy: 0.0239\n",
            "Epoch 122/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6448 - accuracy: 0.0793 - val_loss: 11.9219 - val_accuracy: 0.0235\n",
            "Epoch 123/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6440 - accuracy: 0.0789 - val_loss: 11.9370 - val_accuracy: 0.0241\n",
            "Epoch 124/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6434 - accuracy: 0.0796 - val_loss: 11.9515 - val_accuracy: 0.0238\n",
            "Epoch 125/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6426 - accuracy: 0.0785 - val_loss: 11.9642 - val_accuracy: 0.0240\n",
            "Epoch 126/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6417 - accuracy: 0.0784 - val_loss: 11.9785 - val_accuracy: 0.0246\n",
            "Epoch 127/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6410 - accuracy: 0.0790 - val_loss: 11.9952 - val_accuracy: 0.0238\n",
            "Epoch 128/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6407 - accuracy: 0.0795 - val_loss: 12.0066 - val_accuracy: 0.0240\n",
            "Epoch 129/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6395 - accuracy: 0.0785 - val_loss: 12.0155 - val_accuracy: 0.0246\n",
            "Epoch 130/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6390 - accuracy: 0.0777 - val_loss: 12.0314 - val_accuracy: 0.0247\n",
            "Epoch 131/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6383 - accuracy: 0.0791 - val_loss: 12.0436 - val_accuracy: 0.0244\n",
            "Epoch 132/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6378 - accuracy: 0.0787 - val_loss: 12.0542 - val_accuracy: 0.0231\n",
            "Epoch 133/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6370 - accuracy: 0.0786 - val_loss: 12.0698 - val_accuracy: 0.0241\n",
            "Epoch 134/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6365 - accuracy: 0.0783 - val_loss: 12.0812 - val_accuracy: 0.0247\n",
            "Epoch 135/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6358 - accuracy: 0.0788 - val_loss: 12.0947 - val_accuracy: 0.0239\n",
            "Epoch 136/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6352 - accuracy: 0.0782 - val_loss: 12.1023 - val_accuracy: 0.0243\n",
            "Epoch 137/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6348 - accuracy: 0.0781 - val_loss: 12.1164 - val_accuracy: 0.0242\n",
            "Epoch 138/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6340 - accuracy: 0.0786 - val_loss: 12.1263 - val_accuracy: 0.0245\n",
            "Epoch 139/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6337 - accuracy: 0.0786 - val_loss: 12.1392 - val_accuracy: 0.0242\n",
            "Epoch 140/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6331 - accuracy: 0.0785 - val_loss: 12.1488 - val_accuracy: 0.0234\n",
            "Epoch 141/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6325 - accuracy: 0.0781 - val_loss: 12.1642 - val_accuracy: 0.0241\n",
            "Epoch 142/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6320 - accuracy: 0.0775 - val_loss: 12.1745 - val_accuracy: 0.0244\n",
            "Epoch 143/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6314 - accuracy: 0.0787 - val_loss: 12.1872 - val_accuracy: 0.0240\n",
            "Epoch 144/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6311 - accuracy: 0.0781 - val_loss: 12.1959 - val_accuracy: 0.0241\n",
            "Epoch 145/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6305 - accuracy: 0.0782 - val_loss: 12.2046 - val_accuracy: 0.0230\n",
            "Epoch 146/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6300 - accuracy: 0.0783 - val_loss: 12.2162 - val_accuracy: 0.0237\n",
            "Epoch 147/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6297 - accuracy: 0.0778 - val_loss: 12.2298 - val_accuracy: 0.0243\n",
            "Epoch 148/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6290 - accuracy: 0.0788 - val_loss: 12.2358 - val_accuracy: 0.0240\n",
            "Epoch 149/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6287 - accuracy: 0.0784 - val_loss: 12.2513 - val_accuracy: 0.0238\n",
            "Epoch 150/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6281 - accuracy: 0.0783 - val_loss: 12.2599 - val_accuracy: 0.0235\n",
            "Epoch 151/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6278 - accuracy: 0.0785 - val_loss: 12.2713 - val_accuracy: 0.0237\n",
            "Epoch 152/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6272 - accuracy: 0.0782 - val_loss: 12.2780 - val_accuracy: 0.0235\n",
            "Epoch 153/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6269 - accuracy: 0.0786 - val_loss: 12.2872 - val_accuracy: 0.0243\n",
            "Epoch 154/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6264 - accuracy: 0.0787 - val_loss: 12.3020 - val_accuracy: 0.0242\n",
            "Epoch 155/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6260 - accuracy: 0.0787 - val_loss: 12.3088 - val_accuracy: 0.0245\n",
            "Epoch 156/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6257 - accuracy: 0.0780 - val_loss: 12.3161 - val_accuracy: 0.0237\n",
            "Epoch 157/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6255 - accuracy: 0.0789 - val_loss: 12.3269 - val_accuracy: 0.0237\n",
            "Epoch 158/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6250 - accuracy: 0.0785 - val_loss: 12.3319 - val_accuracy: 0.0234\n",
            "Epoch 159/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6243 - accuracy: 0.0788 - val_loss: 12.3541 - val_accuracy: 0.0247\n",
            "Epoch 160/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6241 - accuracy: 0.0785 - val_loss: 12.3573 - val_accuracy: 0.0245\n",
            "Epoch 161/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6237 - accuracy: 0.0788 - val_loss: 12.3646 - val_accuracy: 0.0243\n",
            "Epoch 162/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6235 - accuracy: 0.0777 - val_loss: 12.3747 - val_accuracy: 0.0244\n",
            "Epoch 163/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6232 - accuracy: 0.0780 - val_loss: 12.3851 - val_accuracy: 0.0242\n",
            "Epoch 164/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6228 - accuracy: 0.0782 - val_loss: 12.3933 - val_accuracy: 0.0249\n",
            "Epoch 165/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6226 - accuracy: 0.0783 - val_loss: 12.4029 - val_accuracy: 0.0233\n",
            "Epoch 166/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6222 - accuracy: 0.0779 - val_loss: 12.4086 - val_accuracy: 0.0242\n",
            "Epoch 167/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6219 - accuracy: 0.0782 - val_loss: 12.4226 - val_accuracy: 0.0247\n",
            "Epoch 168/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6216 - accuracy: 0.0784 - val_loss: 12.4295 - val_accuracy: 0.0243\n",
            "Epoch 169/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6212 - accuracy: 0.0782 - val_loss: 12.4361 - val_accuracy: 0.0231\n",
            "Epoch 170/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6209 - accuracy: 0.0786 - val_loss: 12.4429 - val_accuracy: 0.0226\n",
            "Epoch 171/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6207 - accuracy: 0.0784 - val_loss: 12.4520 - val_accuracy: 0.0237\n",
            "Epoch 172/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6206 - accuracy: 0.0783 - val_loss: 12.4622 - val_accuracy: 0.0242\n",
            "Epoch 173/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6203 - accuracy: 0.0783 - val_loss: 12.4677 - val_accuracy: 0.0241\n",
            "Epoch 174/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6201 - accuracy: 0.0784 - val_loss: 12.4780 - val_accuracy: 0.0242\n",
            "Epoch 175/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6196 - accuracy: 0.0789 - val_loss: 12.4832 - val_accuracy: 0.0232\n",
            "Epoch 176/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6193 - accuracy: 0.0784 - val_loss: 12.4933 - val_accuracy: 0.0235\n",
            "Epoch 177/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6190 - accuracy: 0.0774 - val_loss: 12.4985 - val_accuracy: 0.0235\n",
            "Epoch 178/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6190 - accuracy: 0.0775 - val_loss: 12.5058 - val_accuracy: 0.0234\n",
            "Epoch 179/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6187 - accuracy: 0.0783 - val_loss: 12.5170 - val_accuracy: 0.0234\n",
            "Epoch 180/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6183 - accuracy: 0.0781 - val_loss: 12.5242 - val_accuracy: 0.0230\n",
            "Epoch 181/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6183 - accuracy: 0.0776 - val_loss: 12.5290 - val_accuracy: 0.0234\n",
            "Epoch 182/500\n",
            "155/155 [==============================] - 15s 98ms/step - loss: 3.6178 - accuracy: 0.0781 - val_loss: 12.5379 - val_accuracy: 0.0238\n",
            "Epoch 183/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6174 - accuracy: 0.0772 - val_loss: 12.5460 - val_accuracy: 0.0241\n",
            "Epoch 184/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6173 - accuracy: 0.0780 - val_loss: 12.5489 - val_accuracy: 0.0235\n",
            "Epoch 185/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6171 - accuracy: 0.0791 - val_loss: 12.5581 - val_accuracy: 0.0238\n",
            "Epoch 186/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6168 - accuracy: 0.0782 - val_loss: 12.5669 - val_accuracy: 0.0241\n",
            "Epoch 187/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6168 - accuracy: 0.0781 - val_loss: 12.5757 - val_accuracy: 0.0234\n",
            "Epoch 188/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6165 - accuracy: 0.0781 - val_loss: 12.5828 - val_accuracy: 0.0239\n",
            "Epoch 189/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6162 - accuracy: 0.0781 - val_loss: 12.5896 - val_accuracy: 0.0236\n",
            "Epoch 190/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6163 - accuracy: 0.0786 - val_loss: 12.5925 - val_accuracy: 0.0235\n",
            "Epoch 191/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6160 - accuracy: 0.0776 - val_loss: 12.6015 - val_accuracy: 0.0249\n",
            "Epoch 192/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6157 - accuracy: 0.0781 - val_loss: 12.6099 - val_accuracy: 0.0239\n",
            "Epoch 193/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6153 - accuracy: 0.0780 - val_loss: 12.6170 - val_accuracy: 0.0240\n",
            "Epoch 194/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6150 - accuracy: 0.0782 - val_loss: 12.6243 - val_accuracy: 0.0231\n",
            "Epoch 195/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6152 - accuracy: 0.0782 - val_loss: 12.6300 - val_accuracy: 0.0240\n",
            "Epoch 196/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6151 - accuracy: 0.0783 - val_loss: 12.6378 - val_accuracy: 0.0235\n",
            "Epoch 197/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6147 - accuracy: 0.0780 - val_loss: 12.6446 - val_accuracy: 0.0243\n",
            "Epoch 198/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6144 - accuracy: 0.0774 - val_loss: 12.6484 - val_accuracy: 0.0236\n",
            "Epoch 199/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6144 - accuracy: 0.0773 - val_loss: 12.6533 - val_accuracy: 0.0244\n",
            "Epoch 200/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6140 - accuracy: 0.0774 - val_loss: 12.6609 - val_accuracy: 0.0242\n",
            "Epoch 201/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6141 - accuracy: 0.0778 - val_loss: 12.6698 - val_accuracy: 0.0239\n",
            "Epoch 202/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6136 - accuracy: 0.0775 - val_loss: 12.6731 - val_accuracy: 0.0234\n",
            "Epoch 203/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6136 - accuracy: 0.0784 - val_loss: 12.6774 - val_accuracy: 0.0234\n",
            "Epoch 204/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6135 - accuracy: 0.0783 - val_loss: 12.6859 - val_accuracy: 0.0237\n",
            "Epoch 205/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6133 - accuracy: 0.0780 - val_loss: 12.6923 - val_accuracy: 0.0238\n",
            "Epoch 206/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6131 - accuracy: 0.0781 - val_loss: 12.6948 - val_accuracy: 0.0237\n",
            "Epoch 207/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6129 - accuracy: 0.0779 - val_loss: 12.7016 - val_accuracy: 0.0239\n",
            "Epoch 208/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6128 - accuracy: 0.0779 - val_loss: 12.7122 - val_accuracy: 0.0242\n",
            "Epoch 209/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6125 - accuracy: 0.0783 - val_loss: 12.7157 - val_accuracy: 0.0240\n",
            "Epoch 210/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6123 - accuracy: 0.0784 - val_loss: 12.7234 - val_accuracy: 0.0244\n",
            "Epoch 211/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6124 - accuracy: 0.0778 - val_loss: 12.7297 - val_accuracy: 0.0234\n",
            "Epoch 212/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6121 - accuracy: 0.0779 - val_loss: 12.7368 - val_accuracy: 0.0242\n",
            "Epoch 213/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6121 - accuracy: 0.0781 - val_loss: 12.7392 - val_accuracy: 0.0233\n",
            "Epoch 214/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6121 - accuracy: 0.0778 - val_loss: 12.7442 - val_accuracy: 0.0233\n",
            "Epoch 215/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6119 - accuracy: 0.0779 - val_loss: 12.7516 - val_accuracy: 0.0234\n",
            "Epoch 216/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6117 - accuracy: 0.0785 - val_loss: 12.7559 - val_accuracy: 0.0238\n",
            "Epoch 217/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6115 - accuracy: 0.0775 - val_loss: 12.7628 - val_accuracy: 0.0236\n",
            "Epoch 218/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6113 - accuracy: 0.0771 - val_loss: 12.7699 - val_accuracy: 0.0246\n",
            "Epoch 219/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6111 - accuracy: 0.0780 - val_loss: 12.7744 - val_accuracy: 0.0241\n",
            "Epoch 220/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6112 - accuracy: 0.0782 - val_loss: 12.7781 - val_accuracy: 0.0242\n",
            "Epoch 221/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6108 - accuracy: 0.0778 - val_loss: 12.7847 - val_accuracy: 0.0239\n",
            "Epoch 222/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6109 - accuracy: 0.0780 - val_loss: 12.7889 - val_accuracy: 0.0230\n",
            "Epoch 223/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6106 - accuracy: 0.0780 - val_loss: 12.7958 - val_accuracy: 0.0243\n",
            "Epoch 224/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6105 - accuracy: 0.0777 - val_loss: 12.7976 - val_accuracy: 0.0239\n",
            "Epoch 225/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6106 - accuracy: 0.0770 - val_loss: 12.8007 - val_accuracy: 0.0239\n",
            "Epoch 226/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6101 - accuracy: 0.0776 - val_loss: 12.8148 - val_accuracy: 0.0246\n",
            "Epoch 227/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6101 - accuracy: 0.0784 - val_loss: 12.8157 - val_accuracy: 0.0242\n",
            "Epoch 228/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6101 - accuracy: 0.0777 - val_loss: 12.8205 - val_accuracy: 0.0239\n",
            "Epoch 229/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6100 - accuracy: 0.0775 - val_loss: 12.8231 - val_accuracy: 0.0239\n",
            "Epoch 230/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6098 - accuracy: 0.0776 - val_loss: 12.8320 - val_accuracy: 0.0241\n",
            "Epoch 231/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6095 - accuracy: 0.0782 - val_loss: 12.8345 - val_accuracy: 0.0236\n",
            "Epoch 232/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6095 - accuracy: 0.0778 - val_loss: 12.8405 - val_accuracy: 0.0236\n",
            "Epoch 233/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6095 - accuracy: 0.0780 - val_loss: 12.8404 - val_accuracy: 0.0234\n",
            "Epoch 234/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6093 - accuracy: 0.0783 - val_loss: 12.8497 - val_accuracy: 0.0235\n",
            "Epoch 235/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6091 - accuracy: 0.0783 - val_loss: 12.8514 - val_accuracy: 0.0224\n",
            "Epoch 236/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6091 - accuracy: 0.0783 - val_loss: 12.8579 - val_accuracy: 0.0236\n",
            "Epoch 237/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6091 - accuracy: 0.0774 - val_loss: 12.8639 - val_accuracy: 0.0232\n",
            "Epoch 238/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6090 - accuracy: 0.0772 - val_loss: 12.8679 - val_accuracy: 0.0247\n",
            "Epoch 239/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6088 - accuracy: 0.0781 - val_loss: 12.8710 - val_accuracy: 0.0237\n",
            "Epoch 240/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6089 - accuracy: 0.0775 - val_loss: 12.8770 - val_accuracy: 0.0235\n",
            "Epoch 241/500\n",
            "155/155 [==============================] - 15s 99ms/step - loss: 3.6086 - accuracy: 0.0784 - val_loss: 12.8827 - val_accuracy: 0.0241\n",
            "Epoch 242/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6085 - accuracy: 0.0778 - val_loss: 12.8867 - val_accuracy: 0.0238\n",
            "Epoch 243/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6082 - accuracy: 0.0781 - val_loss: 12.8890 - val_accuracy: 0.0237\n",
            "Epoch 244/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6084 - accuracy: 0.0778 - val_loss: 12.8938 - val_accuracy: 0.0236\n",
            "Epoch 245/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6081 - accuracy: 0.0780 - val_loss: 12.8980 - val_accuracy: 0.0247\n",
            "Epoch 246/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6081 - accuracy: 0.0781 - val_loss: 12.9059 - val_accuracy: 0.0236\n",
            "Epoch 247/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6082 - accuracy: 0.0778 - val_loss: 12.9073 - val_accuracy: 0.0232\n",
            "Epoch 248/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6079 - accuracy: 0.0773 - val_loss: 12.9140 - val_accuracy: 0.0241\n",
            "Epoch 249/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6079 - accuracy: 0.0776 - val_loss: 12.9184 - val_accuracy: 0.0242\n",
            "Epoch 250/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6080 - accuracy: 0.0774 - val_loss: 12.9213 - val_accuracy: 0.0240\n",
            "Epoch 251/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6078 - accuracy: 0.0778 - val_loss: 12.9229 - val_accuracy: 0.0240\n",
            "Epoch 252/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6075 - accuracy: 0.0779 - val_loss: 12.9351 - val_accuracy: 0.0246\n",
            "Epoch 253/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6075 - accuracy: 0.0778 - val_loss: 12.9384 - val_accuracy: 0.0238\n",
            "Epoch 254/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6073 - accuracy: 0.0780 - val_loss: 12.9439 - val_accuracy: 0.0237\n",
            "Epoch 255/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6073 - accuracy: 0.0772 - val_loss: 12.9408 - val_accuracy: 0.0234\n",
            "Epoch 256/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6074 - accuracy: 0.0782 - val_loss: 12.9480 - val_accuracy: 0.0238\n",
            "Epoch 257/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6074 - accuracy: 0.0775 - val_loss: 12.9478 - val_accuracy: 0.0234\n",
            "Epoch 258/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6071 - accuracy: 0.0782 - val_loss: 12.9566 - val_accuracy: 0.0238\n",
            "Epoch 259/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6071 - accuracy: 0.0772 - val_loss: 12.9575 - val_accuracy: 0.0233\n",
            "Epoch 260/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6070 - accuracy: 0.0781 - val_loss: 12.9624 - val_accuracy: 0.0235\n",
            "Epoch 261/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6065 - accuracy: 0.0775 - val_loss: 12.9677 - val_accuracy: 0.0236\n",
            "Epoch 262/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6066 - accuracy: 0.0778 - val_loss: 12.9712 - val_accuracy: 0.0248\n",
            "Epoch 263/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6068 - accuracy: 0.0772 - val_loss: 12.9738 - val_accuracy: 0.0237\n",
            "Epoch 264/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6066 - accuracy: 0.0782 - val_loss: 12.9785 - val_accuracy: 0.0244\n",
            "Epoch 265/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6065 - accuracy: 0.0779 - val_loss: 12.9779 - val_accuracy: 0.0230\n",
            "Epoch 266/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6065 - accuracy: 0.0775 - val_loss: 12.9864 - val_accuracy: 0.0236\n",
            "Epoch 267/500\n",
            "155/155 [==============================] - 15s 100ms/step - loss: 3.6065 - accuracy: 0.0779 - val_loss: 12.9944 - val_accuracy: 0.0245\n",
            "Epoch 268/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6064 - accuracy: 0.0779 - val_loss: 12.9913 - val_accuracy: 0.0240\n",
            "Epoch 269/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6064 - accuracy: 0.0776 - val_loss: 12.9975 - val_accuracy: 0.0236\n",
            "Epoch 270/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6060 - accuracy: 0.0779 - val_loss: 13.0034 - val_accuracy: 0.0229\n",
            "Epoch 271/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6058 - accuracy: 0.0787 - val_loss: 13.0077 - val_accuracy: 0.0232\n",
            "Epoch 272/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6060 - accuracy: 0.0778 - val_loss: 13.0081 - val_accuracy: 0.0239\n",
            "Epoch 273/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6061 - accuracy: 0.0776 - val_loss: 13.0130 - val_accuracy: 0.0236\n",
            "Epoch 274/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6060 - accuracy: 0.0776 - val_loss: 13.0154 - val_accuracy: 0.0234\n",
            "Epoch 275/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6061 - accuracy: 0.0773 - val_loss: 13.0200 - val_accuracy: 0.0244\n",
            "Epoch 276/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6058 - accuracy: 0.0785 - val_loss: 13.0190 - val_accuracy: 0.0238\n",
            "Epoch 277/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6057 - accuracy: 0.0774 - val_loss: 13.0281 - val_accuracy: 0.0239\n",
            "Epoch 278/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6055 - accuracy: 0.0782 - val_loss: 13.0289 - val_accuracy: 0.0240\n",
            "Epoch 279/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6057 - accuracy: 0.0773 - val_loss: 13.0275 - val_accuracy: 0.0240\n",
            "Epoch 280/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6056 - accuracy: 0.0785 - val_loss: 13.0354 - val_accuracy: 0.0243\n",
            "Epoch 281/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6057 - accuracy: 0.0776 - val_loss: 13.0407 - val_accuracy: 0.0236\n",
            "Epoch 282/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6053 - accuracy: 0.0780 - val_loss: 13.0395 - val_accuracy: 0.0240\n",
            "Epoch 283/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6053 - accuracy: 0.0782 - val_loss: 13.0430 - val_accuracy: 0.0236\n",
            "Epoch 284/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6053 - accuracy: 0.0786 - val_loss: 13.0495 - val_accuracy: 0.0236\n",
            "Epoch 285/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6052 - accuracy: 0.0774 - val_loss: 13.0515 - val_accuracy: 0.0239\n",
            "Epoch 286/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6051 - accuracy: 0.0776 - val_loss: 13.0548 - val_accuracy: 0.0245\n",
            "Epoch 287/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6053 - accuracy: 0.0785 - val_loss: 13.0605 - val_accuracy: 0.0238\n",
            "Epoch 288/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6051 - accuracy: 0.0773 - val_loss: 13.0608 - val_accuracy: 0.0244\n",
            "Epoch 289/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6052 - accuracy: 0.0775 - val_loss: 13.0673 - val_accuracy: 0.0246\n",
            "Epoch 290/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6049 - accuracy: 0.0774 - val_loss: 13.0668 - val_accuracy: 0.0244\n",
            "Epoch 291/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6046 - accuracy: 0.0785 - val_loss: 13.0751 - val_accuracy: 0.0245\n",
            "Epoch 292/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6048 - accuracy: 0.0779 - val_loss: 13.0753 - val_accuracy: 0.0242\n",
            "Epoch 293/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6048 - accuracy: 0.0780 - val_loss: 13.0772 - val_accuracy: 0.0233\n",
            "Epoch 294/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6047 - accuracy: 0.0774 - val_loss: 13.0821 - val_accuracy: 0.0227\n",
            "Epoch 295/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6043 - accuracy: 0.0784 - val_loss: 13.0835 - val_accuracy: 0.0237\n",
            "Epoch 296/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6046 - accuracy: 0.0779 - val_loss: 13.0867 - val_accuracy: 0.0227\n",
            "Epoch 297/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6045 - accuracy: 0.0772 - val_loss: 13.0888 - val_accuracy: 0.0233\n",
            "Epoch 298/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6043 - accuracy: 0.0775 - val_loss: 13.0910 - val_accuracy: 0.0234\n",
            "Epoch 299/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6045 - accuracy: 0.0781 - val_loss: 13.0964 - val_accuracy: 0.0244\n",
            "Epoch 300/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6041 - accuracy: 0.0785 - val_loss: 13.0975 - val_accuracy: 0.0234\n",
            "Epoch 301/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6043 - accuracy: 0.0779 - val_loss: 13.1028 - val_accuracy: 0.0236\n",
            "Epoch 302/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6043 - accuracy: 0.0780 - val_loss: 13.1024 - val_accuracy: 0.0237\n",
            "Epoch 303/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6043 - accuracy: 0.0788 - val_loss: 13.1083 - val_accuracy: 0.0236\n",
            "Epoch 304/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6042 - accuracy: 0.0779 - val_loss: 13.1130 - val_accuracy: 0.0238\n",
            "Epoch 305/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6043 - accuracy: 0.0773 - val_loss: 13.1131 - val_accuracy: 0.0242\n",
            "Epoch 306/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6042 - accuracy: 0.0778 - val_loss: 13.1189 - val_accuracy: 0.0242\n",
            "Epoch 307/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6039 - accuracy: 0.0771 - val_loss: 13.1189 - val_accuracy: 0.0235\n",
            "Epoch 308/500\n",
            "155/155 [==============================] - 23s 150ms/step - loss: 3.6041 - accuracy: 0.0775 - val_loss: 13.1202 - val_accuracy: 0.0242\n",
            "Epoch 309/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6041 - accuracy: 0.0781 - val_loss: 13.1232 - val_accuracy: 0.0236\n",
            "Epoch 310/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6038 - accuracy: 0.0773 - val_loss: 13.1241 - val_accuracy: 0.0237\n",
            "Epoch 311/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6037 - accuracy: 0.0782 - val_loss: 13.1304 - val_accuracy: 0.0234\n",
            "Epoch 312/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6039 - accuracy: 0.0779 - val_loss: 13.1304 - val_accuracy: 0.0229\n",
            "Epoch 313/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6036 - accuracy: 0.0776 - val_loss: 13.1359 - val_accuracy: 0.0234\n",
            "Epoch 314/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6039 - accuracy: 0.0778 - val_loss: 13.1392 - val_accuracy: 0.0238\n",
            "Epoch 315/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6037 - accuracy: 0.0780 - val_loss: 13.1414 - val_accuracy: 0.0240\n",
            "Epoch 316/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6038 - accuracy: 0.0777 - val_loss: 13.1431 - val_accuracy: 0.0236\n",
            "Epoch 317/500\n",
            "155/155 [==============================] - 16s 100ms/step - loss: 3.6035 - accuracy: 0.0782 - val_loss: 13.1452 - val_accuracy: 0.0244\n",
            "Epoch 318/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6035 - accuracy: 0.0772 - val_loss: 13.1492 - val_accuracy: 0.0241\n",
            "Epoch 319/500\n",
            "155/155 [==============================] - 17s 107ms/step - loss: 3.6035 - accuracy: 0.0779 - val_loss: 13.1500 - val_accuracy: 0.0244\n",
            "Epoch 320/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6037 - accuracy: 0.0777 - val_loss: 13.1537 - val_accuracy: 0.0235\n",
            "Epoch 321/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6033 - accuracy: 0.0780 - val_loss: 13.1558 - val_accuracy: 0.0233\n",
            "Epoch 322/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6032 - accuracy: 0.0774 - val_loss: 13.1596 - val_accuracy: 0.0238\n",
            "Epoch 323/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6032 - accuracy: 0.0780 - val_loss: 13.1640 - val_accuracy: 0.0245\n",
            "Epoch 324/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6033 - accuracy: 0.0772 - val_loss: 13.1646 - val_accuracy: 0.0244\n",
            "Epoch 325/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6033 - accuracy: 0.0778 - val_loss: 13.1634 - val_accuracy: 0.0241\n",
            "Epoch 326/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6031 - accuracy: 0.0778 - val_loss: 13.1671 - val_accuracy: 0.0238\n",
            "Epoch 327/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6029 - accuracy: 0.0774 - val_loss: 13.1721 - val_accuracy: 0.0243\n",
            "Epoch 328/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6030 - accuracy: 0.0780 - val_loss: 13.1763 - val_accuracy: 0.0247\n",
            "Epoch 329/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6032 - accuracy: 0.0774 - val_loss: 13.1762 - val_accuracy: 0.0233\n",
            "Epoch 330/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6029 - accuracy: 0.0774 - val_loss: 13.1827 - val_accuracy: 0.0245\n",
            "Epoch 331/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6031 - accuracy: 0.0783 - val_loss: 13.1778 - val_accuracy: 0.0237\n",
            "Epoch 332/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6030 - accuracy: 0.0776 - val_loss: 13.1836 - val_accuracy: 0.0237\n",
            "Epoch 333/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6029 - accuracy: 0.0774 - val_loss: 13.1861 - val_accuracy: 0.0231\n",
            "Epoch 334/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6029 - accuracy: 0.0777 - val_loss: 13.1916 - val_accuracy: 0.0241\n",
            "Epoch 335/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6031 - accuracy: 0.0769 - val_loss: 13.1903 - val_accuracy: 0.0241\n",
            "Epoch 336/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6029 - accuracy: 0.0778 - val_loss: 13.1907 - val_accuracy: 0.0238\n",
            "Epoch 337/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6027 - accuracy: 0.0781 - val_loss: 13.1979 - val_accuracy: 0.0229\n",
            "Epoch 338/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6028 - accuracy: 0.0774 - val_loss: 13.1985 - val_accuracy: 0.0235\n",
            "Epoch 339/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6026 - accuracy: 0.0777 - val_loss: 13.2013 - val_accuracy: 0.0240\n",
            "Epoch 340/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6027 - accuracy: 0.0778 - val_loss: 13.2019 - val_accuracy: 0.0238\n",
            "Epoch 341/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6028 - accuracy: 0.0769 - val_loss: 13.2039 - val_accuracy: 0.0237\n",
            "Epoch 342/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6027 - accuracy: 0.0778 - val_loss: 13.2029 - val_accuracy: 0.0239\n",
            "Epoch 343/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6024 - accuracy: 0.0773 - val_loss: 13.2140 - val_accuracy: 0.0233\n",
            "Epoch 344/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6024 - accuracy: 0.0783 - val_loss: 13.2121 - val_accuracy: 0.0245\n",
            "Epoch 345/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6025 - accuracy: 0.0773 - val_loss: 13.2135 - val_accuracy: 0.0228\n",
            "Epoch 346/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6024 - accuracy: 0.0777 - val_loss: 13.2122 - val_accuracy: 0.0235\n",
            "Epoch 347/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6026 - accuracy: 0.0779 - val_loss: 13.2186 - val_accuracy: 0.0233\n",
            "Epoch 348/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6023 - accuracy: 0.0774 - val_loss: 13.2241 - val_accuracy: 0.0234\n",
            "Epoch 349/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6025 - accuracy: 0.0778 - val_loss: 13.2210 - val_accuracy: 0.0234\n",
            "Epoch 350/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0777 - val_loss: 13.2226 - val_accuracy: 0.0243\n",
            "Epoch 351/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0775 - val_loss: 13.2258 - val_accuracy: 0.0237\n",
            "Epoch 352/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0779 - val_loss: 13.2274 - val_accuracy: 0.0234\n",
            "Epoch 353/500\n",
            "155/155 [==============================] - 16s 101ms/step - loss: 3.6023 - accuracy: 0.0780 - val_loss: 13.2307 - val_accuracy: 0.0241\n",
            "Epoch 354/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0776 - val_loss: 13.2331 - val_accuracy: 0.0236\n",
            "Epoch 355/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6023 - accuracy: 0.0778 - val_loss: 13.2348 - val_accuracy: 0.0241\n",
            "Epoch 356/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0784 - val_loss: 13.2377 - val_accuracy: 0.0234\n",
            "Epoch 357/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6021 - accuracy: 0.0777 - val_loss: 13.2384 - val_accuracy: 0.0232\n",
            "Epoch 358/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6022 - accuracy: 0.0783 - val_loss: 13.2426 - val_accuracy: 0.0240\n",
            "Epoch 359/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.6020 - accuracy: 0.0777 - val_loss: 13.2404 - val_accuracy: 0.0231\n",
            "Epoch 360/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6019 - accuracy: 0.0775 - val_loss: 13.2426 - val_accuracy: 0.0238\n",
            "Epoch 361/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6020 - accuracy: 0.0784 - val_loss: 13.2518 - val_accuracy: 0.0232\n",
            "Epoch 362/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6021 - accuracy: 0.0772 - val_loss: 13.2492 - val_accuracy: 0.0244\n",
            "Epoch 363/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6020 - accuracy: 0.0777 - val_loss: 13.2534 - val_accuracy: 0.0243\n",
            "Epoch 364/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6020 - accuracy: 0.0780 - val_loss: 13.2554 - val_accuracy: 0.0244\n",
            "Epoch 365/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6020 - accuracy: 0.0772 - val_loss: 13.2569 - val_accuracy: 0.0242\n",
            "Epoch 366/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6019 - accuracy: 0.0775 - val_loss: 13.2545 - val_accuracy: 0.0241\n",
            "Epoch 367/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6018 - accuracy: 0.0783 - val_loss: 13.2628 - val_accuracy: 0.0245\n",
            "Epoch 368/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6017 - accuracy: 0.0784 - val_loss: 13.2605 - val_accuracy: 0.0236\n",
            "Epoch 369/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6018 - accuracy: 0.0779 - val_loss: 13.2605 - val_accuracy: 0.0233\n",
            "Epoch 370/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6016 - accuracy: 0.0771 - val_loss: 13.2675 - val_accuracy: 0.0236\n",
            "Epoch 371/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6017 - accuracy: 0.0776 - val_loss: 13.2621 - val_accuracy: 0.0237\n",
            "Epoch 372/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6015 - accuracy: 0.0783 - val_loss: 13.2674 - val_accuracy: 0.0236\n",
            "Epoch 373/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6016 - accuracy: 0.0773 - val_loss: 13.2702 - val_accuracy: 0.0240\n",
            "Epoch 374/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6015 - accuracy: 0.0777 - val_loss: 13.2727 - val_accuracy: 0.0248\n",
            "Epoch 375/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6017 - accuracy: 0.0780 - val_loss: 13.2736 - val_accuracy: 0.0240\n",
            "Epoch 376/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6016 - accuracy: 0.0773 - val_loss: 13.2746 - val_accuracy: 0.0241\n",
            "Epoch 377/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6016 - accuracy: 0.0776 - val_loss: 13.2767 - val_accuracy: 0.0242\n",
            "Epoch 378/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.6017 - accuracy: 0.0776 - val_loss: 13.2773 - val_accuracy: 0.0230\n",
            "Epoch 379/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6016 - accuracy: 0.0771 - val_loss: 13.2836 - val_accuracy: 0.0245\n",
            "Epoch 380/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6014 - accuracy: 0.0776 - val_loss: 13.2813 - val_accuracy: 0.0231\n",
            "Epoch 381/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6015 - accuracy: 0.0777 - val_loss: 13.2845 - val_accuracy: 0.0237\n",
            "Epoch 382/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6016 - accuracy: 0.0784 - val_loss: 13.2850 - val_accuracy: 0.0244\n",
            "Epoch 383/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6015 - accuracy: 0.0780 - val_loss: 13.2873 - val_accuracy: 0.0230\n",
            "Epoch 384/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6014 - accuracy: 0.0771 - val_loss: 13.2905 - val_accuracy: 0.0246\n",
            "Epoch 385/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6015 - accuracy: 0.0775 - val_loss: 13.2932 - val_accuracy: 0.0237\n",
            "Epoch 386/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6013 - accuracy: 0.0779 - val_loss: 13.2916 - val_accuracy: 0.0229\n",
            "Epoch 387/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6015 - accuracy: 0.0770 - val_loss: 13.2967 - val_accuracy: 0.0231\n",
            "Epoch 388/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6011 - accuracy: 0.0777 - val_loss: 13.2996 - val_accuracy: 0.0234\n",
            "Epoch 389/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6011 - accuracy: 0.0778 - val_loss: 13.2953 - val_accuracy: 0.0231\n",
            "Epoch 390/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6010 - accuracy: 0.0776 - val_loss: 13.2994 - val_accuracy: 0.0243\n",
            "Epoch 391/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6013 - accuracy: 0.0775 - val_loss: 13.2988 - val_accuracy: 0.0236\n",
            "Epoch 392/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6010 - accuracy: 0.0776 - val_loss: 13.3032 - val_accuracy: 0.0227\n",
            "Epoch 393/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6008 - accuracy: 0.0784 - val_loss: 13.3060 - val_accuracy: 0.0239\n",
            "Epoch 394/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0785 - val_loss: 13.3068 - val_accuracy: 0.0239\n",
            "Epoch 395/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6011 - accuracy: 0.0777 - val_loss: 13.3028 - val_accuracy: 0.0233\n",
            "Epoch 396/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6012 - accuracy: 0.0765 - val_loss: 13.3082 - val_accuracy: 0.0235\n",
            "Epoch 397/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6010 - accuracy: 0.0775 - val_loss: 13.3115 - val_accuracy: 0.0241\n",
            "Epoch 398/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0773 - val_loss: 13.3134 - val_accuracy: 0.0250\n",
            "Epoch 399/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0768 - val_loss: 13.3137 - val_accuracy: 0.0241\n",
            "Epoch 400/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6010 - accuracy: 0.0781 - val_loss: 13.3148 - val_accuracy: 0.0238\n",
            "Epoch 401/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6011 - accuracy: 0.0777 - val_loss: 13.3170 - val_accuracy: 0.0242\n",
            "Epoch 402/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6009 - accuracy: 0.0777 - val_loss: 13.3176 - val_accuracy: 0.0232\n",
            "Epoch 403/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0777 - val_loss: 13.3217 - val_accuracy: 0.0243\n",
            "Epoch 404/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0774 - val_loss: 13.3227 - val_accuracy: 0.0239\n",
            "Epoch 405/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6008 - accuracy: 0.0776 - val_loss: 13.3238 - val_accuracy: 0.0244\n",
            "Epoch 406/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0777 - val_loss: 13.3252 - val_accuracy: 0.0243\n",
            "Epoch 407/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6010 - accuracy: 0.0781 - val_loss: 13.3272 - val_accuracy: 0.0243\n",
            "Epoch 408/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6009 - accuracy: 0.0778 - val_loss: 13.3265 - val_accuracy: 0.0237\n",
            "Epoch 409/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6009 - accuracy: 0.0776 - val_loss: 13.3268 - val_accuracy: 0.0232\n",
            "Epoch 410/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0779 - val_loss: 13.3269 - val_accuracy: 0.0240\n",
            "Epoch 411/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6008 - accuracy: 0.0779 - val_loss: 13.3323 - val_accuracy: 0.0246\n",
            "Epoch 412/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6008 - accuracy: 0.0782 - val_loss: 13.3327 - val_accuracy: 0.0238\n",
            "Epoch 413/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0773 - val_loss: 13.3367 - val_accuracy: 0.0239\n",
            "Epoch 414/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6008 - accuracy: 0.0779 - val_loss: 13.3399 - val_accuracy: 0.0238\n",
            "Epoch 415/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6006 - accuracy: 0.0772 - val_loss: 13.3360 - val_accuracy: 0.0240\n",
            "Epoch 416/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0775 - val_loss: 13.3383 - val_accuracy: 0.0247\n",
            "Epoch 417/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6006 - accuracy: 0.0780 - val_loss: 13.3440 - val_accuracy: 0.0229\n",
            "Epoch 418/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0773 - val_loss: 13.3414 - val_accuracy: 0.0235\n",
            "Epoch 419/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0776 - val_loss: 13.3411 - val_accuracy: 0.0229\n",
            "Epoch 420/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6004 - accuracy: 0.0777 - val_loss: 13.3440 - val_accuracy: 0.0236\n",
            "Epoch 421/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6007 - accuracy: 0.0780 - val_loss: 13.3485 - val_accuracy: 0.0238\n",
            "Epoch 422/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0774 - val_loss: 13.3463 - val_accuracy: 0.0238\n",
            "Epoch 423/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6004 - accuracy: 0.0771 - val_loss: 13.3476 - val_accuracy: 0.0237\n",
            "Epoch 424/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6004 - accuracy: 0.0778 - val_loss: 13.3495 - val_accuracy: 0.0233\n",
            "Epoch 425/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0778 - val_loss: 13.3509 - val_accuracy: 0.0233\n",
            "Epoch 426/500\n",
            "155/155 [==============================] - 16s 102ms/step - loss: 3.6004 - accuracy: 0.0769 - val_loss: 13.3538 - val_accuracy: 0.0235\n",
            "Epoch 427/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6004 - accuracy: 0.0776 - val_loss: 13.3574 - val_accuracy: 0.0236\n",
            "Epoch 428/500\n",
            "155/155 [==============================] - 17s 107ms/step - loss: 3.6004 - accuracy: 0.0774 - val_loss: 13.3567 - val_accuracy: 0.0241\n",
            "Epoch 429/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6004 - accuracy: 0.0775 - val_loss: 13.3536 - val_accuracy: 0.0235\n",
            "Epoch 430/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0776 - val_loss: 13.3568 - val_accuracy: 0.0226\n",
            "Epoch 431/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0772 - val_loss: 13.3603 - val_accuracy: 0.0242\n",
            "Epoch 432/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6006 - accuracy: 0.0776 - val_loss: 13.3614 - val_accuracy: 0.0239\n",
            "Epoch 433/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6002 - accuracy: 0.0775 - val_loss: 13.3610 - val_accuracy: 0.0243\n",
            "Epoch 434/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6005 - accuracy: 0.0780 - val_loss: 13.3628 - val_accuracy: 0.0237\n",
            "Epoch 435/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6004 - accuracy: 0.0774 - val_loss: 13.3650 - val_accuracy: 0.0243\n",
            "Epoch 436/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6002 - accuracy: 0.0776 - val_loss: 13.3659 - val_accuracy: 0.0242\n",
            "Epoch 437/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6001 - accuracy: 0.0779 - val_loss: 13.3649 - val_accuracy: 0.0237\n",
            "Epoch 438/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6003 - accuracy: 0.0777 - val_loss: 13.3672 - val_accuracy: 0.0232\n",
            "Epoch 439/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6000 - accuracy: 0.0773 - val_loss: 13.3662 - val_accuracy: 0.0235\n",
            "Epoch 440/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6002 - accuracy: 0.0773 - val_loss: 13.3738 - val_accuracy: 0.0235\n",
            "Epoch 441/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6003 - accuracy: 0.0774 - val_loss: 13.3733 - val_accuracy: 0.0230\n",
            "Epoch 442/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6002 - accuracy: 0.0779 - val_loss: 13.3733 - val_accuracy: 0.0232\n",
            "Epoch 443/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6003 - accuracy: 0.0765 - val_loss: 13.3747 - val_accuracy: 0.0241\n",
            "Epoch 444/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6001 - accuracy: 0.0777 - val_loss: 13.3752 - val_accuracy: 0.0229\n",
            "Epoch 445/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6003 - accuracy: 0.0774 - val_loss: 13.3754 - val_accuracy: 0.0230\n",
            "Epoch 446/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6001 - accuracy: 0.0774 - val_loss: 13.3751 - val_accuracy: 0.0227\n",
            "Epoch 447/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6001 - accuracy: 0.0776 - val_loss: 13.3765 - val_accuracy: 0.0224\n",
            "Epoch 448/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6000 - accuracy: 0.0782 - val_loss: 13.3783 - val_accuracy: 0.0236\n",
            "Epoch 449/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6004 - accuracy: 0.0770 - val_loss: 13.3804 - val_accuracy: 0.0237\n",
            "Epoch 450/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6002 - accuracy: 0.0777 - val_loss: 13.3817 - val_accuracy: 0.0237\n",
            "Epoch 451/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6000 - accuracy: 0.0780 - val_loss: 13.3866 - val_accuracy: 0.0243\n",
            "Epoch 452/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.6002 - accuracy: 0.0771 - val_loss: 13.3856 - val_accuracy: 0.0235\n",
            "Epoch 453/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5999 - accuracy: 0.0774 - val_loss: 13.3855 - val_accuracy: 0.0238\n",
            "Epoch 454/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6000 - accuracy: 0.0778 - val_loss: 13.3837 - val_accuracy: 0.0236\n",
            "Epoch 455/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6000 - accuracy: 0.0772 - val_loss: 13.3866 - val_accuracy: 0.0240\n",
            "Epoch 456/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6001 - accuracy: 0.0765 - val_loss: 13.3888 - val_accuracy: 0.0241\n",
            "Epoch 457/500\n",
            "155/155 [==============================] - 16s 106ms/step - loss: 3.5999 - accuracy: 0.0774 - val_loss: 13.3889 - val_accuracy: 0.0240\n",
            "Epoch 458/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5999 - accuracy: 0.0772 - val_loss: 13.3933 - val_accuracy: 0.0237\n",
            "Epoch 459/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6000 - accuracy: 0.0783 - val_loss: 13.3916 - val_accuracy: 0.0233\n",
            "Epoch 460/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0778 - val_loss: 13.3945 - val_accuracy: 0.0237\n",
            "Epoch 461/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.6000 - accuracy: 0.0777 - val_loss: 13.3928 - val_accuracy: 0.0241\n",
            "Epoch 462/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5999 - accuracy: 0.0775 - val_loss: 13.3948 - val_accuracy: 0.0238\n",
            "Epoch 463/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.6001 - accuracy: 0.0776 - val_loss: 13.3953 - val_accuracy: 0.0236\n",
            "Epoch 464/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.6001 - accuracy: 0.0775 - val_loss: 13.3976 - val_accuracy: 0.0240\n",
            "Epoch 465/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5997 - accuracy: 0.0773 - val_loss: 13.3964 - val_accuracy: 0.0243\n",
            "Epoch 466/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5998 - accuracy: 0.0778 - val_loss: 13.3988 - val_accuracy: 0.0226\n",
            "Epoch 467/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5999 - accuracy: 0.0782 - val_loss: 13.3994 - val_accuracy: 0.0237\n",
            "Epoch 468/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5997 - accuracy: 0.0771 - val_loss: 13.4013 - val_accuracy: 0.0233\n",
            "Epoch 469/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0776 - val_loss: 13.4039 - val_accuracy: 0.0241\n",
            "Epoch 470/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5998 - accuracy: 0.0770 - val_loss: 13.4018 - val_accuracy: 0.0235\n",
            "Epoch 471/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5999 - accuracy: 0.0769 - val_loss: 13.4036 - val_accuracy: 0.0231\n",
            "Epoch 472/500\n",
            "155/155 [==============================] - 17s 108ms/step - loss: 3.5998 - accuracy: 0.0776 - val_loss: 13.4054 - val_accuracy: 0.0237\n",
            "Epoch 473/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0775 - val_loss: 13.4062 - val_accuracy: 0.0234\n",
            "Epoch 474/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5995 - accuracy: 0.0780 - val_loss: 13.4066 - val_accuracy: 0.0240\n",
            "Epoch 475/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.5994 - accuracy: 0.0773 - val_loss: 13.4133 - val_accuracy: 0.0242\n",
            "Epoch 476/500\n",
            "155/155 [==============================] - 16s 106ms/step - loss: 3.5995 - accuracy: 0.0776 - val_loss: 13.4082 - val_accuracy: 0.0234\n",
            "Epoch 477/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.5997 - accuracy: 0.0778 - val_loss: 13.4130 - val_accuracy: 0.0237\n",
            "Epoch 478/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5995 - accuracy: 0.0771 - val_loss: 13.4088 - val_accuracy: 0.0234\n",
            "Epoch 479/500\n",
            "155/155 [==============================] - 16s 106ms/step - loss: 3.5997 - accuracy: 0.0772 - val_loss: 13.4136 - val_accuracy: 0.0237\n",
            "Epoch 480/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0773 - val_loss: 13.4173 - val_accuracy: 0.0242\n",
            "Epoch 481/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.5998 - accuracy: 0.0776 - val_loss: 13.4173 - val_accuracy: 0.0240\n",
            "Epoch 482/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5996 - accuracy: 0.0779 - val_loss: 13.4150 - val_accuracy: 0.0246\n",
            "Epoch 483/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5995 - accuracy: 0.0777 - val_loss: 13.4152 - val_accuracy: 0.0228\n",
            "Epoch 484/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5995 - accuracy: 0.0778 - val_loss: 13.4189 - val_accuracy: 0.0238\n",
            "Epoch 485/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5995 - accuracy: 0.0776 - val_loss: 13.4209 - val_accuracy: 0.0239\n",
            "Epoch 486/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5996 - accuracy: 0.0778 - val_loss: 13.4168 - val_accuracy: 0.0238\n",
            "Epoch 487/500\n",
            "155/155 [==============================] - 16s 105ms/step - loss: 3.5994 - accuracy: 0.0776 - val_loss: 13.4231 - val_accuracy: 0.0243\n",
            "Epoch 488/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5993 - accuracy: 0.0776 - val_loss: 13.4196 - val_accuracy: 0.0229\n",
            "Epoch 489/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0771 - val_loss: 13.4214 - val_accuracy: 0.0231\n",
            "Epoch 490/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5994 - accuracy: 0.0778 - val_loss: 13.4250 - val_accuracy: 0.0239\n",
            "Epoch 491/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5998 - accuracy: 0.0773 - val_loss: 13.4225 - val_accuracy: 0.0239\n",
            "Epoch 492/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0777 - val_loss: 13.4232 - val_accuracy: 0.0233\n",
            "Epoch 493/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5992 - accuracy: 0.0778 - val_loss: 13.4253 - val_accuracy: 0.0235\n",
            "Epoch 494/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5994 - accuracy: 0.0779 - val_loss: 13.4268 - val_accuracy: 0.0238\n",
            "Epoch 495/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5994 - accuracy: 0.0774 - val_loss: 13.4271 - val_accuracy: 0.0230\n",
            "Epoch 496/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5993 - accuracy: 0.0774 - val_loss: 13.4253 - val_accuracy: 0.0233\n",
            "Epoch 497/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5996 - accuracy: 0.0773 - val_loss: 13.4255 - val_accuracy: 0.0233\n",
            "Epoch 498/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5993 - accuracy: 0.0775 - val_loss: 13.4349 - val_accuracy: 0.0235\n",
            "Epoch 499/500\n",
            "155/155 [==============================] - 16s 104ms/step - loss: 3.5993 - accuracy: 0.0776 - val_loss: 13.4322 - val_accuracy: 0.0236\n",
            "Epoch 500/500\n",
            "155/155 [==============================] - 16s 103ms/step - loss: 3.5993 - accuracy: 0.0773 - val_loss: 13.4295 - val_accuracy: 0.0241\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=500, verbose=1, batch_size=512, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-WycnX3zl3Tx",
        "outputId": "a7040a1b-3652-42cd-d39d-44a23e3660b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4026fd9990>]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'], color='green', label='Train Data')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Wl4eUZpvl7J3",
        "outputId": "85e2931f-677a-4e84-b8eb-0cfa3df4a996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4026f7f090>]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'], color='green', label='Train Data')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='Validation Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "iwDDlk79fYSe"
      },
      "outputs": [],
      "source": [
        "model.save('word2vec.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Model**"
      ],
      "metadata": {
        "id": "P4GvDkAcvmdg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "McWk2c7kfoOd"
      },
      "outputs": [],
      "source": [
        "# laod model\n",
        "model = load_model('word2vec.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JiFkSzhi52",
        "outputId": "6499268c-f69c-46c2-8229-e83550194365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f4026f31d50>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Mu08LLKqbUjL"
      },
      "outputs": [],
      "source": [
        "weights = model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT7U6Sw6xYql",
        "outputId": "6bb0508c-f0a9-4771-e9e7-d3e3cb3fb508"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.3678592 , -0.35041156, -0.5472734 , -0.707333  , -0.8379311 ,\n",
              "        0.21526782,  0.5348847 , -0.37712884, -0.1790406 , -0.06838758,\n",
              "       -0.7753943 ,  0.00430979,  0.8226259 , -0.3004043 , -0.15486704,\n",
              "        0.4198015 ,  0.78254235,  0.71474075, -0.49433383,  0.45515683,\n",
              "        0.11145765,  0.6082657 ,  0.17053723,  0.82410467, -0.04604195,\n",
              "        0.59913605,  0.30833507,  0.04826039, -0.185569  , -0.9114347 ,\n",
              "       -0.683399  , -0.60392755, -0.01325986,  0.34528697,  0.18896767,\n",
              "        0.3710613 , -0.12635884,  0.086489  ,  0.18441024, -0.7493928 ,\n",
              "        0.73838097,  0.48428702, -0.51301557, -0.5504357 ,  0.5049649 ,\n",
              "        0.25433883,  0.8603807 , -0.26184046,  0.4026695 , -0.08935367,\n",
              "       -0.35658374,  1.048677  , -0.12000211, -0.58423996, -1.0096934 ,\n",
              "        0.6490526 , -0.18603194, -0.5482508 ,  0.44427115, -0.12540224,\n",
              "        0.39631197,  0.2287674 , -0.10721198, -0.3848411 , -0.4588026 ,\n",
              "       -0.919718  , -0.20322919, -0.3585306 ,  0.22199608,  0.47130477,\n",
              "        0.66796917, -0.19705842, -0.56745625, -0.83257097,  0.04765534,\n",
              "        0.5750712 ,  0.3961459 ,  0.26732957,  0.774885  , -0.4486848 ,\n",
              "       -0.30342138,  0.29393056,  0.23350367, -0.31715512, -0.5843296 ,\n",
              "       -0.7642539 ,  0.41140276,  0.65307087, -0.08014528,  0.05038522,\n",
              "        0.45096323, -0.5931131 ,  0.08804054,  0.63001734, -0.10203288,\n",
              "       -0.46594685, -0.08293527,  0.03548169,  0.12149365, -0.15659048],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "weights[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "p4qSGi4xIBc3"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Ds2srxegG79R"
      },
      "outputs": [],
      "source": [
        "def get_most_similarity(word, model=model, tokenizer=tokenizer, n=15):\n",
        "  num_unique_words = len(tokenizer.word_index) + 1\n",
        "  word_to_sequences = tokenizer.texts_to_sequences([word])[0]\n",
        "  word_to_sequences_one_hot = to_categorical(word_to_sequences, num_unique_words)\n",
        "  prediction = model.predict(word_to_sequences_one_hot)[0]\n",
        "  index = np.argsort(prediction)[::-1][:n]\n",
        "  sequences_to_word = tokenizer.sequences_to_texts([index])[0]\n",
        "  most_similarity = sequences_to_word.split(' ')\n",
        "  return most_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdWkt3rtI5mW",
        "outputId": "adf344f2-0f9e-453e-c657-51f63ae86402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'عقل',\n",
              " 'آتش',\n",
              " 'عاشقان',\n",
              " 'جمله',\n",
              " 'شمس',\n",
              " 'جهان',\n",
              " 'گشت',\n",
              " 'ملک',\n",
              " 'دست',\n",
              " 'گشته',\n",
              " 'مست',\n",
              " 'شاه']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "get_most_similarity('عشق')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vOPqYELUQUGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "620a83f4-96b6-46b1-ef28-ca6d0e16bbd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['جان',\n",
              " 'دل',\n",
              " 'تن',\n",
              " 'عشق',\n",
              " 'جهان',\n",
              " 'فزا',\n",
              " 'آب',\n",
              " 'ساقی',\n",
              " 'گرد',\n",
              " 'دست',\n",
              " 'هزاران',\n",
              " 'ذره',\n",
              " 'چشم',\n",
              " 'عاشقان',\n",
              " 'جمله']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "get_most_similarity('جان')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('کنج')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmDO4rOtHVCr",
        "outputId": "29066f44-a451-48fd-9438-faa486acbdd8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عاشق',\n",
              " 'زندان',\n",
              " 'ای',\n",
              " 'درآرد',\n",
              " 'نرسم',\n",
              " 'نشین',\n",
              " 'کنجی',\n",
              " 'خلا',\n",
              " 'کنج',\n",
              " 'آشفته',\n",
              " 'شاهی',\n",
              " 'طلب',\n",
              " 'قدیمست',\n",
              " 'نماند',\n",
              " 'جمله']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EwloJphDiQuE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "word2vec_neural_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}