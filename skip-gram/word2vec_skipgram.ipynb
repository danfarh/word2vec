{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Word2Vec Skip-gram**"
      ],
      "metadata": {
        "id": "AaSAbwmsyvsy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1htD3uRTqfry"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "elTVD2pVOMFp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Reshape, Conv1D, MaxPool1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xCNiunBhTK"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--GFqd9iqyPb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4w3NERBvq55R",
        "outputId": "ce6d2ec9-c4b5-4498-c0f5-475d27f982d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   1\n",
              "0  ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...\n",
              "1  امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...\n",
              "2  خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...\n",
              "3  در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...\n",
              "4  ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8860960-e637-4ad1-a30e-233f52b3481c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8860960-e637-4ad1-a30e-233f52b3481c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8860960-e637-4ad1-a30e-233f52b3481c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8860960-e637-4ad1-a30e-233f52b3481c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckG4SpxpBv0v"
      },
      "source": [
        "**Read Stop-Words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1ET4Envq9WJ"
      },
      "outputs": [],
      "source": [
        "def read_stop_words(filename):\n",
        "  with open(filename) as stopwords_file:\n",
        "    stopwords = stopwords_file.readlines()\n",
        "  stopwords = [line.replace('\\n', '') for line in stopwords] \n",
        "  return stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcvHmY1GrB6m",
        "outputId": "bf6df2f6-5d66-4494-8cca-9a311d670154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1382\n"
          ]
        }
      ],
      "source": [
        "stopwords = read_stop_words('stopwords.txt')\n",
        "print(len(stopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrUF5WHobMYG"
      },
      "source": [
        "**hazm library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51aGKS8zcXBb",
        "outputId": "5ecbe916-4bf1-435d-e905-e650e516da55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394485 sha256=52d7ccd818418ca1e57a67ba31a2f8cb79bddba42ea2008b81772532b59d1667\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154474 sha256=cc24d8f6220fe38c34fa1490dd3e255d8086ef8d21173c895f111d1596eb9761\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "# install hazm library\n",
        "!pip install hazm\n",
        "from hazm import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efCRPjKQbXHH"
      },
      "source": [
        "### **Preprocess the text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCg2QfwVa_6C"
      },
      "outputs": [],
      "source": [
        "# preprocess the text\n",
        "def text_preprocess(data):\n",
        "  text = [line.replace('\\t', ' ') for line in data.values.flatten()]\n",
        "  text = [line.replace('-', ' ') for line in text]\n",
        "  text = [re.sub(\"\\d+\", \"\", t) for t in text]\n",
        "\n",
        "  word_tokenized = [word_tokenize(t) for t in text]\n",
        "  word_tokenized_filtered = [[w for w in sentence if w not in stopwords] for sentence in word_tokenized]\n",
        "\n",
        "  sentences = [' '.join(sentence) for sentence in word_tokenized_filtered]\n",
        "  sentences = [sentence for sentence in sentences if sentence != '']\n",
        "\n",
        "  return sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbJ_TpjbrR52"
      },
      "outputs": [],
      "source": [
        "sentences = text_preprocess(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EN2dI2uITsRP",
        "outputId": "3f638ba3-084b-4fe9-da30-469978f02202"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'رستخیز رحمت منتها آتشی افروخته بیشه اندیشه'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1buSxp96bxfF"
      },
      "source": [
        "### **get less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnVjtr5ldH0h"
      },
      "outputs": [],
      "source": [
        "def get_all_sentences():\n",
        "  all_sentences = ''\n",
        "  sentences = text_preprocess(data)\n",
        "  for sentence in sentences:\n",
        "    all_sentences += sentence\n",
        "    all_sentences += ' '\n",
        "\n",
        "  return all_sentences  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mjyKRbHeXGB"
      },
      "outputs": [],
      "source": [
        "def get_word_freq(vocabularies):\n",
        "  word_freq = []\n",
        "  for vocab in vocabularies:\n",
        "    word_freq.append(vocabularies.count(vocab))\n",
        "  return word_freq  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3BTyonArXoS"
      },
      "outputs": [],
      "source": [
        "# get the words that frequentes less than 2 times in the corpus\n",
        "def get_less_frequente_words():\n",
        "  low_frequency_words = []\n",
        "  all_sentences = get_all_sentences()\n",
        "  vocabularies = all_sentences.split(' ')\n",
        "  word_freq = get_word_freq(vocabularies)\n",
        "\n",
        "  for i in range(len(word_freq)):\n",
        "    if word_freq[i] < 2:\n",
        "      low_frequency_words.append(vocabularies[i])\n",
        "\n",
        "  return low_frequency_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i758iopdesxx"
      },
      "outputs": [],
      "source": [
        "less_frequente_words = get_less_frequente_words()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3CZ3SK3Obj",
        "outputId": "f8aa18aa-eb76-44c9-bbea-fcb808fcc77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6366\n"
          ]
        }
      ],
      "source": [
        "print(len(less_frequente_words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebfg1Rvyb-Gv"
      },
      "source": [
        "## **remove less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC7K9jAcv0Qz"
      },
      "outputs": [],
      "source": [
        "# remove the words that frequentes less than 2 times in the corpus\n",
        "def remove_less_frequente_words(less_frequente_words, sentences):\n",
        "  sentences_tokenized = [word_tokenize(sentence) for sentence in sentences]\n",
        "  sentences_tokenized_filtered = [[w for w in sentence if w not in less_frequente_words] for sentence in sentences_tokenized]\n",
        "  corpus = [' '.join(sentence) for sentence in sentences_tokenized_filtered]\n",
        "  corpus = [sentence for sentence in corpus if sentence != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH0VEdXFwS6L"
      },
      "outputs": [],
      "source": [
        "corpus = remove_less_frequente_words(less_frequente_words, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvdxpqaHzAnp",
        "outputId": "b79b2830-098c-4f57-da74-d439b9c36388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['رستخیز رحمت منتها آتشی افروخته بیشه اندیشه',\n",
              " 'خندان آمدی مفتاح زندان آمدی آمدی بخشش فضل خدا',\n",
              " 'خورشید حاجب تویی امید واجب تویی مطلب تویی طالب تویی منتها',\n",
              " 'سینه اندیشه آراسته حاجت روا',\n",
              " 'روح علم باقی بهانه دغل علت دوا',\n",
              " 'دغل کژ گنه کین مست مست نان شوربا',\n",
              " 'هل عقل هل نان نشاید ماجرا',\n",
              " 'تدبیر رنگ افکنی روم زنگ افکنی جنگ افکنی یری',\n",
              " 'پنهان گوش جان بهانه کسان جان رب زنان والله کیا',\n",
              " 'خامش رفتم پای علم کاغذ بنه بشکن قلم ساقی درآمد الصلا']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "corpus[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHH7-nVDcRAx"
      },
      "source": [
        "## **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xOHtNwUOAY1"
      },
      "outputs": [],
      "source": [
        "# tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeZyyz09OOBL"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rHUu4qzOWxT",
        "outputId": "fc46fb8b-60cb-45cb-d29b-fe223009c2f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('جان', 1),\n",
              " ('دل', 2),\n",
              " ('عشق', 3),\n",
              " ('آب', 4),\n",
              " ('چشم', 5),\n",
              " ('شب', 6),\n",
              " ('جهان', 7),\n",
              " ('شمس', 8),\n",
              " ('دست', 9),\n",
              " ('مست', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "list(tokenizer.word_index.items())[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmi-MUXBf4VU"
      },
      "outputs": [],
      "source": [
        " # find more stopwords by sorting the tokenizer word counts\n",
        "#  word_count_sorted = dict(sorted(tokenizer.word_counts.items(), reverse=False, key=lambda t: t[1]))\n",
        "#  word_count_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ElB_faJPCQs"
      },
      "outputs": [],
      "source": [
        "encoded = tokenizer.texts_to_sequences(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNgPCssskVPV",
        "outputId": "5ddcb291-aed7-4469-b91d-19bf1c4eb798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2726, 283, 1337, 397, 1610, 967, 143],\n",
              " [185, 568, 1124, 398, 568, 568, 830, 332, 23],\n",
              " [46, 2727, 29, 636, 2031, 29, 831, 29, 258, 29, 1337],\n",
              " [92, 143, 1338, 727, 728],\n",
              " [30, 221, 162, 399, 1611, 968, 244],\n",
              " [1611, 729, 2032, 569, 10, 10, 209, 2728],\n",
              " [464, 13, 464, 209, 1125, 419],\n",
              " [969, 104, 1612, 352, 1126, 1612, 192, 1612, 730],\n",
              " [77, 41, 1, 399, 1613, 1, 259, 245, 284, 1127],\n",
              " [201, 731, 56, 221, 2729, 377, 732, 1128, 31, 570, 186]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "encoded[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldaLQ0svKR1B"
      },
      "outputs": [],
      "source": [
        "num_all_words = sum(len(s) for s in encoded) # total number of words in the corpus\n",
        "num_unique_words = len(tokenizer.word_index) + 1  # total number of unique words in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwyN6alDj0Rl",
        "outputId": "ea5b8290-6908-4669-e574-30b262afc2f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32654, 4284)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "num_all_words, num_unique_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a--qhdFXzAh"
      },
      "source": [
        "### **Generate data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUFMB4csVOSc"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "window_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7mmQECLjEqz"
      },
      "outputs": [],
      "source": [
        "def generate_data(corpus, window_size, num_unique_words):\n",
        "    maxlen = window_size * 2\n",
        "    all_inputs = []\n",
        "    all_outputs = []\n",
        "    for words in corpus:\n",
        "      len_words = len(words)\n",
        "      for index,w in enumerate(words):\n",
        "        s = index - window_size\n",
        "        e = index + window_size + 1\n",
        "        for i in range(s, e):\n",
        "            if i != index and 0 <= i < len_words:\n",
        "              all_inputs.append(w) \n",
        "              #all_inputs.append(to_categorical(w, num_unique_words)) \n",
        "              all_outputs.append(to_categorical(words[i], num_unique_words))\n",
        "\n",
        "    return (np.array(all_inputs), np.array(all_outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-rdJV9GmsAu",
        "outputId": "0ad65224-0f4a-4fe8-cb57-cb5f99d5fc8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98832,), (98832, 4284))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Create training data\n",
        "X_train, y_train = generate_data(encoded, window_size, num_unique_words)\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDJ7gZp2yo8",
        "outputId": "86c82802-68c6-4f41-f766-84884f2bde74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2726, 2726,  283, ...,  619, 1810, 1810]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxGjSSyJzXu5",
        "outputId": "d1c4eeb5-edc2-4740-9b2a-5b229c408f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([], dtype=int64),)\n"
          ]
        }
      ],
      "source": [
        "# for i in X_train:\n",
        "#   print(np.where(i == 1))\n",
        "print(np.where(X_train[0] == 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mjVK7vmvwiW"
      },
      "source": [
        "## **Create Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zVNpd6yT7Wx"
      },
      "outputs": [],
      "source": [
        "embed_size=100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_unique_words, output_dim=embed_size, input_length=1, embeddings_initializer='glorot_uniform'))\n",
        "model.add(Reshape((embed_size, )))\n",
        "model.add(Dense(num_unique_words, activation='softmax', kernel_initializer='glorot_uniform'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCAYelLXEcXH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi8g7duhbFuV",
        "outputId": "a7214009-8ca4-4186-a70c-9dbfff213e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 100)            428400    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4284)              432684    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 861,084\n",
            "Trainable params: 861,084\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61aR17ijDIVc",
        "outputId": "4972d501-ff1c-4b98-afc6-803d31c0ddbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "97/97 [==============================] - 12s 116ms/step - loss: 8.3305 - accuracy: 0.0185\n",
            "Epoch 2/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 8.0868 - accuracy: 0.0278\n",
            "Epoch 3/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 7.6407 - accuracy: 0.0274\n",
            "Epoch 4/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 7.4582 - accuracy: 0.0292\n",
            "Epoch 5/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 7.3597 - accuracy: 0.0310\n",
            "Epoch 6/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 7.2707 - accuracy: 0.0345\n",
            "Epoch 7/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 7.1752 - accuracy: 0.0381\n",
            "Epoch 8/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 7.0710 - accuracy: 0.0421\n",
            "Epoch 9/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 6.9593 - accuracy: 0.0458\n",
            "Epoch 10/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 6.8412 - accuracy: 0.0503\n",
            "Epoch 11/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 6.7181 - accuracy: 0.0547\n",
            "Epoch 12/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 6.5920 - accuracy: 0.0587\n",
            "Epoch 13/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 6.4644 - accuracy: 0.0628\n",
            "Epoch 14/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 6.3376 - accuracy: 0.0663\n",
            "Epoch 15/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 6.2127 - accuracy: 0.0695\n",
            "Epoch 16/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 6.0905 - accuracy: 0.0723\n",
            "Epoch 17/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 5.9727 - accuracy: 0.0740\n",
            "Epoch 18/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 5.8590 - accuracy: 0.0758\n",
            "Epoch 19/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 5.7504 - accuracy: 0.0778\n",
            "Epoch 20/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 5.6466 - accuracy: 0.0781\n",
            "Epoch 21/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 5.5481 - accuracy: 0.0787\n",
            "Epoch 22/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 5.4548 - accuracy: 0.0793\n",
            "Epoch 23/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 5.3667 - accuracy: 0.0787\n",
            "Epoch 24/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 5.2837 - accuracy: 0.0786\n",
            "Epoch 25/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 5.2058 - accuracy: 0.0790\n",
            "Epoch 26/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 5.1326 - accuracy: 0.0789\n",
            "Epoch 27/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 5.0640 - accuracy: 0.0784\n",
            "Epoch 28/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.9996 - accuracy: 0.0785\n",
            "Epoch 29/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 4.9392 - accuracy: 0.0786\n",
            "Epoch 30/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.8825 - accuracy: 0.0787\n",
            "Epoch 31/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.8293 - accuracy: 0.0790\n",
            "Epoch 32/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.7792 - accuracy: 0.0788\n",
            "Epoch 33/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.7320 - accuracy: 0.0794\n",
            "Epoch 34/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.6876 - accuracy: 0.0800\n",
            "Epoch 35/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.6458 - accuracy: 0.0805\n",
            "Epoch 36/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.6065 - accuracy: 0.0805\n",
            "Epoch 37/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.5694 - accuracy: 0.0807\n",
            "Epoch 38/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.5342 - accuracy: 0.0813\n",
            "Epoch 39/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.5012 - accuracy: 0.0816\n",
            "Epoch 40/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 4.4701 - accuracy: 0.0817\n",
            "Epoch 41/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.4407 - accuracy: 0.0822\n",
            "Epoch 42/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.4130 - accuracy: 0.0828\n",
            "Epoch 43/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 4.3868 - accuracy: 0.0825\n",
            "Epoch 44/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.3619 - accuracy: 0.0827\n",
            "Epoch 45/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.3384 - accuracy: 0.0830\n",
            "Epoch 46/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.3162 - accuracy: 0.0832\n",
            "Epoch 47/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.2953 - accuracy: 0.0827\n",
            "Epoch 48/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.2751 - accuracy: 0.0822\n",
            "Epoch 49/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.2564 - accuracy: 0.0827\n",
            "Epoch 50/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.2385 - accuracy: 0.0826\n",
            "Epoch 51/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.2216 - accuracy: 0.0824\n",
            "Epoch 52/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.2057 - accuracy: 0.0821\n",
            "Epoch 53/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.1904 - accuracy: 0.0815\n",
            "Epoch 54/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 4.1759 - accuracy: 0.0817\n",
            "Epoch 55/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 4.1623 - accuracy: 0.0809\n",
            "Epoch 56/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.1491 - accuracy: 0.0809\n",
            "Epoch 57/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.1367 - accuracy: 0.0811\n",
            "Epoch 58/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.1249 - accuracy: 0.0810\n",
            "Epoch 59/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.1136 - accuracy: 0.0812\n",
            "Epoch 60/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 4.1028 - accuracy: 0.0806\n",
            "Epoch 61/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 4.0926 - accuracy: 0.0799\n",
            "Epoch 62/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.0828 - accuracy: 0.0799\n",
            "Epoch 63/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.0734 - accuracy: 0.0794\n",
            "Epoch 64/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 4.0644 - accuracy: 0.0789\n",
            "Epoch 65/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 4.0559 - accuracy: 0.0796\n",
            "Epoch 66/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 4.0478 - accuracy: 0.0793\n",
            "Epoch 67/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 4.0398 - accuracy: 0.0788\n",
            "Epoch 68/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 4.0322 - accuracy: 0.0790\n",
            "Epoch 69/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 4.0250 - accuracy: 0.0784\n",
            "Epoch 70/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.0181 - accuracy: 0.0790\n",
            "Epoch 71/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 4.0115 - accuracy: 0.0785\n",
            "Epoch 72/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 4.0051 - accuracy: 0.0781\n",
            "Epoch 73/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9987 - accuracy: 0.0778\n",
            "Epoch 74/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.9930 - accuracy: 0.0777\n",
            "Epoch 75/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9871 - accuracy: 0.0780\n",
            "Epoch 76/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9818 - accuracy: 0.0784\n",
            "Epoch 77/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9764 - accuracy: 0.0775\n",
            "Epoch 78/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 3.9713 - accuracy: 0.0775\n",
            "Epoch 79/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9665 - accuracy: 0.0780\n",
            "Epoch 80/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9616 - accuracy: 0.0776\n",
            "Epoch 81/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.9569 - accuracy: 0.0776\n",
            "Epoch 82/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9525 - accuracy: 0.0775\n",
            "Epoch 83/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.9482 - accuracy: 0.0771\n",
            "Epoch 84/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9441 - accuracy: 0.0769\n",
            "Epoch 85/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9400 - accuracy: 0.0765\n",
            "Epoch 86/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9362 - accuracy: 0.0774\n",
            "Epoch 87/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9324 - accuracy: 0.0776\n",
            "Epoch 88/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 3.9288 - accuracy: 0.0757\n",
            "Epoch 89/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9252 - accuracy: 0.0771\n",
            "Epoch 90/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9217 - accuracy: 0.0765\n",
            "Epoch 91/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.9184 - accuracy: 0.0766\n",
            "Epoch 92/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.9149 - accuracy: 0.0763\n",
            "Epoch 93/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9120 - accuracy: 0.0768\n",
            "Epoch 94/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9087 - accuracy: 0.0767\n",
            "Epoch 95/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9059 - accuracy: 0.0765\n",
            "Epoch 96/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9030 - accuracy: 0.0769\n",
            "Epoch 97/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.9002 - accuracy: 0.0767\n",
            "Epoch 98/300\n",
            "97/97 [==============================] - 11s 115ms/step - loss: 3.8975 - accuracy: 0.0765\n",
            "Epoch 99/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8949 - accuracy: 0.0764\n",
            "Epoch 100/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8922 - accuracy: 0.0760\n",
            "Epoch 101/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8896 - accuracy: 0.0759\n",
            "Epoch 102/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8873 - accuracy: 0.0766\n",
            "Epoch 103/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8848 - accuracy: 0.0762\n",
            "Epoch 104/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8822 - accuracy: 0.0759\n",
            "Epoch 105/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8801 - accuracy: 0.0763\n",
            "Epoch 106/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8780 - accuracy: 0.0755\n",
            "Epoch 107/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.8759 - accuracy: 0.0759\n",
            "Epoch 108/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.8738 - accuracy: 0.0760\n",
            "Epoch 109/300\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 3.8717 - accuracy: 0.0753\n",
            "Epoch 110/300\n",
            "97/97 [==============================] - 12s 125ms/step - loss: 3.8697 - accuracy: 0.0757\n",
            "Epoch 111/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.8677 - accuracy: 0.0749\n",
            "Epoch 112/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8658 - accuracy: 0.0756\n",
            "Epoch 113/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.8638 - accuracy: 0.0762\n",
            "Epoch 114/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8622 - accuracy: 0.0758\n",
            "Epoch 115/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8602 - accuracy: 0.0751\n",
            "Epoch 116/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8584 - accuracy: 0.0754\n",
            "Epoch 117/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8568 - accuracy: 0.0755\n",
            "Epoch 118/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8551 - accuracy: 0.0760\n",
            "Epoch 119/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8534 - accuracy: 0.0756\n",
            "Epoch 120/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8520 - accuracy: 0.0754\n",
            "Epoch 121/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8502 - accuracy: 0.0759\n",
            "Epoch 122/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8487 - accuracy: 0.0757\n",
            "Epoch 123/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8473 - accuracy: 0.0757\n",
            "Epoch 124/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8458 - accuracy: 0.0754\n",
            "Epoch 125/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8443 - accuracy: 0.0755\n",
            "Epoch 126/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8429 - accuracy: 0.0754\n",
            "Epoch 127/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8417 - accuracy: 0.0755\n",
            "Epoch 128/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8404 - accuracy: 0.0753\n",
            "Epoch 129/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8389 - accuracy: 0.0749\n",
            "Epoch 130/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8376 - accuracy: 0.0753\n",
            "Epoch 131/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.8363 - accuracy: 0.0757\n",
            "Epoch 132/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8349 - accuracy: 0.0751\n",
            "Epoch 133/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8339 - accuracy: 0.0751\n",
            "Epoch 134/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8327 - accuracy: 0.0754\n",
            "Epoch 135/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8314 - accuracy: 0.0754\n",
            "Epoch 136/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8303 - accuracy: 0.0750\n",
            "Epoch 137/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8291 - accuracy: 0.0752\n",
            "Epoch 138/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.8282 - accuracy: 0.0751\n",
            "Epoch 139/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.8269 - accuracy: 0.0750\n",
            "Epoch 140/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8259 - accuracy: 0.0758\n",
            "Epoch 141/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8250 - accuracy: 0.0750\n",
            "Epoch 142/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8238 - accuracy: 0.0754\n",
            "Epoch 143/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8230 - accuracy: 0.0754\n",
            "Epoch 144/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8218 - accuracy: 0.0752\n",
            "Epoch 145/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8211 - accuracy: 0.0750\n",
            "Epoch 146/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8200 - accuracy: 0.0748\n",
            "Epoch 147/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8190 - accuracy: 0.0751\n",
            "Epoch 148/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8181 - accuracy: 0.0757\n",
            "Epoch 149/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8171 - accuracy: 0.0753\n",
            "Epoch 150/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8162 - accuracy: 0.0750\n",
            "Epoch 151/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8153 - accuracy: 0.0753\n",
            "Epoch 152/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8144 - accuracy: 0.0750\n",
            "Epoch 153/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8137 - accuracy: 0.0749\n",
            "Epoch 154/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8129 - accuracy: 0.0753\n",
            "Epoch 155/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8122 - accuracy: 0.0750\n",
            "Epoch 156/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8112 - accuracy: 0.0754\n",
            "Epoch 157/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8106 - accuracy: 0.0749\n",
            "Epoch 158/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8098 - accuracy: 0.0751\n",
            "Epoch 159/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8090 - accuracy: 0.0749\n",
            "Epoch 160/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8082 - accuracy: 0.0753\n",
            "Epoch 161/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8075 - accuracy: 0.0749\n",
            "Epoch 162/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8068 - accuracy: 0.0748\n",
            "Epoch 163/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8061 - accuracy: 0.0748\n",
            "Epoch 164/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8053 - accuracy: 0.0756\n",
            "Epoch 165/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.8046 - accuracy: 0.0746\n",
            "Epoch 166/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8040 - accuracy: 0.0750\n",
            "Epoch 167/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8034 - accuracy: 0.0746\n",
            "Epoch 168/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8027 - accuracy: 0.0747\n",
            "Epoch 169/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.8020 - accuracy: 0.0744\n",
            "Epoch 170/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8014 - accuracy: 0.0743\n",
            "Epoch 171/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8009 - accuracy: 0.0748\n",
            "Epoch 172/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.8002 - accuracy: 0.0741\n",
            "Epoch 173/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7995 - accuracy: 0.0752\n",
            "Epoch 174/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7988 - accuracy: 0.0748\n",
            "Epoch 175/300\n",
            "97/97 [==============================] - 11s 116ms/step - loss: 3.7984 - accuracy: 0.0748\n",
            "Epoch 176/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7980 - accuracy: 0.0742\n",
            "Epoch 177/300\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 3.7973 - accuracy: 0.0746\n",
            "Epoch 178/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7967 - accuracy: 0.0751\n",
            "Epoch 179/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7962 - accuracy: 0.0746\n",
            "Epoch 180/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7956 - accuracy: 0.0747\n",
            "Epoch 181/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7951 - accuracy: 0.0753\n",
            "Epoch 182/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7945 - accuracy: 0.0744\n",
            "Epoch 183/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7939 - accuracy: 0.0749\n",
            "Epoch 184/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7934 - accuracy: 0.0748\n",
            "Epoch 185/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7932 - accuracy: 0.0747\n",
            "Epoch 186/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7926 - accuracy: 0.0740\n",
            "Epoch 187/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7920 - accuracy: 0.0747\n",
            "Epoch 188/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7916 - accuracy: 0.0749\n",
            "Epoch 189/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7911 - accuracy: 0.0748\n",
            "Epoch 190/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7908 - accuracy: 0.0744\n",
            "Epoch 191/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7901 - accuracy: 0.0747\n",
            "Epoch 192/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7896 - accuracy: 0.0748\n",
            "Epoch 193/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7892 - accuracy: 0.0750\n",
            "Epoch 194/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7888 - accuracy: 0.0747\n",
            "Epoch 195/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7883 - accuracy: 0.0747\n",
            "Epoch 196/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7879 - accuracy: 0.0744\n",
            "Epoch 197/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7875 - accuracy: 0.0748\n",
            "Epoch 198/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7871 - accuracy: 0.0747\n",
            "Epoch 199/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7865 - accuracy: 0.0746\n",
            "Epoch 200/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7863 - accuracy: 0.0750\n",
            "Epoch 201/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7859 - accuracy: 0.0746\n",
            "Epoch 202/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7854 - accuracy: 0.0748\n",
            "Epoch 203/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7850 - accuracy: 0.0744\n",
            "Epoch 204/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7848 - accuracy: 0.0744\n",
            "Epoch 205/300\n",
            "97/97 [==============================] - 12s 124ms/step - loss: 3.7843 - accuracy: 0.0742\n",
            "Epoch 206/300\n",
            "97/97 [==============================] - 13s 132ms/step - loss: 3.7841 - accuracy: 0.0746\n",
            "Epoch 207/300\n",
            "97/97 [==============================] - 12s 128ms/step - loss: 3.7837 - accuracy: 0.0743\n",
            "Epoch 208/300\n",
            "97/97 [==============================] - 12s 125ms/step - loss: 3.7831 - accuracy: 0.0744\n",
            "Epoch 209/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7827 - accuracy: 0.0745\n",
            "Epoch 210/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.7825 - accuracy: 0.0742\n",
            "Epoch 211/300\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 3.7822 - accuracy: 0.0750\n",
            "Epoch 212/300\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 3.7818 - accuracy: 0.0746\n",
            "Epoch 213/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7815 - accuracy: 0.0745\n",
            "Epoch 214/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7811 - accuracy: 0.0749\n",
            "Epoch 215/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7808 - accuracy: 0.0737\n",
            "Epoch 216/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7804 - accuracy: 0.0742\n",
            "Epoch 217/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7800 - accuracy: 0.0744\n",
            "Epoch 218/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7798 - accuracy: 0.0746\n",
            "Epoch 219/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7796 - accuracy: 0.0750\n",
            "Epoch 220/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7792 - accuracy: 0.0745\n",
            "Epoch 221/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7788 - accuracy: 0.0747\n",
            "Epoch 222/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7785 - accuracy: 0.0749\n",
            "Epoch 223/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7784 - accuracy: 0.0744\n",
            "Epoch 224/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7782 - accuracy: 0.0742\n",
            "Epoch 225/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7776 - accuracy: 0.0736\n",
            "Epoch 226/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7775 - accuracy: 0.0745\n",
            "Epoch 227/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7770 - accuracy: 0.0743\n",
            "Epoch 228/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7767 - accuracy: 0.0743\n",
            "Epoch 229/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7765 - accuracy: 0.0750\n",
            "Epoch 230/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7761 - accuracy: 0.0743\n",
            "Epoch 231/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7760 - accuracy: 0.0735\n",
            "Epoch 232/300\n",
            "97/97 [==============================] - 12s 124ms/step - loss: 3.7758 - accuracy: 0.0746\n",
            "Epoch 233/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7754 - accuracy: 0.0750\n",
            "Epoch 234/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.7751 - accuracy: 0.0747\n",
            "Epoch 235/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7748 - accuracy: 0.0745\n",
            "Epoch 236/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7748 - accuracy: 0.0741\n",
            "Epoch 237/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7744 - accuracy: 0.0747\n",
            "Epoch 238/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7741 - accuracy: 0.0747\n",
            "Epoch 239/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7739 - accuracy: 0.0747\n",
            "Epoch 240/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7737 - accuracy: 0.0740\n",
            "Epoch 241/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7734 - accuracy: 0.0739\n",
            "Epoch 242/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.7732 - accuracy: 0.0743\n",
            "Epoch 243/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7729 - accuracy: 0.0744\n",
            "Epoch 244/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7727 - accuracy: 0.0739\n",
            "Epoch 245/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7726 - accuracy: 0.0741\n",
            "Epoch 246/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7721 - accuracy: 0.0745\n",
            "Epoch 247/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7720 - accuracy: 0.0747\n",
            "Epoch 248/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7718 - accuracy: 0.0745\n",
            "Epoch 249/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7716 - accuracy: 0.0745\n",
            "Epoch 250/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7714 - accuracy: 0.0747\n",
            "Epoch 251/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7710 - accuracy: 0.0744\n",
            "Epoch 252/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7709 - accuracy: 0.0742\n",
            "Epoch 253/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7708 - accuracy: 0.0743\n",
            "Epoch 254/300\n",
            "97/97 [==============================] - 12s 118ms/step - loss: 3.7706 - accuracy: 0.0744\n",
            "Epoch 255/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7703 - accuracy: 0.0747\n",
            "Epoch 256/300\n",
            "97/97 [==============================] - 11s 117ms/step - loss: 3.7701 - accuracy: 0.0746\n",
            "Epoch 257/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7700 - accuracy: 0.0743\n",
            "Epoch 258/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7697 - accuracy: 0.0744\n",
            "Epoch 259/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7695 - accuracy: 0.0745\n",
            "Epoch 260/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7693 - accuracy: 0.0742\n",
            "Epoch 261/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7688 - accuracy: 0.0741\n",
            "Epoch 262/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7689 - accuracy: 0.0744\n",
            "Epoch 263/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7688 - accuracy: 0.0738\n",
            "Epoch 264/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7686 - accuracy: 0.0742\n",
            "Epoch 265/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7682 - accuracy: 0.0749\n",
            "Epoch 266/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7682 - accuracy: 0.0742\n",
            "Epoch 267/300\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 3.7680 - accuracy: 0.0745\n",
            "Epoch 268/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7678 - accuracy: 0.0741\n",
            "Epoch 269/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7676 - accuracy: 0.0744\n",
            "Epoch 270/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7673 - accuracy: 0.0740\n",
            "Epoch 271/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7672 - accuracy: 0.0745\n",
            "Epoch 272/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7672 - accuracy: 0.0734\n",
            "Epoch 273/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7671 - accuracy: 0.0735\n",
            "Epoch 274/300\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 3.7667 - accuracy: 0.0743\n",
            "Epoch 275/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7668 - accuracy: 0.0743\n",
            "Epoch 276/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7663 - accuracy: 0.0746\n",
            "Epoch 277/300\n",
            "97/97 [==============================] - 11s 119ms/step - loss: 3.7662 - accuracy: 0.0745\n",
            "Epoch 278/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7661 - accuracy: 0.0745\n",
            "Epoch 279/300\n",
            "97/97 [==============================] - 11s 118ms/step - loss: 3.7659 - accuracy: 0.0735\n",
            "Epoch 280/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7659 - accuracy: 0.0744\n",
            "Epoch 281/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7656 - accuracy: 0.0741\n",
            "Epoch 282/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7656 - accuracy: 0.0737\n",
            "Epoch 283/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7654 - accuracy: 0.0747\n",
            "Epoch 284/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7652 - accuracy: 0.0743\n",
            "Epoch 285/300\n",
            "97/97 [==============================] - 12s 119ms/step - loss: 3.7650 - accuracy: 0.0742\n",
            "Epoch 286/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7650 - accuracy: 0.0739\n",
            "Epoch 287/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7647 - accuracy: 0.0743\n",
            "Epoch 288/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7644 - accuracy: 0.0743\n",
            "Epoch 289/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.7647 - accuracy: 0.0738\n",
            "Epoch 290/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7643 - accuracy: 0.0742\n",
            "Epoch 291/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7641 - accuracy: 0.0740\n",
            "Epoch 292/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7640 - accuracy: 0.0742\n",
            "Epoch 293/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7636 - accuracy: 0.0750\n",
            "Epoch 294/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7637 - accuracy: 0.0741\n",
            "Epoch 295/300\n",
            "97/97 [==============================] - 12s 122ms/step - loss: 3.7636 - accuracy: 0.0738\n",
            "Epoch 296/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7634 - accuracy: 0.0734\n",
            "Epoch 297/300\n",
            "97/97 [==============================] - 12s 121ms/step - loss: 3.7634 - accuracy: 0.0742\n",
            "Epoch 298/300\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 3.7631 - accuracy: 0.0742\n",
            "Epoch 299/300\n",
            "97/97 [==============================] - 12s 123ms/step - loss: 3.7630 - accuracy: 0.0742\n",
            "Epoch 300/300\n",
            "97/97 [==============================] - 12s 120ms/step - loss: 3.7630 - accuracy: 0.0743\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=300, verbose=1, batch_size=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Model**"
      ],
      "metadata": {
        "id": "NA39bFhtxNeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwDDlk79fYSe"
      },
      "outputs": [],
      "source": [
        "model.save('model_skipgram.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4GvDkAcvmdg"
      },
      "source": [
        "## **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "McWk2c7kfoOd"
      },
      "outputs": [],
      "source": [
        "# laod model\n",
        "model = load_model('model_skipgram.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JiFkSzhi52",
        "outputId": "62f3852a-066c-4f9f-e6c7-2c47f32822ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f4c12f59290>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dglp04EQwCPI"
      },
      "source": [
        "### **Get Most Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "p4qSGi4xIBc3"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ds2srxegG79R"
      },
      "outputs": [],
      "source": [
        "def get_most_similarity(word, model=model, tokenizer=tokenizer, n=15):\n",
        "  num_unique_words = len(tokenizer.word_index) + 1\n",
        "  word_to_sequences = tokenizer.texts_to_sequences([word])[0]\n",
        "  prediction = model.predict(word_to_sequences)[0]\n",
        "  index = np.argsort(prediction)[::-1][:n]\n",
        "  sequences_to_word = tokenizer.sequences_to_texts([index])[0]\n",
        "  most_similarity = sequences_to_word.split(' ')\n",
        "  return most_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdWkt3rtI5mW",
        "outputId": "ee1ae389-fbdf-42f9-ce8a-c0b497e83a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'عقل',\n",
              " 'آتش',\n",
              " 'جمله',\n",
              " 'شاه',\n",
              " 'شمس',\n",
              " 'عاشقان',\n",
              " 'مست',\n",
              " 'دست',\n",
              " 'جهان',\n",
              " 'گشته',\n",
              " 'عالم',\n",
              " 'گذر']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "get_most_similarity('عشق')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOPqYELUQUGD",
        "outputId": "2b0e1acb-594f-4f54-e6a9-b3dbc4701ea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['تبریزی',\n",
              " 'تبریز',\n",
              " 'دین',\n",
              " 'الدین',\n",
              " 'الحق',\n",
              " 'مفخر',\n",
              " 'عشق',\n",
              " 'جان',\n",
              " 'خداوند',\n",
              " 'نور',\n",
              " 'الضحی',\n",
              " 'دل',\n",
              " 'مخدوم',\n",
              " 'شمس',\n",
              " 'دست']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "get_most_similarity('شمس')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmDO4rOtHVCr",
        "outputId": "e88dfcc5-dcea-43e3-c704-a83a43df1117"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عاشق',\n",
              " 'ای',\n",
              " 'خلا',\n",
              " 'کنجی',\n",
              " 'درآرد',\n",
              " 'زندان',\n",
              " 'نرسم',\n",
              " 'نشین',\n",
              " 'کنج',\n",
              " 'خری',\n",
              " 'درگاه',\n",
              " 'بهاری',\n",
              " 'متاع',\n",
              " 'خندان',\n",
              " 'طلب']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "get_most_similarity('کنج')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('گل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txWieAX77Ekj",
        "outputId": "d8cb8034-f6ae-49ac-8a90-b775c89b9b66"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['خار',\n",
              " 'آب',\n",
              " 'گل',\n",
              " 'بلبل',\n",
              " 'باغ',\n",
              " 'آتش',\n",
              " 'یار',\n",
              " 'ریحان',\n",
              " 'دل',\n",
              " 'چمن',\n",
              " 'گلزار',\n",
              " 'شکر',\n",
              " 'زمین',\n",
              " 'رعنا',\n",
              " 'جان']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('مست')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo3M1AAT7liK",
        "outputId": "1c8057b5-23f1-49c7-9c23-3d6680d0ef40"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مست',\n",
              " 'چشم',\n",
              " 'آمدست',\n",
              " 'جان',\n",
              " 'خاک',\n",
              " 'عشق',\n",
              " 'خراب',\n",
              " 'عقل',\n",
              " 'ره',\n",
              " 'دست',\n",
              " 'یار',\n",
              " 'جام',\n",
              " 'ماییم',\n",
              " 'پست',\n",
              " 'الست']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('دست')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzJA3Ld67pZF",
        "outputId": "54209c4b-a02b-46a1-ba79-a868afc8131e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['دست',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'پا',\n",
              " 'پای',\n",
              " 'عشق',\n",
              " 'جام',\n",
              " 'دهان',\n",
              " 'مست',\n",
              " 'شمس',\n",
              " 'دلم',\n",
              " 'شب',\n",
              " 'باده',\n",
              " 'کف',\n",
              " 'ساغر']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('عقل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOupDP_27wOj",
        "outputId": "50a14a24-41f6-40a0-8a3b-8fdb860d6d16"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'عقل',\n",
              " 'جان',\n",
              " 'مست',\n",
              " 'خار',\n",
              " 'دل',\n",
              " 'گل',\n",
              " 'بلا',\n",
              " 'سلطان',\n",
              " 'دین',\n",
              " 'قضا',\n",
              " 'روح',\n",
              " 'خط',\n",
              " 'جمله',\n",
              " 'عقیله']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('غم')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9cT8_q073oI",
        "outputId": "074d8dc2-ece9-4081-e9fd-b204df7058f2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['غم',\n",
              " 'دل',\n",
              " 'جان',\n",
              " 'شادی',\n",
              " 'برو',\n",
              " 'شاد',\n",
              " 'جهان',\n",
              " 'اندوه',\n",
              " 'آب',\n",
              " 'عشق',\n",
              " 'باده',\n",
              " 'رود',\n",
              " 'دست',\n",
              " 'لطف',\n",
              " 'عاشق']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('انگور')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UdR8Kxa79Sg",
        "outputId": "a6309116-4f8c-4b30-9e46-18cfb07c6a5c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['پخته',\n",
              " 'باغبان',\n",
              " 'غوره',\n",
              " 'نفی',\n",
              " 'شوره',\n",
              " 'شد',\n",
              " 'ای',\n",
              " 'شور',\n",
              " 'کدامین',\n",
              " 'دل',\n",
              " 'روضه',\n",
              " 'مستم',\n",
              " 'گور',\n",
              " 'برده',\n",
              " 'ساقیا']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('آب')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxOt5GEG8Bpb",
        "outputId": "5cd2fff6-6c21-4a42-c2d3-77ec58cc238a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['گل',\n",
              " 'آب',\n",
              " 'حیات',\n",
              " 'سنگ',\n",
              " 'جان',\n",
              " 'جوی',\n",
              " 'آتش',\n",
              " 'بحر',\n",
              " 'روان',\n",
              " 'جو',\n",
              " 'دل',\n",
              " 'حیوان',\n",
              " 'نان',\n",
              " 'چشمه',\n",
              " 'کوزه']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('آتش')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7XhG8738JAB",
        "outputId": "bb20536b-92b7-4fec-fd44-40d22b3f7845"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'آتش',\n",
              " 'آب',\n",
              " 'جان',\n",
              " 'گل',\n",
              " 'دل',\n",
              " 'برآوردم',\n",
              " 'مفرش',\n",
              " 'آفتاب',\n",
              " 'سوز',\n",
              " 'خلیل',\n",
              " 'فلک',\n",
              " 'زدی',\n",
              " 'جگر',\n",
              " 'خانه']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('شب')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrgHKete8PzV",
        "outputId": "a01a95ea-6874-4485-a020-90e4003a0830"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['شب',\n",
              " 'جان',\n",
              " 'مه',\n",
              " 'گشت',\n",
              " 'سحر',\n",
              " 'دل',\n",
              " 'ماه',\n",
              " 'دام',\n",
              " 'خلق',\n",
              " 'خواب',\n",
              " 'تیره',\n",
              " 'دست',\n",
              " 'شمع',\n",
              " 'سیاه',\n",
              " 'رخ']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('جهان')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxNZL-cc8VcR",
        "outputId": "dd366e19-2baa-4a8d-d302-6a9bb7916710"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['جان',\n",
              " 'جهان',\n",
              " 'دل',\n",
              " 'عشق',\n",
              " 'نهان',\n",
              " 'جمله',\n",
              " 'غم',\n",
              " 'شاه',\n",
              " 'گرد',\n",
              " 'تنگ',\n",
              " 'دید',\n",
              " 'آب',\n",
              " 'عاشق',\n",
              " 'ذره',\n",
              " 'کهی']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('دل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IHZs1JQ8aks",
        "outputId": "a0a2e397-683e-4330-c3c4-ccd11c7b8ea9"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['جان',\n",
              " 'دل',\n",
              " 'عشق',\n",
              " 'خانه',\n",
              " 'غم',\n",
              " 'دست',\n",
              " 'خون',\n",
              " 'جهان',\n",
              " 'تبریز',\n",
              " 'رود',\n",
              " 'سبک',\n",
              " 'تن',\n",
              " 'دین',\n",
              " 'چشم',\n",
              " 'آتش']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('مه')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkYawoaW8gDv",
        "outputId": "1ae53a48-3ed2-48cc-bec9-69b955494cdd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مه',\n",
              " 'نور',\n",
              " 'شب',\n",
              " 'رخ',\n",
              " 'خورشید',\n",
              " 'فلک',\n",
              " 'جان',\n",
              " 'ماه',\n",
              " 'لقایی',\n",
              " 'لقا',\n",
              " 'سجده',\n",
              " 'شمس',\n",
              " 'توبه',\n",
              " 'نهان',\n",
              " 'دیدن']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('نور')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN5MrmxD8ogt",
        "outputId": "d9f938f2-bdee-479b-e2d5-805b502034a2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مه',\n",
              " 'شمع',\n",
              " 'نور',\n",
              " 'شمس',\n",
              " 'نار',\n",
              " 'دل',\n",
              " 'شعله',\n",
              " 'تبریزی',\n",
              " 'عالم',\n",
              " 'آفتاب',\n",
              " 'دیدار',\n",
              " 'سایه',\n",
              " 'چشم',\n",
              " 'صبح',\n",
              " 'موسی']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "word2vec_skipgram.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}