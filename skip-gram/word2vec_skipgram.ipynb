{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Word2Vec Skip-gram**"
      ],
      "metadata": {
        "id": "AaSAbwmsyvsy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1htD3uRTqfry"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "elTVD2pVOMFp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Reshape, Conv1D, MaxPool1D, Dropout\n",
        "from tensorflow.keras.preprocessing.text import one_hot,Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1xCNiunBhTK"
      },
      "source": [
        "# **Read Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--GFqd9iqyPb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4w3NERBvq55R",
        "outputId": "5be4276c-c4aa-4319-e10d-7ea76c45c876"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   1\n",
              "0  ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...\n",
              "1  امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...\n",
              "2  خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...\n",
              "3  در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...\n",
              "4  ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73c7cca0-65fb-4b44-9b44-41ecf4b462a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی اف...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>خورشید را حاجب تویی، امید را واجب تویی\\tمطلب ت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی ب...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73c7cca0-65fb-4b44-9b44-41ecf4b462a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73c7cca0-65fb-4b44-9b44-41ecf4b462a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73c7cca0-65fb-4b44-9b44-41ecf4b462a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckG4SpxpBv0v"
      },
      "source": [
        "**Read Stop-Words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j1ET4Envq9WJ"
      },
      "outputs": [],
      "source": [
        "def read_stop_words(filename):\n",
        "  with open(filename) as stopwords_file:\n",
        "    stopwords = stopwords_file.readlines()\n",
        "  stopwords = [line.replace('\\n', '') for line in stopwords] \n",
        "  return stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcvHmY1GrB6m",
        "outputId": "75602a50-4174-4549-d3c4-9ff145a7ab3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1421\n"
          ]
        }
      ],
      "source": [
        "stopwords = read_stop_words('stopwords.txt')\n",
        "print(len(stopwords))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrUF5WHobMYG"
      },
      "source": [
        "**hazm library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51aGKS8zcXBb",
        "outputId": "76a2cb41-c071-4834-ad97-95674eca2d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 17.0 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 54.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394488 sha256=01a53434b51bc34dbd2d996462e13648669dc34b7a7a313539875b874922f93f\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154070 sha256=65c6e731d68884947ebd964828a41b3c212037d12555d1d8d7be95b16dfb8789\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "# install hazm library\n",
        "!pip install hazm\n",
        "from hazm import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efCRPjKQbXHH"
      },
      "source": [
        "### **Preprocess the text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nCg2QfwVa_6C"
      },
      "outputs": [],
      "source": [
        "# preprocess the text\n",
        "def text_preprocess(data):\n",
        "  text = [line.replace('\\t', ' ') for line in data.values.flatten()]\n",
        "  text = [line.replace('-', ' ') for line in text]\n",
        "  text = [re.sub(\"\\d+\", \"\", t) for t in text]\n",
        "\n",
        "  word_tokenized = [word_tokenize(t) for t in text]\n",
        "  word_tokenized_filtered = [[w for w in sentence if w not in stopwords] for sentence in word_tokenized]\n",
        "\n",
        "  sentences = [' '.join(sentence) for sentence in word_tokenized_filtered]\n",
        "  sentences = [sentence for sentence in sentences if sentence != '']\n",
        "\n",
        "  return sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BbJ_TpjbrR52"
      },
      "outputs": [],
      "source": [
        "sentences = text_preprocess(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EN2dI2uITsRP",
        "outputId": "afb81de2-113a-48d8-8c4b-b101e0a514b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'رستخیز رحمت منتها آتشی افروخته بیشه اندیشه'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1buSxp96bxfF"
      },
      "source": [
        "### **get less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VnVjtr5ldH0h"
      },
      "outputs": [],
      "source": [
        "def get_all_sentences():\n",
        "  all_sentences = ''\n",
        "  sentences = text_preprocess(data)\n",
        "  for sentence in sentences:\n",
        "    all_sentences += sentence\n",
        "    all_sentences += ' '\n",
        "  return all_sentences  \n",
        "\n",
        "def get_word_freq(vocabularies):\n",
        "  word_freq = []\n",
        "  for vocab in vocabularies:\n",
        "    word_freq.append(vocabularies.count(vocab))\n",
        "  return word_freq  \n",
        "\n",
        "# get the words that frequentes less than 2 times in the corpus\n",
        "def get_less_frequente_words():\n",
        "  low_frequency_words = []\n",
        "  all_sentences = get_all_sentences()\n",
        "  vocabularies = all_sentences.split(' ')\n",
        "  word_freq = get_word_freq(vocabularies)\n",
        "\n",
        "  for i in range(len(word_freq)):\n",
        "    if word_freq[i] < 2:\n",
        "      low_frequency_words.append(vocabularies[i])\n",
        "  return low_frequency_words   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "less_frequente_words = get_less_frequente_words()"
      ],
      "metadata": {
        "id": "m7L-K17EBNoG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebfg1Rvyb-Gv"
      },
      "source": [
        "## **remove less frequente words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vC7K9jAcv0Qz"
      },
      "outputs": [],
      "source": [
        "# remove the words that frequentes less than 2 times in the corpus\n",
        "def remove_less_frequente_words(less_frequente_words, sentences):\n",
        "  sentences_tokenized = [word_tokenize(sentence) for sentence in sentences]\n",
        "  sentences_tokenized_filtered = [[w for w in sentence if w not in less_frequente_words] for sentence in sentences_tokenized]\n",
        "  corpus = [' '.join(sentence) for sentence in sentences_tokenized_filtered]\n",
        "  corpus = [sentence for sentence in corpus if sentence != '']\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WH0VEdXFwS6L"
      },
      "outputs": [],
      "source": [
        "corpus = remove_less_frequente_words(less_frequente_words, sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvdxpqaHzAnp",
        "outputId": "de3a094f-6e68-4fa3-c833-b343279fc159"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['رستخیز رحمت منتها آتشی افروخته بیشه اندیشه',\n",
              " 'خندان آمدی مفتاح زندان آمدی آمدی بخشش فضل خدا',\n",
              " 'خورشید حاجب امید واجب مطلب طالب منتها',\n",
              " 'سینه اندیشه آراسته حاجت روا',\n",
              " 'روح علم باقی بهانه دغل علت دوا',\n",
              " 'دغل کژ گنه کین مست مست نان شوربا',\n",
              " 'هل عقل هل نان نشاید ماجرا',\n",
              " 'تدبیر رنگ افکنی روم زنگ افکنی جنگ افکنی',\n",
              " 'پنهان گوش جان بهانه کسان جان رب زنان والله کیا',\n",
              " 'خامش رفتم پای علم کاغذ بنه بشکن قلم ساقی درآمد الصلا']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "corpus[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHH7-nVDcRAx"
      },
      "source": [
        "## **Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0xOHtNwUOAY1"
      },
      "outputs": [],
      "source": [
        "# tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eeZyyz09OOBL"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rHUu4qzOWxT",
        "outputId": "3df01278-e893-4994-9e65-72cde7cb6bde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('جان', 1),\n",
              " ('دل', 2),\n",
              " ('عشق', 3),\n",
              " ('آب', 4),\n",
              " ('چشم', 5),\n",
              " ('شب', 6),\n",
              " ('جهان', 7),\n",
              " ('شمس', 8),\n",
              " ('دست', 9),\n",
              " ('مست', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "list(tokenizer.word_index.items())[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3ElB_faJPCQs"
      },
      "outputs": [],
      "source": [
        "encoded = tokenizer.texts_to_sequences(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNgPCssskVPV",
        "outputId": "a6350a7c-f4da-486a-f2bf-10334be80ab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2692, 272, 1310, 385, 1583, 940, 133],\n",
              " [174, 551, 1097, 386, 551, 551, 803, 320, 23],\n",
              " [45, 2693, 618, 2000, 804, 247, 1310],\n",
              " [88, 133, 1311, 704, 705],\n",
              " [29, 210, 152, 387, 1584, 941, 233],\n",
              " [1584, 706, 2001, 552, 10, 10, 198, 2694],\n",
              " [451, 13, 451, 198, 1098, 407],\n",
              " [942, 98, 1585, 340, 1099, 1585, 181, 1585],\n",
              " [74, 40, 1, 387, 1586, 1, 248, 234, 273, 1100],\n",
              " [190, 707, 55, 210, 2695, 365, 708, 1101, 30, 553, 175]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "encoded[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ldaLQ0svKR1B"
      },
      "outputs": [],
      "source": [
        "num_all_words = sum(len(s) for s in encoded) # total number of words in the corpus\n",
        "num_unique_words = len(tokenizer.word_index) + 1  # total number of unique words in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwyN6alDj0Rl",
        "outputId": "f711a933-f583-495b-a275-0831dc5e0f22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31950, 4250)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "num_all_words, num_unique_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a--qhdFXzAh"
      },
      "source": [
        "### **Generate data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iUFMB4csVOSc"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "window_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "i7mmQECLjEqz"
      },
      "outputs": [],
      "source": [
        "def generate_data(corpus, window_size, num_unique_words):\n",
        "    maxlen = window_size * 2\n",
        "    all_inputs = []\n",
        "    all_outputs = []\n",
        "    for words in corpus:\n",
        "      len_words = len(words)\n",
        "      for index,w in enumerate(words):\n",
        "        s = index - window_size\n",
        "        e = index + window_size + 1\n",
        "        for i in range(s, e):\n",
        "            if i != index and 0 <= i < len_words:\n",
        "              all_inputs.append(w) \n",
        "              all_outputs.append(to_categorical(words[i], num_unique_words))\n",
        "\n",
        "    return (np.array(all_inputs), np.array(all_outputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-rdJV9GmsAu",
        "outputId": "8e6ce618-a8be-4fca-cb20-b5907cafecdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((96036,), (96036, 4250))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Create training data\n",
        "X_train, y_train = generate_data(encoded, window_size, num_unique_words)\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDJ7gZp2yo8",
        "outputId": "32112f7a-e8de-4555-88c7-5e288146de90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2692, 2692,  272, ...,  601, 1782, 1782]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "X_train, y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mjVK7vmvwiW"
      },
      "source": [
        "## **Create Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "7zVNpd6yT7Wx"
      },
      "outputs": [],
      "source": [
        "embed_size=100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_unique_words, output_dim=embed_size, input_length=1, embeddings_initializer='glorot_uniform'))\n",
        "model.add(Reshape((embed_size, )))\n",
        "model.add(Dense(num_unique_words, activation='softmax', kernel_initializer='glorot_uniform'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YCAYelLXEcXH"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi8g7duhbFuV",
        "outputId": "f61c0fb3-ace2-4c2a-e800-bd7f6c54c7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1, 100)            425000    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4250)              429250    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 854,250\n",
            "Trainable params: 854,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61aR17ijDIVc",
        "outputId": "ed8bd117-f172-44c9-ed02-9c28f426bcc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 8.2677 - accuracy: 0.0219\n",
            "Epoch 2/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 7.7314 - accuracy: 0.0269\n",
            "Epoch 3/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 7.4519 - accuracy: 0.0290\n",
            "Epoch 4/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 7.3256 - accuracy: 0.0321\n",
            "Epoch 5/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 7.2040 - accuracy: 0.0377\n",
            "Epoch 6/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 7.0692 - accuracy: 0.0437\n",
            "Epoch 7/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 6.9214 - accuracy: 0.0494\n",
            "Epoch 8/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 6.7633 - accuracy: 0.0557\n",
            "Epoch 9/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 6.5988 - accuracy: 0.0609\n",
            "Epoch 10/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 6.4321 - accuracy: 0.0657\n",
            "Epoch 11/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 6.2667 - accuracy: 0.0694\n",
            "Epoch 12/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 6.1052 - accuracy: 0.0723\n",
            "Epoch 13/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 5.9499 - accuracy: 0.0755\n",
            "Epoch 14/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 5.8021 - accuracy: 0.0772\n",
            "Epoch 15/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 5.6627 - accuracy: 0.0786\n",
            "Epoch 16/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 5.5323 - accuracy: 0.0792\n",
            "Epoch 17/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 5.4106 - accuracy: 0.0788\n",
            "Epoch 18/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 5.2979 - accuracy: 0.0794\n",
            "Epoch 19/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 5.1941 - accuracy: 0.0788\n",
            "Epoch 20/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 5.0984 - accuracy: 0.0784\n",
            "Epoch 21/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 5.0105 - accuracy: 0.0785\n",
            "Epoch 22/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 4.9296 - accuracy: 0.0786\n",
            "Epoch 23/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.8550 - accuracy: 0.0785\n",
            "Epoch 24/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 4.7862 - accuracy: 0.0786\n",
            "Epoch 25/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.7228 - accuracy: 0.0791\n",
            "Epoch 26/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.6643 - accuracy: 0.0792\n",
            "Epoch 27/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.6102 - accuracy: 0.0792\n",
            "Epoch 28/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 4.5602 - accuracy: 0.0799\n",
            "Epoch 29/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 4.5140 - accuracy: 0.0798\n",
            "Epoch 30/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 4.4713 - accuracy: 0.0804\n",
            "Epoch 31/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 4.4317 - accuracy: 0.0804\n",
            "Epoch 32/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.3950 - accuracy: 0.0804\n",
            "Epoch 33/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 4.3610 - accuracy: 0.0808\n",
            "Epoch 34/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 4.3294 - accuracy: 0.0811\n",
            "Epoch 35/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.3002 - accuracy: 0.0805\n",
            "Epoch 36/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 4.2729 - accuracy: 0.0806\n",
            "Epoch 37/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 4.2476 - accuracy: 0.0801\n",
            "Epoch 38/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.2241 - accuracy: 0.0799\n",
            "Epoch 39/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.2021 - accuracy: 0.0791\n",
            "Epoch 40/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.1820 - accuracy: 0.0791\n",
            "Epoch 41/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 4.1629 - accuracy: 0.0787\n",
            "Epoch 42/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 4.1451 - accuracy: 0.0783\n",
            "Epoch 43/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 4.1285 - accuracy: 0.0783\n",
            "Epoch 44/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.1129 - accuracy: 0.0779\n",
            "Epoch 45/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.0984 - accuracy: 0.0772\n",
            "Epoch 46/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.0847 - accuracy: 0.0776\n",
            "Epoch 47/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 4.0720 - accuracy: 0.0774\n",
            "Epoch 48/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 4.0598 - accuracy: 0.0772\n",
            "Epoch 49/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 4.0488 - accuracy: 0.0765\n",
            "Epoch 50/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 4.0380 - accuracy: 0.0767\n",
            "Epoch 51/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 4.0279 - accuracy: 0.0764\n",
            "Epoch 52/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 4.0184 - accuracy: 0.0758\n",
            "Epoch 53/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 4.0094 - accuracy: 0.0763\n",
            "Epoch 54/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 4.0008 - accuracy: 0.0763\n",
            "Epoch 55/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9928 - accuracy: 0.0756\n",
            "Epoch 56/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9853 - accuracy: 0.0754\n",
            "Epoch 57/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9779 - accuracy: 0.0754\n",
            "Epoch 58/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9712 - accuracy: 0.0758\n",
            "Epoch 59/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9644 - accuracy: 0.0752\n",
            "Epoch 60/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.9583 - accuracy: 0.0745\n",
            "Epoch 61/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9524 - accuracy: 0.0749\n",
            "Epoch 62/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9465 - accuracy: 0.0746\n",
            "Epoch 63/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9413 - accuracy: 0.0749\n",
            "Epoch 64/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.9362 - accuracy: 0.0747\n",
            "Epoch 65/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9311 - accuracy: 0.0745\n",
            "Epoch 66/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9265 - accuracy: 0.0745\n",
            "Epoch 67/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.9219 - accuracy: 0.0745\n",
            "Epoch 68/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.9174 - accuracy: 0.0748\n",
            "Epoch 69/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.9133 - accuracy: 0.0746\n",
            "Epoch 70/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.9093 - accuracy: 0.0737\n",
            "Epoch 71/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9052 - accuracy: 0.0739\n",
            "Epoch 72/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.9018 - accuracy: 0.0744\n",
            "Epoch 73/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8983 - accuracy: 0.0749\n",
            "Epoch 74/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8949 - accuracy: 0.0741\n",
            "Epoch 75/200\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 3.8916 - accuracy: 0.0739\n",
            "Epoch 76/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8882 - accuracy: 0.0741\n",
            "Epoch 77/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8853 - accuracy: 0.0744\n",
            "Epoch 78/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8824 - accuracy: 0.0736\n",
            "Epoch 79/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.8795 - accuracy: 0.0741\n",
            "Epoch 80/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8769 - accuracy: 0.0739\n",
            "Epoch 81/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8742 - accuracy: 0.0743\n",
            "Epoch 82/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8716 - accuracy: 0.0742\n",
            "Epoch 83/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8692 - accuracy: 0.0738\n",
            "Epoch 84/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8668 - accuracy: 0.0740\n",
            "Epoch 85/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8645 - accuracy: 0.0739\n",
            "Epoch 86/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.8624 - accuracy: 0.0739\n",
            "Epoch 87/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8601 - accuracy: 0.0742\n",
            "Epoch 88/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8579 - accuracy: 0.0738\n",
            "Epoch 89/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8559 - accuracy: 0.0734\n",
            "Epoch 90/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8541 - accuracy: 0.0737\n",
            "Epoch 91/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8522 - accuracy: 0.0735\n",
            "Epoch 92/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8503 - accuracy: 0.0741\n",
            "Epoch 93/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 3.8485 - accuracy: 0.0732\n",
            "Epoch 94/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8469 - accuracy: 0.0735\n",
            "Epoch 95/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8449 - accuracy: 0.0739\n",
            "Epoch 96/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8431 - accuracy: 0.0734\n",
            "Epoch 97/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8419 - accuracy: 0.0730\n",
            "Epoch 98/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8402 - accuracy: 0.0735\n",
            "Epoch 99/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8387 - accuracy: 0.0730\n",
            "Epoch 100/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8373 - accuracy: 0.0737\n",
            "Epoch 101/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8359 - accuracy: 0.0739\n",
            "Epoch 102/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8346 - accuracy: 0.0736\n",
            "Epoch 103/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8332 - accuracy: 0.0740\n",
            "Epoch 104/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8318 - accuracy: 0.0738\n",
            "Epoch 105/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8305 - accuracy: 0.0737\n",
            "Epoch 106/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8292 - accuracy: 0.0733\n",
            "Epoch 107/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8281 - accuracy: 0.0733\n",
            "Epoch 108/200\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 3.8271 - accuracy: 0.0730\n",
            "Epoch 109/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8258 - accuracy: 0.0731\n",
            "Epoch 110/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8247 - accuracy: 0.0742\n",
            "Epoch 111/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8236 - accuracy: 0.0731\n",
            "Epoch 112/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8226 - accuracy: 0.0735\n",
            "Epoch 113/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 3.8217 - accuracy: 0.0733\n",
            "Epoch 114/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8206 - accuracy: 0.0729\n",
            "Epoch 115/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8196 - accuracy: 0.0730\n",
            "Epoch 116/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.8186 - accuracy: 0.0731\n",
            "Epoch 117/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.8176 - accuracy: 0.0736\n",
            "Epoch 118/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8167 - accuracy: 0.0728\n",
            "Epoch 119/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8159 - accuracy: 0.0731\n",
            "Epoch 120/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8150 - accuracy: 0.0733\n",
            "Epoch 121/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8140 - accuracy: 0.0729\n",
            "Epoch 122/200\n",
            "188/188 [==============================] - 14s 74ms/step - loss: 3.8133 - accuracy: 0.0728\n",
            "Epoch 123/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8126 - accuracy: 0.0737\n",
            "Epoch 124/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8117 - accuracy: 0.0734\n",
            "Epoch 125/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8110 - accuracy: 0.0737\n",
            "Epoch 126/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.8102 - accuracy: 0.0733\n",
            "Epoch 127/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8095 - accuracy: 0.0732\n",
            "Epoch 128/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8087 - accuracy: 0.0735\n",
            "Epoch 129/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8081 - accuracy: 0.0733\n",
            "Epoch 130/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8072 - accuracy: 0.0730\n",
            "Epoch 131/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8066 - accuracy: 0.0726\n",
            "Epoch 132/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8059 - accuracy: 0.0725\n",
            "Epoch 133/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8054 - accuracy: 0.0730\n",
            "Epoch 134/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8048 - accuracy: 0.0731\n",
            "Epoch 135/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8042 - accuracy: 0.0730\n",
            "Epoch 136/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8036 - accuracy: 0.0728\n",
            "Epoch 137/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.8030 - accuracy: 0.0735\n",
            "Epoch 138/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.8022 - accuracy: 0.0733\n",
            "Epoch 139/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.8019 - accuracy: 0.0719\n",
            "Epoch 140/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8012 - accuracy: 0.0731\n",
            "Epoch 141/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.8007 - accuracy: 0.0727\n",
            "Epoch 142/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.8001 - accuracy: 0.0730\n",
            "Epoch 143/200\n",
            "188/188 [==============================] - 14s 75ms/step - loss: 3.7997 - accuracy: 0.0726\n",
            "Epoch 144/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7991 - accuracy: 0.0733\n",
            "Epoch 145/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7984 - accuracy: 0.0726\n",
            "Epoch 146/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7980 - accuracy: 0.0726\n",
            "Epoch 147/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.7978 - accuracy: 0.0726\n",
            "Epoch 148/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.7971 - accuracy: 0.0731\n",
            "Epoch 149/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7967 - accuracy: 0.0723\n",
            "Epoch 150/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7964 - accuracy: 0.0728\n",
            "Epoch 151/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7957 - accuracy: 0.0734\n",
            "Epoch 152/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7954 - accuracy: 0.0728\n",
            "Epoch 153/200\n",
            "188/188 [==============================] - 16s 85ms/step - loss: 3.7947 - accuracy: 0.0729\n",
            "Epoch 154/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7945 - accuracy: 0.0732\n",
            "Epoch 155/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7939 - accuracy: 0.0729\n",
            "Epoch 156/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7937 - accuracy: 0.0728\n",
            "Epoch 157/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7933 - accuracy: 0.0728\n",
            "Epoch 158/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7931 - accuracy: 0.0728\n",
            "Epoch 159/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7926 - accuracy: 0.0725\n",
            "Epoch 160/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7920 - accuracy: 0.0732\n",
            "Epoch 161/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7920 - accuracy: 0.0727\n",
            "Epoch 162/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7912 - accuracy: 0.0729\n",
            "Epoch 163/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7910 - accuracy: 0.0732\n",
            "Epoch 164/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7906 - accuracy: 0.0729\n",
            "Epoch 165/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7905 - accuracy: 0.0725\n",
            "Epoch 166/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7900 - accuracy: 0.0728\n",
            "Epoch 167/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7897 - accuracy: 0.0725\n",
            "Epoch 168/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7892 - accuracy: 0.0727\n",
            "Epoch 169/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7888 - accuracy: 0.0723\n",
            "Epoch 170/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7886 - accuracy: 0.0727\n",
            "Epoch 171/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7883 - accuracy: 0.0734\n",
            "Epoch 172/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7882 - accuracy: 0.0726\n",
            "Epoch 173/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7877 - accuracy: 0.0726\n",
            "Epoch 174/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7873 - accuracy: 0.0729\n",
            "Epoch 175/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7871 - accuracy: 0.0721\n",
            "Epoch 176/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7869 - accuracy: 0.0725\n",
            "Epoch 177/200\n",
            "188/188 [==============================] - 14s 76ms/step - loss: 3.7865 - accuracy: 0.0733\n",
            "Epoch 178/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7863 - accuracy: 0.0725\n",
            "Epoch 179/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7863 - accuracy: 0.0722\n",
            "Epoch 180/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7856 - accuracy: 0.0726\n",
            "Epoch 181/200\n",
            "188/188 [==============================] - 17s 88ms/step - loss: 3.7854 - accuracy: 0.0728\n",
            "Epoch 182/200\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 3.7852 - accuracy: 0.0721\n",
            "Epoch 183/200\n",
            "188/188 [==============================] - 15s 77ms/step - loss: 3.7852 - accuracy: 0.0732\n",
            "Epoch 184/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7846 - accuracy: 0.0721\n",
            "Epoch 185/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7845 - accuracy: 0.0724\n",
            "Epoch 186/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7843 - accuracy: 0.0719\n",
            "Epoch 187/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7841 - accuracy: 0.0718\n",
            "Epoch 188/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7840 - accuracy: 0.0726\n",
            "Epoch 189/200\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 3.7834 - accuracy: 0.0725\n",
            "Epoch 190/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7833 - accuracy: 0.0728\n",
            "Epoch 191/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7830 - accuracy: 0.0730\n",
            "Epoch 192/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7831 - accuracy: 0.0726\n",
            "Epoch 193/200\n",
            "188/188 [==============================] - 15s 82ms/step - loss: 3.7827 - accuracy: 0.0728\n",
            "Epoch 194/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7825 - accuracy: 0.0728\n",
            "Epoch 195/200\n",
            "188/188 [==============================] - 15s 80ms/step - loss: 3.7823 - accuracy: 0.0728\n",
            "Epoch 196/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7822 - accuracy: 0.0724\n",
            "Epoch 197/200\n",
            "188/188 [==============================] - 14s 77ms/step - loss: 3.7819 - accuracy: 0.0727\n",
            "Epoch 198/200\n",
            "188/188 [==============================] - 15s 78ms/step - loss: 3.7816 - accuracy: 0.0727\n",
            "Epoch 199/200\n",
            "188/188 [==============================] - 15s 79ms/step - loss: 3.7816 - accuracy: 0.0725\n",
            "Epoch 200/200\n",
            "188/188 [==============================] - 15s 81ms/step - loss: 3.7813 - accuracy: 0.0726\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=200, verbose=1, batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save Model**"
      ],
      "metadata": {
        "id": "NA39bFhtxNeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "iwDDlk79fYSe"
      },
      "outputs": [],
      "source": [
        "model.save('model_skipgram.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4GvDkAcvmdg"
      },
      "source": [
        "## **Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "McWk2c7kfoOd"
      },
      "outputs": [],
      "source": [
        "# laod model\n",
        "model = load_model('model_skipgram.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JiFkSzhi52",
        "outputId": "e5d09970-1a5a-44e2-ce9a-4995db4993cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f2032c88210>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dglp04EQwCPI"
      },
      "source": [
        "### **Get Most Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "p4qSGi4xIBc3"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.h5', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Ds2srxegG79R"
      },
      "outputs": [],
      "source": [
        "def get_most_similarity(word, model=model, tokenizer=tokenizer, n=15):\n",
        "  num_unique_words = len(tokenizer.word_index) + 1\n",
        "  word_to_sequences = tokenizer.texts_to_sequences([word])[0]\n",
        "  prediction = model.predict(word_to_sequences)[0]\n",
        "  index = np.argsort(prediction)[::-1][:n]\n",
        "  sequences_to_word = tokenizer.sequences_to_texts([index])[0]\n",
        "  most_similarity = sequences_to_word.split(' ')\n",
        "  return most_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdWkt3rtI5mW",
        "outputId": "5530bc93-8259-4a66-c527-c499a450d227"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'عقل',\n",
              " 'آتش',\n",
              " 'شاه',\n",
              " 'جمله',\n",
              " 'شمس',\n",
              " 'عاشقان',\n",
              " 'دست',\n",
              " 'مست',\n",
              " 'جهان',\n",
              " 'گشت',\n",
              " 'ملک',\n",
              " 'روح']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "get_most_similarity('عشق')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOPqYELUQUGD",
        "outputId": "ba5161ce-b356-4eb7-9fe7-6d77ac2b0257"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['تبریزی',\n",
              " 'تبریز',\n",
              " 'دین',\n",
              " 'الدین',\n",
              " 'مفخر',\n",
              " 'الحق',\n",
              " 'جان',\n",
              " 'عشق',\n",
              " 'خداوند',\n",
              " 'نور',\n",
              " 'الضحی',\n",
              " 'دل',\n",
              " 'ذره',\n",
              " 'مخدوم',\n",
              " 'خورشید']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "get_most_similarity('شمس')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmDO4rOtHVCr",
        "outputId": "0c74a555-5ca1-4f53-8c6a-0554274e1302"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عاشق',\n",
              " 'درآرد',\n",
              " 'زندان',\n",
              " 'ای',\n",
              " 'نرسم',\n",
              " 'نشین',\n",
              " 'کنجی',\n",
              " 'خلا',\n",
              " 'کنج',\n",
              " 'مشین',\n",
              " 'دمی',\n",
              " 'بیدار',\n",
              " 'کرده',\n",
              " 'مطلق',\n",
              " 'نه']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "get_most_similarity('کنج')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('گل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txWieAX77Ekj",
        "outputId": "f5140827-08ae-4d63-d376-afa0b0ffdcb9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['آب',\n",
              " 'خار',\n",
              " 'گل',\n",
              " 'بلبل',\n",
              " 'دل',\n",
              " 'باغ',\n",
              " 'یار',\n",
              " 'ریحان',\n",
              " 'آتش',\n",
              " 'گلزار',\n",
              " 'نسرین',\n",
              " 'رعنا',\n",
              " 'چمن',\n",
              " 'شکر',\n",
              " 'رود']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('مست')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo3M1AAT7liK",
        "outputId": "b2f687e1-4c92-4aa0-fb07-8cd917ab7af0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مست',\n",
              " 'چشم',\n",
              " 'جان',\n",
              " 'آمدست',\n",
              " 'خاک',\n",
              " 'عشق',\n",
              " 'عقل',\n",
              " 'خراب',\n",
              " 'ره',\n",
              " 'دست',\n",
              " 'خواجه',\n",
              " 'جام',\n",
              " 'یار',\n",
              " 'جمله',\n",
              " 'مخمور']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('دست')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzJA3Ld67pZF",
        "outputId": "13249f7c-cab7-4e82-d7ff-6154b9c42df4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['دست',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'پا',\n",
              " 'پای',\n",
              " 'عشق',\n",
              " 'جام',\n",
              " 'دهان',\n",
              " 'مست',\n",
              " 'شب',\n",
              " 'شمس',\n",
              " 'کف',\n",
              " 'دلم',\n",
              " 'باده',\n",
              " 'یار']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('عقل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOupDP_27wOj",
        "outputId": "c53e2c66-a078-46fe-c5dd-0acf45a193c5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['عشق',\n",
              " 'عقل',\n",
              " 'جان',\n",
              " 'مست',\n",
              " 'خار',\n",
              " 'دل',\n",
              " 'قضا',\n",
              " 'گل',\n",
              " 'خط',\n",
              " 'روح',\n",
              " 'دین',\n",
              " 'سلطان',\n",
              " 'بلا',\n",
              " 'نهد',\n",
              " 'دام']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('غم')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9cT8_q073oI",
        "outputId": "1ceb0205-1a12-47e2-c915-96edece4a316"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['دل',\n",
              " 'غم',\n",
              " 'جان',\n",
              " 'شادی',\n",
              " 'شاد',\n",
              " 'اندوه',\n",
              " 'جهان',\n",
              " 'شب',\n",
              " 'یار',\n",
              " 'دست',\n",
              " 'عشق',\n",
              " 'باده',\n",
              " 'آب',\n",
              " 'عاشق',\n",
              " 'بخسب']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('انگور')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UdR8Kxa79Sg",
        "outputId": "b2319496-5623-4bcc-cbfa-63a78c91ae2b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['غوره',\n",
              " 'پخته',\n",
              " 'باغبان',\n",
              " 'خون',\n",
              " 'گور',\n",
              " 'ای',\n",
              " 'روضه',\n",
              " 'نفی',\n",
              " 'مستم',\n",
              " 'دل',\n",
              " 'شد',\n",
              " 'کدامین',\n",
              " 'شور',\n",
              " 'شوره',\n",
              " 'برده']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('آب')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxOt5GEG8Bpb",
        "outputId": "a6db9dbc-1f0b-4d22-9906-1943bb07631c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['گل',\n",
              " 'آب',\n",
              " 'حیات',\n",
              " 'جان',\n",
              " 'سنگ',\n",
              " 'آتش',\n",
              " 'جوی',\n",
              " 'روان',\n",
              " 'بحر',\n",
              " 'جو',\n",
              " 'دل',\n",
              " 'نان',\n",
              " 'چشمه',\n",
              " 'حیوان',\n",
              " 'زندگانی']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('آتش')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7XhG8738JAB",
        "outputId": "cef2e2b2-5b20-4431-9514-7eadbaac7fe7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['آتش',\n",
              " 'عشق',\n",
              " 'آب',\n",
              " 'جان',\n",
              " 'گل',\n",
              " 'دل',\n",
              " 'برآوردم',\n",
              " 'فلک',\n",
              " 'زدی',\n",
              " 'جگر',\n",
              " 'خلیل',\n",
              " 'خانه',\n",
              " 'آفتاب',\n",
              " 'مفرش',\n",
              " 'سوز']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('شب')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrgHKete8PzV",
        "outputId": "f276d43f-fe8f-4b07-be4f-de68091cf50a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['شب',\n",
              " 'مه',\n",
              " 'گشت',\n",
              " 'جان',\n",
              " 'دل',\n",
              " 'سحر',\n",
              " 'ماه',\n",
              " 'دست',\n",
              " 'رخ',\n",
              " 'تیره',\n",
              " 'دام',\n",
              " 'خلق',\n",
              " 'شمع',\n",
              " 'خواب',\n",
              " 'سیاه']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('جهان')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxNZL-cc8VcR",
        "outputId": "fbf912e4-8cf2-4a50-b412-16dfdde3961b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['جان',\n",
              " 'جهان',\n",
              " 'دل',\n",
              " 'نهان',\n",
              " 'عشق',\n",
              " 'جمله',\n",
              " 'تنگ',\n",
              " 'غم',\n",
              " 'گرد',\n",
              " 'نقش',\n",
              " 'شاه',\n",
              " 'عاشق',\n",
              " 'دید',\n",
              " 'ذره',\n",
              " 'بنگر']"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('دل')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IHZs1JQ8aks",
        "outputId": "a42620be-6968-4559-a9a0-a8b30e0b4aab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['جان',\n",
              " 'دل',\n",
              " 'عشق',\n",
              " 'خانه',\n",
              " 'غم',\n",
              " 'خون',\n",
              " 'دست',\n",
              " 'جهان',\n",
              " 'گل',\n",
              " 'تبریز',\n",
              " 'رود',\n",
              " 'سبک',\n",
              " 'دین',\n",
              " 'سخن',\n",
              " 'نور']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('مه')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkYawoaW8gDv",
        "outputId": "11e7f3e5-1f10-4c93-93cf-7c96788f4e1e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مه',\n",
              " 'نور',\n",
              " 'شب',\n",
              " 'رخ',\n",
              " 'فلک',\n",
              " 'خورشید',\n",
              " 'ماه',\n",
              " 'جان',\n",
              " 'لقا',\n",
              " 'سجده',\n",
              " 'لقایی',\n",
              " 'چرخ',\n",
              " 'پاره',\n",
              " 'توبه',\n",
              " 'استاره']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_most_similarity('نور')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN5MrmxD8ogt",
        "outputId": "d0b80b47-4f8b-41a7-bbbd-f6605a3b05f1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['مه',\n",
              " 'نور',\n",
              " 'شمع',\n",
              " 'شمس',\n",
              " 'شعله',\n",
              " 'نار',\n",
              " 'دل',\n",
              " 'تبریزی',\n",
              " 'آفتاب',\n",
              " 'عالم',\n",
              " 'دیدار',\n",
              " 'سایه',\n",
              " 'موسی',\n",
              " 'چشم',\n",
              " 'صبح']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "word2vec_skipgram.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}